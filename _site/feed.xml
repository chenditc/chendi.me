<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Di's Blog</title>
    <description></description>
    <link>http://0.0.0.0:4000/</link>
    <atom:link href="http://0.0.0.0:4000/feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Tue, 04 Aug 2020 11:49:50 +0800</pubDate>
    <lastBuildDate>Tue, 04 Aug 2020 11:49:50 +0800</lastBuildDate>
    <generator>Jekyll v4.0.0</generator>
    
      <item>
        <title>Reading notes: Clean Agile</title>
        <description>&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;#第一章敏捷的起源&quot;&gt;第一章：敏捷的起源&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;#铁十字项目中必须要做的权衡&quot;&gt;铁十字，项目中必须要做的权衡&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#敏捷的目的&quot;&gt;敏捷的目的&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#管理项目的铁十字-the-iron-cross&quot;&gt;管理项目的铁十字 (The Iron Cross)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&quot;#第二章为什么要敏捷&quot;&gt;第二章：为什么要敏捷&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;#程序员的职业素养-professionalism&quot;&gt;程序员的职业素养 (Professionalism)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#一些对程序员的合理的期望-reasonable-expectations&quot;&gt;一些对程序员的合理的期望 (Reasonable Expectations)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#权利法案-the-bill-of-rights&quot;&gt;权利法案 (The Bill Of Rights)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&quot;#第三章敏捷的业务方实践&quot;&gt;第三章：敏捷的业务方实践&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;前言&quot;&gt;前言&lt;/h2&gt;

&lt;p&gt;在过去项目的开发和迭代过程中，遇到了不少业务方和开发方预期不一致导致的冲突，在所谓的”敏捷迭代“的过程中，也没有感受到敏捷带来的效率或者项目可控性的提升。学而不思则罔，思而不学则殆，于是带着工作中的疑问来阅读整洁系列的新作。&lt;/p&gt;

&lt;p&gt;疑问1: 为什么直观感受上敏捷没有带来效率上的提升，每个时间周期内能做完的事情或者需求还是那么多？&lt;/p&gt;

&lt;p&gt;疑问2: 为什么项目仍然会一直 delay？&lt;/p&gt;

&lt;p&gt;这个读书笔记并不是一个完整的中文翻译，只摘取书中的关键观点，针对每个观点与我过去项目管理中的经验做对比，并提供一部分我自己的想法。&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;第一章敏捷的起源&quot;&gt;第一章：敏捷的起源&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;http://book.chendi.me:8080/site/library/view/clean-agile-back/9780135782002/ch01.html&quot;&gt;第一章原文&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;敏捷的关键点其实是尽量保持人员的稳定，同时坚守对质量的维护。在这两个前提下，把时间点和需求量的取舍交给最终用户来进行。&lt;/p&gt;

&lt;hr /&gt;

&lt;h4 id=&quot;铁十字项目中必须要做的权衡&quot;&gt;铁十字，项目中必须要做的权衡&lt;/h4&gt;

&lt;blockquote&gt;
  &lt;p&gt;The reason that these techniques fail so spectacularly is that the managers who use them do not understand the fundamental physics of software projects. This physics constrains all projects to obey an unassailable trade-off called the Iron Cross of project management. Good, fast, cheap, done: Pick any three you like. You can’t have the fourth. You can have a project that is good, fast, and cheap, but it won’t get done. You can have a project that is done, cheap, and fast, but it won’t be any good.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;观点总结：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;就像我们的日常生活被物理定律支配一样，软件开发也有基本规律。书中称为 &lt;em&gt;The Iron Cross&lt;/em&gt; （铁十字），即：对于一个项目，在质量、速度、成本、完成度4个维度中挑选3个，舍弃一个，不会有一个项目能高质量、低成本、快速地把所有需求都完成。如果一个项目能低成本、快速地把所有需求都完成，这个项目一定质量不高。&lt;/li&gt;
  &lt;li&gt;项目经理需要做好权衡，把这4个方面都做到足够好即可，不需要做到100%。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;实际项目：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;在过去的软件开发项目中，质量意味着 bug 率和代码可维护性，交付的产品中有多少未修复的 bug，有多少单元测试覆盖。速度意味着一个需求的交付周期。成本意味着有多少人参与。完成度意味着有多少需求完成了，特别是一些为了使用体验而提出的优化需求。&lt;/li&gt;
  &lt;li&gt;在上一个项目当中，项目初期有一个明确的完成时间点，且评估下来时间上很紧张，同时项目的范围的约束有简单的功能点罗列，所以在项目开始时，我们的权衡就是：
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;质量 (Good) 70%&lt;/strong&gt;。因为我们在完成项目的同时希望可以做成一个可复制的产品，没有人愿意接手垃圾代码。所以单元测试、代码风格、同行评审是一开始就强制加在提交流程里的。但是对于一些不影响主流程的 bug，可能就决定暂不处理了。&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;速度 (Fast) 90%&lt;/strong&gt;。由于项目的周期很紧，所以速度是最不能牺牲的一部分。&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;成本 (Cheap) 50%&lt;/strong&gt;。由于内部人员的支持不足，成本上被迫做了很大的牺牲。&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;完成度 (Done) 30%&lt;/strong&gt;。由于其他方面的限制能调整的空间太少，只能在完成度上做牺牲，对于用户体验不好的地方暂时不做处理，能把功能性需求完成就行。对于 UI 上不好看的地方也暂时不处理。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;思考：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;和 CEO 的一个比较大的分歧就在于铁十字是不是能改变。对于 CEO 来说，一个公司的存亡往往意味着能以更低的成本(Cheap)、更快的速度(Fast)做出体验更好(Done\Good)的产品来满足客户。但是对于我来说，这个权衡是实实在在存在，并且得做的，而作出的牺牲都可能被归咎于团队的积极性和主观能动性不高，毕竟多改几个 bug （Good），多做几个需求（Done）都是可以通过加班来提高的嘛。&lt;/li&gt;
  &lt;li&gt;在其他的资料中，也提到类似的看法，比如 Atlassian（做 Jira 的公司）提到 &lt;a href=&quot;https://www.atlassian.com/agile/agile-at-scale/agile-iron-triangle&quot;&gt;The iron triangle of planning
&lt;/a&gt; 。
    &lt;ul&gt;
      &lt;li&gt;传统的项目管理有3个需要权衡的铁三角：工作范围（比如需求点和功能点）、资源（经济资源和人力资源）、时间（交付里程碑）。这3个被称为&lt;strong&gt;铁&lt;/strong&gt;三角，就意味着在改变一个要素的情况下，是不可能不影响其他两个要素的。比如在增加需求的情况下，不加资源是不可能按原时间交付的。&lt;/li&gt;
      &lt;li&gt;但是实际工作中，总是会有要求需求要全部做完，人员也没有额外的变动空间，时间节点也是限制死的。这时候大家是怎么办的呢？其他人的博客其实也提到过 &lt;a href=&quot;https://medium.com/serious-scrum/the-lie-of-the-iron-triangle-6445e5e4fb26&quot;&gt;The Lie of the Iron Triangle
&lt;/a&gt; 在这种情况下，其实牺牲的就是铁三角的第四个面，也就是当这三个条件无法组成三角形时，质量就流失了。我们会加班工作，跳过必要的测试步骤，压缩用户培训时间，压缩部署流程中的检验环节，跳过文档的撰写，不修复一些低优先的 bug。于是我们就交付了一个质量有问题的产品。作为这个产品的作者，程序员，无疑是悲哀的。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h4 id=&quot;敏捷的目的&quot;&gt;敏捷的目的&lt;/h4&gt;

&lt;blockquote&gt;
  &lt;p&gt;As the iterations progress, the error bars shrink until there is no point in hoping that the original date has any chance of success.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;This loss of hope is a major goal of Agile. We practice Agile in order to destroy hope before that hope can kill the project.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;ol&gt;
    &lt;li&gt;Sprint is the term used in Scrum. I dislike the term because it implies running as fast as possible. A software project is a marathon, and you don’t want to sprint in a marathon.&lt;/li&gt;
  &lt;/ol&gt;
&lt;/blockquote&gt;

&lt;p&gt;观点总结：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;敏捷迭代的目的不是使开发速度更快，也不是使项目不会 delay。恰恰相反，敏捷迭代的目的，是在早期把项目不会 delay 的希望给打碎，避免像瀑布式开发，到了交付前几天或者几周，才发现项目无法交付。&lt;/li&gt;
  &lt;li&gt;敏捷迭代中每个迭代叫一个“冲刺”，但是这个词并不好，因为一个软件项目是一场马拉松，你不会想在跑马拉松的时候保持冲刺的姿态。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;实际项目：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;实际工作中，“敏捷”往往给人一个感觉，”敏捷“迭代会使得项目开发的速度变快，这个其实从一开始就不是“敏捷”的意义。&lt;/li&gt;
  &lt;li&gt;在我做的上一个项目中，其实并不需要敏捷迭代来预警，从一开始的项目计划排下来，就没办法排一个不 delay 的计划。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;思考：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;敏捷的意义在于预警，在于可控性。可控性不意味着不会 delay，而是及早地把问题暴露出来，及早地采取措施解决问题。但是如果项目一开始就没有一个计划能不 delay，那么无论用什么项目管理或者迭代的方法，还有什么意义呢？ 当然有意义，项目的目标是实现商业价值，错过了时间可能会减少商业价值，所以不 delay 不能作为项目的最终目标之一，最终目标应该是以最大化项目的商业价值为目标。&lt;/li&gt;
  &lt;li&gt;至此，疑问1和疑问2都被解释了，其实敏捷并没有打算解决我们认为的开发效率和项目 delay 的问题。那么敏捷团队是怎样看待并处理 delay 这件事情呢？&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h4 id=&quot;管理项目的铁十字-the-iron-cross&quot;&gt;管理项目的铁十字 (The Iron Cross)&lt;/h4&gt;

&lt;blockquote&gt;
  &lt;p&gt;Remember, the date was chosen for good business reasons. Those business reasons probably haven’t changed. So a delay often means that the business is going to take a significant hit of some kind.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Brooks’ law states: Adding manpower to a late project makes it later.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Everyone knows that you can go much faster by producing crap. So, stop writing all those tests, stop doing all those code reviews, stop all that refactoring nonsense, and just code you devils, just code. Code 80 hours per week if necessary, but just code! Producing crap does not make you go faster, it makes you go slower. This is the lesson you learn after you’ve been a programmer for 20 or 30 years. There is no such thing as quick and dirty.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Anything dirty is slow.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;If the organization is rational, then the stakeholders eventually bow their heads in acceptance and begin to scrutinize the plan. One by one, they will identify the features that they don’t absolutely need by November. This hurts, but what real choice does the rational organization have? And so the plan is adjusted. Some features are delayed.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;观点总结：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;当我们通过敏捷迭代开发了一段时间之后，我们可能会发现项目或者交付物会 delay，这时候怎么办呢？常见的方案有几个：
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;修改交付目标时间点。&lt;/strong&gt;这个方案简单，但是往往后期会被作为一个事故诟病。&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;加人。&lt;/strong&gt;根据 Brooks 定律，加人会导致项目进一步 delay。因为新人加入项目之后需要原项目组的人分配额外的时间进行培训和问题解答，会影响原项目组的人的效率，而新人往往要过几周才能不需要指导地完成工作，就意味着这几周内，效率是比原来要低的。但是如果时间够长，整体团队效率还是能较之前有提升的。&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;降低质量。&lt;/strong&gt;这个方案往往是大多数人采取的方案。例如时间不够的时候，不写单元测试，不写注释，不写文档，不做代码评审，不做完整的回归测试，不做用户培训，不使用灰度发布。这样可以写出很多&lt;em&gt;脏&lt;/em&gt;代码。但是做过20、30年开发的人都知道，没有哪个&lt;em&gt;脏&lt;/em&gt;代码可以很快开发完成的，越&lt;em&gt;脏&lt;/em&gt;的东西，越慢。&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;砍需求，减少需求范围。&lt;/strong&gt;让用户放弃一部分需求是很困难的，特别是用户出资支持这个项目开发的时候，更难。但是如果整个组织和用户是理性的，在不修改时间的前提下，会很痛苦地接受这个事情，砍掉一部分需求。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;实际项目：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;作为项目经理，无时不刻在面对这4个方案的选择，每个方案都需要克服一定的压力才可能落实。改时间的话往往意味着 KPI 不达成，或者合同违约。而砍需求对用户来说也是一个很痛苦的决定，这个对话也会很艰难。于是看似简单的方法就变成了加人或则会降低质量。在我上一个项目中，频繁的人员变化导致了许多的重复工作，项目背景、代码框架需要重新介绍，需要重新磨合，但却是项目慢慢变好的一个必经之路。而质量，则是最难坚守的一道坎。后端的代码一直坚持着单元测试，但是前端却很难用类似的方法进行覆盖管理，也是后续项目迭代越来越慢的一个原因。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;思考：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;对于一个产品经理或者项目经理来说，最难的应该是坚守产品的质量，但在我看来，这也是区分一个平庸的项目经理和一个优秀项目经理的关键点。没有经历过软件开发的人，不会理解代码质量对于长期发展的影响有多深。&lt;/li&gt;
  &lt;li&gt;敏捷的关键点其实是尽量保持人员的稳定，同时坚守对质量的维护。在这两个前提下，把时间点和需求量的取舍交给最终用户来进行。&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;第二章为什么要敏捷&quot;&gt;第二章：为什么要敏捷&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;http://book.chendi.me:8080/site/library/view/clean-agile-back/9780135782002/ch02.html&quot;&gt;第二章原文&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;敏捷迭代的目标和实施前提。&lt;/p&gt;

&lt;h4 id=&quot;程序员的职业素养-professionalism&quot;&gt;程序员的职业素养 (Professionalism)&lt;/h4&gt;

&lt;blockquote&gt;
  &lt;p&gt;We in this industry sorely need to increase our professionalism. We fail too often. We ship too much crap. We accept too many defects. We make terrible trade-offs. Too often, we behave like unruly teenagers with a new credit card. In simpler times, these behaviors were tolerable because the stakes were relatively low. In the ’70s and ’80s and even into the ’90s, the cost of software failure, though high, was limited and containable.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;观点总结：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;在当今的社会，生活的方方面面已经离不开程序员的代码贡献了，app、网站、公共交通、政府、银行、医疗等等都被软件应用打通了。想象你写的那些代码会被作用到这些关键的领域，而你的一个 bug 可能导致他人损失金钱甚至生命，那我们对待手上的代码时，应该要保持更高地专业度和职业素养才行。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;实际项目：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;在之前的项目中，即使我很希望能保持最高的专业度，所有代码都有测试用例覆盖，每个提交有对应的单元测试执行，每个环境的部署都有自动的健康检测等等。但是做这些事情短期看不到什么成果，而且会导致成本大幅上升，就根本推不下去。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;思考：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;作为一个程序员，难的不是尽力写出好的代码，或者保持高的专业度，难的是上司或者领导迫于商业或者其他压力，要求你不写测试用例，不测试直接上线等等。&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h4 id=&quot;一些对程序员的合理的期望-reasonable-expectations&quot;&gt;一些对程序员的合理的期望 (Reasonable Expectations)&lt;/h4&gt;

&lt;blockquote&gt;
  &lt;p&gt;What follows is a list of perfectly reasonable expectations that managers, users, and customers have of us. Notice as you read through this list that one side of your brain agrees that each item is perfectly reasonable. Notice that the other side of your brain, the programmer side, reacts in horror. The programmer side of your brain may not be able to imagine how to meet these expectations.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Meeting these expectations is one of the primary goals of Agile development. The principles and practices of Agile address most of the expectations on this list quite directly. The behaviors below are what any good chief technology officer (CTO) should expect from their staff. Indeed, to drive this point home, I want you to think of me as your CTO. Here is what I expect.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;观点总结：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;敏捷开发的一个主要目的是达到以下的一系列期望，这些期望是针对程序员的。可以把这些期望想象成敏捷开发的目标。敏捷的方法论就是为了达到这些期望而设计出来的。
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;我们不交付垃圾 (We will Not Ship Shyt)。&lt;/strong&gt; 这个听起来是个废话，但是现实是，这确实需要作为一个期望提出。所以敏捷会强调测试、重构、简化设计，从而保证交付给客户的都是高质量的、用户友好的产品。&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;技术上持续可部署 (Continous Technical Readiness)。&lt;/strong&gt; 敏捷要求在每个迭代结束的时候，系统都是处在一个可部署的状态。如果用户选择不部署更新，比如做完的功能点还不够多，或者商业时机没到，这是一个商业决定，这没关系。但是在每个迭代结束的时候，所有完成的功能都需要是写完代码、测试过、写清楚文档的。所以敏捷要求每个用户故事都足够小，从而保证可以在一个迭代中高质量地完成。&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;稳定的产能 (Stable Productivity)。&lt;/strong&gt; 在项目一开始的时候，往往会发现功能做的很快，因为没有老的代码库的依赖，没有历史包袱，但是随着项目发展，同样复杂度的需求可能会需要花许多2-3倍的时间，这往往是很多非研发的客户或者管理者无法理解的。其实出现这个情况就意味着代码的架构设计或者逻辑结构有问题，需要优化或者重构，但是重构应该是随着每个需求小范围的进行的，不应该整体推翻重来。同样的，敏捷要求的测试、结对编程、重构和简化设计都是保持稳定产能的关键。&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;低成本地进行修改 (Inexpensive Adaptability)。&lt;/strong&gt; 研发经常会抱怨需求一直变更，但是好的架构和好的程序设计应该是能灵活应对需求的变更的，如果无法灵活应对，则代表你的架构或者设计很差。程序员的意义也正是在于可以实现需求变更。同样的，敏捷要求的测试、结对编程、重构和简化设计都是保持低成本地进行修改的关键。&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;代码的持续优化提升 (Continous Improvement)。无畏地把事情做好 (Fearless Competence)&lt;/strong&gt; 人类渐渐地把事情变得更好，代码也不应该例外，不应该因为时间的流逝，代码渐渐腐化。而代码的腐化往往出现在尝试走捷径的时候，例如一个需求做一个简单修改，但是留下一个 magic number，也可以做一个小重构，把变量抽离开，此时有很多人都会不敢做这个小重构，因为担心改出一些意外的 bug。但是如果有面向测试编程的支持，所有的需求都有自动化的测试用例，如果测试用例都跑过了就意味着没问题，那么我相信大部分程序员都不会害怕做这样的小重构。而敏捷推崇的结对编程、面向测试编程、重构、简化设计都是为了支持这一点。&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;测试应该找不到问题 (QA Should Find Nothing) 应该尽量做自动化测试 (Test Automation)&lt;/strong&gt; 当 测试跑一遍他们的测试用例的时候，他们应该能得出系统一切正常的这个答案。当测试发现 bug 的时候，研发团队应该复盘在研发的流程中，哪一步出错了，从而保证下一次不会出现同样的问题。同样的，对于测试来说，重复的手工测试是耗时、昂贵、而且&lt;strong&gt;不人道&lt;/strong&gt;的，如果留给测试时间不足的话，那么无论怎样对测试用例进行取舍，交付出去的都是一个没有被完整测试过的产品，所以我们应该用自动化测试来覆盖所有可以覆盖的测试用例，让测试只需要测那些无法自动化的部分。这也是让研发团队可以做到交付测试无 bug 的必经的一步。&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;我们为其他人互相打掩护 (We Cover for Each Other)&lt;/strong&gt; 客户不会关心你的私人生活是不是有什么变故，生病、度假都不应该影响到整体，不应该让整个团队停摆。所以敏捷的结对编程、完整团队、集体拥有的思想都是为了达到这个目标的。&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;诚实的预估 (Honest Estimates)&lt;/strong&gt; 所有的预估，都应该是诚实的。最诚实的预估是 “我不知道”。但是呢，即使一些事情自己不知道，也应该基于自己了解的信息提供一些信息。比如我们可能无法预估出某个任务可能需要花的时间有多长，但是我们可以和已经做过的事情比较，比如任务 A 比任务 B 简单，但是比任务 C 复杂，这也是非常有价值的。或者我们也可以给出不同置信度的预估，比如任务 A 有 5% 的可能在 3 天内完成，有 50% 的可能在 6 天内完成，有 95% 的可能在 20 天内完成。这个信息也可以给项目经理很多帮助。&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;你需要说“不” (You Need to say no)&lt;/strong&gt; 即便我们工程师是为了解决问题而存在的，但是当事情没有一条可能完成的路径时，无论上级或者外部有多大的压力，也需要把 “No“ 说出来。敏捷的完整团队思想是为了支持这一点的。&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;持续学习 (Continous Agressive Learning)&lt;/strong&gt; 无论公司支不支持，即使没有机会，也要自己创造机会去学习，从而适应这个快速变化的行业。&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;做导师 (Mentoring)&lt;/strong&gt; 最好的学习方式是教其他人，所以尽量去做导师辅导新人。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;实际项目：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;这是一个很长的期望列表，我也针对这个期望列表来对照看看在过去的项目中做的如何。
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;我们不交付垃圾 (We will Not Ship Shyt)。&lt;/strong&gt; 这个可以说是意外地做得最差的一条。无论是在哪个公司，我都对过去交付的产品不够满意，在 Bloomberg，即使一个老牌的大公司，大部分代码也缺少单元测试，甚至很多代码都无法在业务流程中进行测试。而其他的创业公司，有一部分新项目有比较好的单元测试覆盖，但是也仍然缺少端到端的自动化测试，所以至今也没有一个产品或者公司是在这一条让我可以拍着胸脯说，我交付的产品我满意。&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;技术上持续可部署 (Continous Technical Readiness)。&lt;/strong&gt; 意外的这一条倒是做的还不错，现在大部分的公司都有了自己的 CI 系统，可以在研发提交之后自动进行单元测试、自动部署。所以至少在每个迭代结束的时候，只要及时把 bug 修复，是可以做到持续可部署的。&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;稳定的产能 (Stable Productivity)。&lt;/strong&gt; 这一点在 Bloomberg 这样的大公司做的是比较差的，因为历史包袱太严重，每个需求的修改都是牵一发而动全身，而大部分代码又没有单元测试，就大大拉低了整体团队的迭代速度。在熵简的我负责的项目中，后端的代码都是有完整的单元测试覆盖的，从而保证了整体后端迭代的速度并不太受时间影响而变化，但是前端的代码却没有这个覆盖，也导致了整体前端的迭代速度会相对较慢。不过前端的自动化测试也一直是一个国内外较难进行的工作。&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;低成本地进行修改 (Inexpensive Adaptability)。&lt;/strong&gt; 这一条和 “稳定的产能“ 其实类似，在代码健康的情况下，整体的修改成本不会太高。但是有一点是敏捷没有提到的，在代码设计时，如果代码的底层逻辑是与实际业务设计贴近的，那么修改起来的成本也会和实际业务贴近，更容易被客户接受。例如某个实体是否是唯一的，是否作为可能被重用，在数据库、页面、处理 API 的定义上尽可能去和业务逻辑贴近，从而保证业务发起的修改复杂度更可控。&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;代码的持续优化提升 (Continous Improvement)。无畏地把事情做好 (Fearless Competence)&lt;/strong&gt; 这一条无论在哪个公司，都没有很好地做到。一个是由于业务时间线的压力，当研发提出需要对某部分的代码进行重构的时候，业务领导往往不会支持这个人物的排期。另一个是由于程序员自身的恐惧，害怕由于自己修改了代码导致 bug，不光要熬夜加班改 bug，可能也会影响到自己的绩效。这两个问题，前者可以让领导认同敏捷的思想，从而推行定期清理技术债的行动。后者则一方面靠程序员的自我修养，另一方面靠敏捷的完整团队的意识，责任共担，从而让大家可以做对的事。&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;测试应该找不到问题 (QA Should Find Nothing) 应该尽量做自动化测试 (Test Automation)&lt;/strong&gt; 我不认在国内任何一家公司能做到这个程度，在我呆过的公司也没有一家做到的。我认同这个思想，但是可能太理想化了。&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;我们为其他人互相打掩护 (We Cover for Each Other)&lt;/strong&gt; 在 Bloomberg，所有的功能都有主负责任和副负责人，同时代码评审也很认真，所以很好地达到了这个要求。但是在创业公司，大部分人对这一点其实是排斥的，因为能暂时完成、替代其他人的工作往往被认为是工作内容不饱和，团队产能有冗余，管理层就会希望进一步压榨产能，直至团队成员缺一不可。&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;诚实的预估 (Honest Estimates)&lt;/strong&gt; 与其说是诚实，不如说是有技巧地预估。当无法给出一个准确答案的时候，给出一个相对值或者概率值。但是这个在之前的项目中，给出相对预估的有，但是给出概率预估的我还没遇到。&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;你需要说“不” (You Need to say no)&lt;/strong&gt; 这一点在之前的项目中基本没有做到。特别是创业公司，被扣了一顶帽子 “创业公司就是要把不可能完成的事情做成”，那这时所有的 “No” 就变成了和公司对着干的行为，是无法生存下去的。&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;持续学习 (Continous Agressive Learning) 做导师 (Mentoring)&lt;/strong&gt; 这两点主要得看公司对于这两个行为的支持程度。Bloomberg 是完全支持的态度，但是创业公司往往都是明着或者暗着反对的态度，比如把工作量排到996或者007，基本也不会有时间进行额外的学习或者 Mentor 了。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;思考：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;这些期望描绘了一个敏捷迭代的乌托邦，如果能达到 50% 基本就是一个不错的公司了，如果能达到 80%，就可以列上程序员的理想雇主了。&lt;/li&gt;
  &lt;li&gt;预计在未来10年内，这些期望都不会完全被认同，比如自动化测试就需要很长的时间才能完成覆盖和补全，如果哪个公司能让程序员低成本地进行自动化测试，这家公司也会创造极大的财富。&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h4 id=&quot;权利法案-the-bill-of-rights&quot;&gt;权利法案 (The Bill Of Rights)&lt;/h4&gt;

&lt;blockquote&gt;
  &lt;p&gt;The goal of Agile was to heal the divide between business and development.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Notice, as you read these rights, that the rights of the customer and the rights of the developer are complementary. They fit together like a hand in a glove. They create a balance of expectations between the two groups.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;观点总结：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;敏捷的目的是修复业务方和研发方的鸿沟，而权利法案就是两方制衡的方案。&lt;/li&gt;
  &lt;li&gt;用户不光指的是最终的使用者，也包括内部的产品经理和项目经理。&lt;/li&gt;
  &lt;li&gt;用户的权利：
    &lt;ul&gt;
      &lt;li&gt;用户有权知道整体的安排，以及每个需求完成所需的代价。
        &lt;ul&gt;
          &lt;li&gt;整体的安排不代表在某个时间点一定会交付某个需求，要么需求点，要么时间点是需要可以进行调整的。需要可调整的并不意味着可以不预估，还是要预估一个带可能性的时间帮助用户处理相关事宜。&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;用户有权知道每个迭代预计会完成的功能/需求/产出。&lt;/li&gt;
      &lt;li&gt;用户有权在一个可以运行的系统上看到工作的的进度，可以尝试用不同的测试用例来验证。&lt;/li&gt;
      &lt;li&gt;用户有权改主意，有权在花合理的代价的前提下改需求。
        &lt;ul&gt;
          &lt;li&gt;修改需求或者功能是可以的，只要能对应付出价格/时间上的妥协，这也是软件开发行业存在的意义。而合理的代价意味着软件的设计应该是好的，灵活的，而不是需要推倒重来的。&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;用户有权知道时间计划和工作量预估的变化，同时选择修改需求范围以保证某个时间点的交付。&lt;/li&gt;
      &lt;li&gt;用户可以在任意一个时间点取消项目，并且拿到一个可以运行的，反映了至今为止投入的可以工作的系统。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;开发者包括研发、测试、需求分析师等。&lt;/li&gt;
  &lt;li&gt;开发的权利：
    &lt;ul&gt;
      &lt;li&gt;开发者有权知道每个需求的优先级和清晰的描述。
        &lt;ul&gt;
          &lt;li&gt;这条要求了开发者拿到的需求是固定并清晰的。这个可能和前面用户能改需求的权利相违背，但主要区别在于时间范围。在一个迭代的内部，需求需要是固定并清晰的，在迭代和迭代之间，需求是可以变化的。&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;开发者有权在任何时候高质量地完成工作。
        &lt;ul&gt;
          &lt;li&gt;这条意味着，&lt;strong&gt;不能因为需求做不完而要求开发者做出违背职业素养的事&lt;/strong&gt;，比如跳过测试、文档、代码审核，或指责明知有安全隐患却不处理。&lt;/li&gt;
          &lt;li&gt;这条也许是最难的一条。&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;开发者有权向同事、领导、客户寻求并获得帮助。&lt;/li&gt;
      &lt;li&gt;开发者有权提出工作量预估，并且更新修改自己的工作量预估。
        &lt;ul&gt;
          &lt;li&gt;预估不代表承诺。&lt;/li&gt;
          &lt;li&gt;预估不可能准确，预估永远只是个预测值。&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;开发者有权主动获取自己的责任范围，而不是被动分配。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;关键点1: 计划内，要么需求范围，要么时间点需要是灵活的，不能两个都是定死的。用户没有权利要求在某个时间点前一定要完成某些功能，用户只能通过修改需求范围来达到所需要的时间点。为了使用户能理性地作出这个判断，需要给他提供足够的信息，包括每个工作的预估时间和代价。&lt;/li&gt;
  &lt;li&gt;关键点2: 不能因为需求做不完而要求开发者做出违背职业素养的事。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;实际项目：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;在上一个项目中，用户的权利基本都是可以得到保障的，除了一点，就是当前项目的状态。项目的状态都是经过美化过的，没人愿意承认当前的项目当中问题一大堆，显得自己能力不行，但是哪个项目会是一帆风顺没有坎坷的呢？&lt;/li&gt;
  &lt;li&gt;在上一个项目中，研发的权利是没办法得到保障的。
    &lt;ul&gt;
      &lt;li&gt;无法高质量地完成工作。当需求来不及做的时候，第一处理方案总是加班，在长期无偿加班的时候，开发者也很难保持一个完美主义的状态把事情做到 100 分，于是就产出了低质量的产品。如果第一处理方案也没法处理，第二处理方案往往是跳过测试、跳过文档、跳过审核，跳过这些看似不会立即产生价值的阶段。&lt;/li&gt;
      &lt;li&gt;无法拿到清晰描述的需求和优先级。在面对强势的客户时，客户提出的需求在一个迭代内可以变化两三次，导致前一个需求还没测试完，需求就又变了。&lt;/li&gt;
      &lt;li&gt;预估即承诺。在预估的时候，管理层认为预估应该要尽量贴近实际，所以偏长的预估往往会被 challenge。而在实际推进的时候，预估又被认为是“承诺”，导致“承诺”的时间内永远完不成工作。此时理性人的做法就是提高预估的时间，这样一来，用户就得不到真实的信息了。也违背了“诚实预估”的期望。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;思考：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;如果在所有人都认同这个权利法案的前提下，项目的推进是可以在一个理性且高效的节奏里进行的，关键是&lt;strong&gt;所有人&lt;/strong&gt;都认同这个权利法案。而这个关键就要求大家都了解到每个权利背后的原因，没有做过研发的人是很难理解的，比如为什么不能承诺某个事情在某个时间点前一定要完成。&lt;/li&gt;
  &lt;li&gt;认同这个权利法案最好是在项目启动会的时候就提出，明确基调之后，后续的细则措施也会好推行很多。&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;第三章敏捷的业务方最佳实践&quot;&gt;第三章：敏捷的业务方最佳实践&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;http://book.chendi.me:8080/site/library/view/clean-agile-back/9780135782002/ch03.html&quot;&gt;第三章原文&lt;/a&gt;&lt;/p&gt;

&lt;h4 id=&quot;项目计划和估时&quot;&gt;项目计划和估时&lt;/h4&gt;

&lt;blockquote&gt;
  &lt;p&gt;How do you estimate a project? The simple answer is that you break it down into its constituent pieces and then estimate those pieces. This is a fine approach; but what if the pieces themselves are too big to estimate with any accuracy? You simply break down those pieces into smaller pieces and estimate them.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;If you would like an accurate and precise estimate of a project, then break it down into individual lines of code. The time it takes you to do this will give you a very accurate and precise measure of how long it took you to build the project—because you just built it.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;观点总结：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;项目的计划和排期常见的方法是把一个大项目，拆成小的工作包，对每一个工作包进行估时后，再进行汇总。如果有某个工作包没办法估时怎么办呢？把它拆成更小颗粒度的工作包。这样循环下去，最小的颗粒度可以拆分到每一行代码。&lt;/li&gt;
  &lt;li&gt;如果我们想要一个很精准的时间预估，那么我们就需要把任务拆成每一行代码，但是如果这样做了，那这个项目也就做完了，这样做就会花很长时间来进行时间预估。而时间预估的目的是获得一个不精确的预估，预估得越不精确，所需要花在预估上的时间也越少，反之亦然。&lt;/li&gt;
  &lt;li&gt;预估的时候可以用 &lt;a href=&quot;https://en.wikipedia.org/wiki/Program_evaluation_and_review_technique&quot;&gt;PERT 方法&lt;/a&gt;，预估三个时间，一个 10% 可能完成的时间，一个 50% 可能完成的时间，还有一个 90% 可能完成的时间，项目经理利用这三个时间来做项目计划。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;实际项目：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;在上一个项目中，由于管理层认为“预估时间”等于“承诺时间”，而研发又倾向于预估一个 50% 可能完成工作的时间。这就导致了预估时间有 50% 可能是不够的，也就意味着有 50% 的延期可能。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;思考：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;在预估的同时，最好也能把预估不准的可能因素给列出来，包括第三方库的使用、新架构的引入、新的业务流程的熟悉等。这样项目经理才能把这些导致预估不准的要素也作为项目风险考虑进去。&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h4 id=&quot;用户故事和估时&quot;&gt;用户故事和估时&lt;/h4&gt;

&lt;blockquote&gt;
  &lt;p&gt;A user story is an abbreviated description of a feature of the system, told from the point of view of a user.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;So, we pick a story from the batch that we consider to be of average complexity. Then, we choose a number of points for the story. It is now our Golden Story. It is the standard against which all other stories will be compared.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;The iteration begins with the Iteration Planning Meeting (IPM). This meeting should be scheduled to be one-twentieth the duration of the iteration. The IPM for a two-week iteration should require about a half a day.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;观点总结：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;每个用户故事是一个需求的简短描述，简短到可以一眼看完，但是又能明白要解决&lt;strong&gt;用户&lt;/strong&gt;的什么问题。&lt;/li&gt;
  &lt;li&gt;在早期挑选一个平均复杂度的需求作为&lt;strong&gt;黄金故事&lt;/strong&gt;，也就是&lt;strong&gt;锚点&lt;/strong&gt;，&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

</description>
        <pubDate>Sun, 28 Jun 2020 08:15:00 +0800</pubDate>
        <link>http://0.0.0.0:4000/2020/06/28/reading-notes-clean-agile/</link>
        <guid isPermaLink="true">http://0.0.0.0:4000/2020/06/28/reading-notes-clean-agile/</guid>
        
        <category>Tech</category>
        
        <category>Agile</category>
        
        
      </item>
    
      <item>
        <title>On Premise Deployment Solution</title>
        <description>&lt;h2 id=&quot;前言&quot;&gt;前言&lt;/h2&gt;

&lt;p&gt;随着业务的快速发展，我们对私有化部署的流程上也发现不少可以优化改进的地方，今天主要和大家分享一下我们私有化部署方式的演进过程：
第一阶段：以脚本为核心的部署方式（docker文件 + 脚本 + 环境变量）
第二阶段：以 Jenkins 为核心的部署方式（docker文件 + jenkins + 配置文件）
第三阶段：以 Jenkins 和 docker harbor 为核心的部署方式（docker harbor + jenkins + 配置文件）&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;第一阶段&quot;&gt;第一阶段&lt;/h3&gt;

&lt;p&gt;在我们做第一个私有化部署的系统时，我们的系统架构相对简单，包含的需要部署的组件不超过10个。所以对于部署方案，我们的考虑是：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;能支持横向扩展。&lt;/li&gt;
  &lt;li&gt;能支持快速部署启动一个开发环境或者 debug 环境。&lt;/li&gt;
  &lt;li&gt;能支持快速部署一个新的客户环境。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;所以在第一阶段，我们的做法是用&lt;strong&gt;一个&lt;/strong&gt;很牛逼的脚本，一键启动所有组件。其中组件需要相互关联的部分，都通过变量设置在脚本中，从而避免参数设置不一致导致的部署问题，例如：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;DB_ENGINE=mysql
DB_HOST=192.168.0.3,192.168.0.4
DB_PORT=3306

# Start backend server
start_backend_server.sh -e db_host=$DB_HOST -e db_port=$DB_PORT

# Start async worker
start_async_worker.sh  -e db_host=$DB_HOST -e db_port=$DB_PORT

...
...
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;这个方案在我们只有一个产品的时候是非常方便的，操作步骤简单直接，且维护成本不高，也很灵活。&lt;/p&gt;

&lt;p&gt;但是随着公司的产品不断增多，需要进行复用的组件和工具也越来越多。例如两个产品的部署过程中，可能都会需要部署 redis、mysql、RabbitMQ，在每个项目中都放一个相同的 start_redis.sh 的脚本显然不是一个很好的方案，这样会导致后续对 redis 的版本升级或者参数调优无法在各个项目中应用。基于 &lt;strong&gt;DRY (Don’t Repeat Yourself)&lt;/strong&gt; 原则，我们开启了第二阶段的部署方案升级。&lt;/p&gt;

&lt;h3 id=&quot;第二阶段&quot;&gt;第二阶段&lt;/h3&gt;

&lt;p&gt;第二阶段主要是为了解决几个第一阶段的问题：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;脚本更新不及时。内部测试环境在更新部署的时候使用的是 k8s 集群，于是没有使用脚本进行部署。所以常常出现代码进行了修改，但是只更新了 k8s 的服务配置文件，没更新私有化部署脚本的问题。&lt;/li&gt;
  &lt;li&gt;使用方法和文档更新不及时。当某个组件的部署方式发生变更时，需要对应更新每一个产品的部署文档，常出现一个组件更新了，但是只更新了一个产品的文档，其他的就忘了。&lt;/li&gt;
  &lt;li&gt;脚本复用性差。随着产品的不断增多，每个产品都有一部分重复的基础组件的部署代码，这部分代码无法在产品间进行复用。&lt;/li&gt;
  &lt;li&gt;容错性差。当部署的过程中遇到错误时，在几百行 shell 代码中找到问题的难度大。&lt;/li&gt;
  &lt;li&gt;难以保证幂等性。shell 的编写对大部分人来说是一个过程性的编写方式，难以做到每个步骤都是幂等的，在执行脚本的过程中对执行者要求比较高，需要考虑重复执行脚本带来的副作用。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;针对这些问题，我们也考虑了几种不同的解决方案：&lt;/p&gt;

&lt;h4 id=&quot;备选1-使用docker编排引擎&quot;&gt;备选1: 使用docker编排引擎&lt;/h4&gt;

&lt;p&gt;使用 k8s 或者 docker swarm 进行容器的编排，用编排文件替代部署脚本。这个方案也是我们在内部测试环境中用的方案，方案的好处很明显：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;可以利用 k8s 的负载均衡完成集群内部的横向扩容，而不需要额外的负载均衡。&lt;/li&gt;
  &lt;li&gt;可以更充分地利用 k8s 的资源调度，最大程度利用宿主主机的资源。&lt;/li&gt;
  &lt;li&gt;可以使用声明式的配置方式，声明最终希望达成的状态，而由编排引擎来生成、执行相应的操作。同时可以对配置文件进行版本管理，达到 Configuration as Code 和 Infrastructure as Code 的方式。&lt;/li&gt;
  &lt;li&gt;可以保证在测试环境中的部署方式和私有化部署环境中一致，从而通过在测试过程中强制更新 k8s 保证代码和部署流程的一致性。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;除开业界已经认同的这些好处之外，也有一部分实际情况的制约：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;目前 k8s 集群的部署和维护在国内的金融和实体企业仍然是相对空白的，也缺少对该类技术的了解。&lt;/li&gt;
  &lt;li&gt;对于生产环境上使用的 k8s 集群，机构往往希望可以有专业的商业支持服务，包括但不限于证书的配置调试、集群的扩缩容、异构硬件的支持、性能问题的排查、网络问题的排查等。这个支持的成本和其带来的增益比还是不足以支撑这个方案的。&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;备选2-基于成熟工具的编排部署jenkins--ansible&quot;&gt;备选2: 基于成熟工具的编排部署（Jenkins + ansible）&lt;/h4&gt;

&lt;p&gt;为了解决上一个备选方案的制约，我们考虑以一个相对成熟的工具来实现类似的功能。此时我们考虑使用 Jenkins 来进行脚本的封装和管理，同时使用 ansible 和统一的配置文件来实现 k8s 能带给我们的好处。&lt;/p&gt;

&lt;h5 id=&quot;集群的灵活调度和横向扩容&quot;&gt;集群的灵活调度和横向扩容&lt;/h5&gt;

&lt;p&gt;为了实现灵活的集群内部的横向扩容，我们使用一个集中式的网关进行网络请求的转发，如下图：
&lt;a href=&quot;/img/in-post/on-premise-deployment/star_nginx.png&quot;&gt;&lt;img src=&quot;/img/in-post/on-premise-deployment/star_nginx.png&quot; alt=&quot;star_nginx.png&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;所有组件内部的请求访问都经过一个 Nginx 网关进行转发，这样如果我们需要对某个服务进行宿主主机的变更，或者需要增加额外的实例进行横向扩容，都可以在不更改其他服务配置的前提下进行。&lt;/p&gt;

&lt;h5 id=&quot;声明式的配置方式&quot;&gt;声明式的配置方式&lt;/h5&gt;

&lt;p&gt;为了能达到声明式的配置，我们将配置文件简化成了类似的格式：&lt;/p&gt;

&lt;p&gt;main.yaml:&lt;/p&gt;
&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;service1&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;redis&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;deploy_hosts&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;192.168.0.2&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;192.168.0.3&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;192.168.0.4&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;port&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;6379&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;memory_limit&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;1G&lt;/span&gt;

&lt;span class=&quot;na&quot;&gt;service2&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;mysql&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;deploy_hosts&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;192.168.0.2&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;port&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;3306&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;而我们的启动脚本也统一读取这个配置文件来知悉他依赖的组件部署在哪，应该通过哪个端口进行访问。这样以来，我们便实现了 SSOT (Single Source of Truth)，不会出现迁移修改组件后，依赖其的服务无法使用的情况。运维同学在看到这个配置文件之后，也可以很直观地看出来每个服务运行在哪、有什么参数配置。&lt;/p&gt;

&lt;p&gt;同时我们把启动脚本转换成了一个 Ansible 的脚本。Ansible 的一个特点便是声明式、可复用。我们的 Ansible 脚本从 main.yaml 中读取服务希望达到的状态后，会进行所有相关的操作，包括生成配置文件、拉取最新的 docker、启动 docker、检测是否需要初始化数据、检测服务状态符合预期等。这样一来，我们也实现了 Configuration as Code 和 Infrastructure as Code 的部署方式。&lt;/p&gt;

&lt;h5 id=&quot;界面化的封装&quot;&gt;界面化的封装&lt;/h5&gt;

&lt;p&gt;如果要迁移至 Ansible 和配置文件的这个方案，就必须要解决测试环境的问题，我们希望这个部署方案是和开发、测试的部署方法一致的，这样才能保证部署流程和代码的一致性。在这个基础上，为了简化研发的使用，我们对 Ansible 的脚本和配置文件用 Jenkins 进行了封装。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/img/in-post/on-premise-deployment/jenkins_deploy.png&quot;&gt;&lt;img src=&quot;/img/in-post/on-premise-deployment/jenkins_deploy.png&quot; alt=&quot;jenkins_deploy.png&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;在一个 docker 包中包含了：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Jenkins 的所有所需插件和配置，例如每个任务需要调用哪个ansible脚本，每个任务需要触发哪些依赖的任务&lt;/li&gt;
  &lt;li&gt;所有的 Ansible 部署脚本&lt;/li&gt;
  &lt;li&gt;默认的配置文件&lt;/li&gt;
  &lt;li&gt;部署需要用到的工具包，例如 ssh、ansible、openssl 等。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&quot;/img/in-post/on-premise-deployment/jenkins_view.png&quot;&gt;&lt;img src=&quot;/img/in-post/on-premise-deployment/jenkins_view.png&quot; alt=&quot;jenkins_view.png&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;这样一来也大大减少了运维可能出错的操作步骤，同时对于一套标准系统的部署时间也可以减少到小时级别。甚至内部的测试环境部署可以在30分钟内完成，为后续的自动化测试打下基础。&lt;/p&gt;

&lt;h5 id=&quot;公共组件封装&quot;&gt;公共组件封装&lt;/h5&gt;

&lt;p&gt;我们最终选择了方案二（Jenkins + Ansible）作为我们的解决方案，我们把内部所有需要进行私有化部署的系统都迁移到了基于 Jenkins 的部署系统上。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/img/in-post/on-premise-deployment/jenkins_component.png&quot;&gt;&lt;img src=&quot;/img/in-post/on-premise-deployment/jenkins_component.png&quot; alt=&quot;jenkins_component.png&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;对于常用的公共组件包括储存组件：redis、mysql、oracle、elasticsearch、minio 等，所有产品都可以遵循最佳实践进行部署复用。而对于部分业务中间件，例如文档解析、NLP提取、格式转换等服务，所有产品也可以快速接入使用。&lt;/p&gt;

&lt;p&gt;值得一提的是，其他的日志、指标采集、监控告警、看板等功能，也成了整个私有化部署架构中的共享组件，赋能保证了产品的稳定性和可运维性。&lt;/p&gt;

&lt;h5 id=&quot;不足之处&quot;&gt;不足之处&lt;/h5&gt;

&lt;p&gt;在这套方案中，仍有几个细节点是待改善的：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;部署工具本身的版本管理。Jenkins 和部署脚本的内容是会随着产品的迭代而变化的，例如一个月前的产品使用的是 Elasticsearch 6.8，目前的产品使用的是 Elasticsearch 7.6，这时产品的升级过程中，就需要对部署脚本做一定修改，如果使用了错误的部署工具，可能会导致部署的产品出错。&lt;/li&gt;
  &lt;li&gt;docker 镜像文件的传输和管理。由于在私有化部署的环境中，有许多环境是完全不能接入外网的，所以我们的 docker 是通过 &lt;code class=&quot;highlighter-rouge&quot;&gt;docker save -o xxx.tar &amp;lt;image&amp;gt;&lt;/code&gt; 进行导出，然后将 tar 文件通过 jenkins 下载、拷贝、并加载到目标服务器上的。如果能接入外网，就直接从一个 http 服务器下载并加载镜像文件。
    &lt;ul&gt;
      &lt;li&gt;这个方案的第一个问题是 docker 的版本号不好管理。因为对于 tar 文件的每个版本都归档会造成巨大的储存资源的压力，每个版本都保存下来的话，对于一个集成了 CI/CD 的产品，每天会产生10余个部署文件，无疑是一个浪费。&lt;/li&gt;
      &lt;li&gt;第二个问题是更新时较慢。每次更新代码时，及时只更新一行代码，可能也需要下载1G的 docker 文件，导致在私有化环境中更新速度很慢。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;第三阶段&quot;&gt;第三阶段&lt;/h3&gt;

&lt;p&gt;针对第二阶段的一些不足之处，我们也做了更进一步的优化：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;除了使用 docker 文件进行打包和传输，我们也引入了私有化 docker 镜像仓库进行 docker 包的管理。利用 docker 镜像仓库本身的 TAG 功能进行多版本的归档。由于 docker 包的重复文件层不会重复储存，所以可以支持对所有产品版本的归档储存。&lt;/li&gt;
  &lt;li&gt;对于部署工具本身，也同时加入 docker 的镜像仓库中，用 TAG 进行多版本的归档管理，每次部署时，要求部署工具和代码包的版本作为一个统一整体进行部署。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;三阶段的改动相对于第二阶段并不算大，主要工作是：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;将相关 docker 的打包 CI 任务中，增加推送到 docker 的镜像仓库的配置。&lt;/li&gt;
  &lt;li&gt;在默认配置文件当中，原本的 image: 配置字段设置为基于镜像仓库的地址&lt;/li&gt;
  &lt;li&gt;在 ansible 的启动脚本的 docker_container 模块中，增加 pull 选项的配置，决定是否在重启的时候拉取最新的镜像。这一步是相对 tricky 的，因为我们仍然要兼容不能访问私有化镜像仓库的环境，这些环境中 pull 需要设置为 false，而其他环境需要设置为 true。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;总结&quot;&gt;总结&lt;/h3&gt;

&lt;p&gt;我们希望在满足 DRY（Don’t Repeat Yourself）、SSOT (Single Source of Truth)、CaC（Configuration as Code）、IaC（Infrastructure as Code）的原则基础上，尽量简化和自动化部署流程。虽然在实际项目中推广 k8s 的使用遇到了一些困难，但是我们仍然曲线救国，利用老将 Jenkins 和 Ansible 达到了目的。&lt;/p&gt;

</description>
        <pubDate>Sat, 23 May 2020 08:15:00 +0800</pubDate>
        <link>http://0.0.0.0:4000/2020/05/23/on-premise-deployment-solution-change-v3/</link>
        <guid isPermaLink="true">http://0.0.0.0:4000/2020/05/23/on-premise-deployment-solution-change-v3/</guid>
        
        <category>Tech</category>
        
        <category>Deployment</category>
        
        
      </item>
    
      <item>
        <title>Tech Team Management Note</title>
        <description>&lt;h1 id=&quot;整体思路&quot;&gt;整体思路&lt;/h1&gt;
&lt;ol&gt;
  &lt;li&gt;每个人需求不同，单独沟通并在管理过程中尽量满足。需求包括：
    &lt;ul&gt;
      &lt;li&gt;职业发展需求&lt;/li&gt;
      &lt;li&gt;经济需求（薪资、奖金、期权）&lt;/li&gt;
      &lt;li&gt;个人成就需求&lt;/li&gt;
      &lt;li&gt;社会地位需求（办公环境、公司地位、公司福利）&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;以激发团队的主观能动性为主，以被动监督团队成员为辅。&lt;/li&gt;
  &lt;li&gt;公平交换。每个人只要有付出就有回报，同时相互理解，公司在个人遇到困难时给予灵活的支持和政策，个人在公司项目需要时额外加班或者做其他贡献。&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;具体措施&quot;&gt;具体措施&lt;/h1&gt;
&lt;h2 id=&quot;目标设定&quot;&gt;目标设定&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;设置跳一跳能够到的目标，不要太容易达到，也不要不切实际
 	- 研发：时间、难度、质量、工作量
 	- 测试：质量、工作量
 	- 产品、UI：质量、沟通效果、工作量&lt;/li&gt;
  &lt;li&gt;每个人的状态会波动，很正常。长期来看，保持相对紧凑，但是可完成的目标才是产能的最大化。对于每一个阶段的超额或者未达标可以给予一定反馈，但是不需要太夸张。&lt;/li&gt;
  &lt;li&gt;以能稳定完成，可预期为第一目标。如果无法预期结果，则无法保证项目的如期交付。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;目标评估&quot;&gt;目标评估&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;能直接评估的目标才有意义，如果没法评估的目标就只是个口号。&lt;/li&gt;
  &lt;li&gt;工作量由研发自己评估，自己估的同时，也作为一个 commitment，一个承诺。&lt;/li&gt;
  &lt;li&gt;工作质量由同事的代码审核和整体项目的结果评估。&lt;/li&gt;
  &lt;li&gt;沟通效果由同事之间的调查或者吐槽来评估。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;激励&quot;&gt;激励&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;激励越及时越好。&lt;/li&gt;
  &lt;li&gt;当员工付出了超额的努力，就需要有正反馈，结果未必好，但是如果没有正反馈，就不会有下一次努力。&lt;/li&gt;
  &lt;li&gt;多维度激励本质是提高激励的频率，拆得更细，让大家觉得自己的付出是被认可的。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;惩罚&quot;&gt;惩罚&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;惩罚越及时越好&lt;/li&gt;
  &lt;li&gt;惩罚由于主观原因导致的目的不达标。&lt;/li&gt;
  &lt;li&gt;口头批评但是不惩罚由于客观原因的不达标。&lt;/li&gt;
  &lt;li&gt;惩罚或者口头批评的同时给出提升的路径。&lt;/li&gt;
  &lt;li&gt;提升之后给予正反馈，口头或者物质都可以。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;背景沟通&quot;&gt;背景沟通&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;做的事情，为什么要做这个项目，为什么要做这个需求，做完之后效果如何，了解了背景才能在细节作出最利于整个项目的抉择。&lt;/li&gt;
  &lt;li&gt;对外的人做团队的信息过滤器，传递给团队之前先想一下，对团队有正面还是负面效果。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;知识沉淀和分享&quot;&gt;知识沉淀和分享&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;技术成就感的来源之一，项目一定会遇到难题，再简单的项目也有难题，解决之后能分享出来就会让人有一定成就感。&lt;/li&gt;
  &lt;li&gt;技术能力评估的重要来源之一。高级工程师必须要给团队带来提升，是高级工程师的一个 must。&lt;/li&gt;
  &lt;li&gt;团队认可度的重要来源之一，让团队其他成员觉得我们的团队是一个牛逼的团队。&lt;/li&gt;
  &lt;li&gt;应该要对知识分享的行为给予奖励。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;其他制度设定&quot;&gt;其他制度设定&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;在家办公制度是独特优势，在满足目标作为评估点的前提下，可以很大程度上吸引优秀人才加入团队。&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Fri, 24 Apr 2020 08:15:00 +0800</pubDate>
        <link>http://0.0.0.0:4000/2020/04/24/tech-management-notes/</link>
        <guid isPermaLink="true">http://0.0.0.0:4000/2020/04/24/tech-management-notes/</guid>
        
        <category>Tech</category>
        
        <category>Management</category>
        
        
      </item>
    
      <item>
        <title>直觉（Cover）</title>
        <description>&lt;blockquote&gt;
  &lt;p&gt;“我喜欢你的眼睛你的睫毛你的侧脸，喜欢你嘟着嘴巴说教我吐烟圈。”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;video width=&quot;100%&quot; poster=&quot;/img/in-post/cover/zhijue.jpg&quot; controls=&quot;&quot; preload=&quot;none&quot; type=&quot;video/mp4&quot;&gt;  
&lt;source src=&quot;http://video.chendi.me/videos/20200111-zhijue.mp4&quot; /&gt;  
&lt;/video&gt;

&lt;p&gt;喜欢歌词，单曲循环了好多遍，就想试着录一下了。
第一次还是有点紧张。&lt;/p&gt;
</description>
        <pubDate>Tue, 21 Jan 2020 04:15:00 +0800</pubDate>
        <link>http://0.0.0.0:4000/2020/01/21/zhijue-recording-studio/</link>
        <guid isPermaLink="true">http://0.0.0.0:4000/2020/01/21/zhijue-recording-studio/</guid>
        
        <category>生活</category>
        
        <category>Cover</category>
        
        
      </item>
    
      <item>
        <title>On premise log and metric collection</title>
        <description>&lt;h2 id=&quot;前言&quot;&gt;前言&lt;/h2&gt;

&lt;p&gt;在私有化部署的系统中，系统可能会多次进行分布式组件的部署，而在私有化部署的环境中，可能没有完善的日志收集、指标收集和分析的工具，为了能便捷地进行日志、指标的收集和分析，这里提出一个简单的可复制的 ELK 日志、指标收集方案。&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;背景&quot;&gt;背景&lt;/h2&gt;

&lt;p&gt;在当前的项目中，我们已经使用了 Elasticsearch 作为业务的数据储存，同时利用 ansible、docker、jenkins 组合了一套快速部署的工具。在配置好需要部署主机的 ssh 连接信息后，我们可以通过 jenkins 一键部署一个 Elasticsearch 和 Kibana。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/img/in-post/on-premise-log-metric-collection/jenkins.png&quot;&gt;&lt;img src=&quot;/img/in-post/on-premise-log-metric-collection/jenkins.png&quot; alt=&quot;jenkins.png&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;这套系统遵循以下的设计原则：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Self-Contained Deployment：我们把所有的部署脚本、配置文件、Jenkins 任务都打包到一个标准化的 Jenkins docker 包中，只要安装到目标的环境上，即可把所有部署所需的工具都一次性带入。&lt;/li&gt;
  &lt;li&gt;Single Source of Truth：在 Jenkins 中内嵌一个 yaml 格式的配置文件管理器，对于所有部署需要依赖的变量进行统一管理，例如xx系统后端对外暴露的端口号，只在 Jenkins 中配置一次，所有的脚本都会自动读取该变量。&lt;/li&gt;
  &lt;li&gt;Configuration as Code, Infrastructure as Code：当所有的配置确定下来后，后续的流程理论上是可以做到全自动化的，所以所有的安装都通过脚本来完成。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;需求分析&quot;&gt;需求分析&lt;/h3&gt;

&lt;p&gt;在私有化部署的环境中，日志的收集使用有几个特点：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;需要能快速部署。由于客户的数量较多，我们需要能快速地部署监控系统，监控系统本身的运维压力需要较小。&lt;/li&gt;
  &lt;li&gt;部署组件要简单，且健壮性强。由于部署环境较为复杂，希望每个组件自身是健壮的，同时组件之间的交互尽量简单，避免复杂的网络拓扑。&lt;/li&gt;
  &lt;li&gt;功能性优于稳定性。由于日志和指标信息本身在宿主主机和应用上是有副本的，所以即时监控系统的数据丢失了，影响也不大。但是如果系统能提供更多强大的功能，对于分析是很有帮助的。&lt;/li&gt;
  &lt;li&gt;性能要求不高。由于私有化环境对接系统的容量和复杂度可控，可以使用单机部署，同时查询慢一些也没关系。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;同时需要满足几个需求：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;需要能采集分布式的日志，并且集中式地查看&lt;/li&gt;
  &lt;li&gt;需要能采集机器的基本信息，例如 CPU、磁盘，并进行监控&lt;/li&gt;
  &lt;li&gt;最好能采集应用的数据，例如导入数据的条目数，并进行监控&lt;/li&gt;
  &lt;li&gt;最好能实现异常指标的告警功能&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;方案分析&quot;&gt;方案分析&lt;/h3&gt;

&lt;p&gt;方案上有3个备选方案：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;利用 ELK （Elasticsearch、Logstash、Kibana） 做整体的监控基础组件，同时使用 Elastic 新推出的 beat 系列作为采集工具。
&lt;a href=&quot;/img/in-post/on-premise-log-metric-collection/dashboard1.png&quot;&gt;&lt;img src=&quot;/img/in-post/on-premise-log-metric-collection/dashboard1.png&quot; alt=&quot;dashboard1.png&quot; /&gt;&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;利用 Zabbix、Open-Falcon 等运维监控工具进行系统基础组件的监控。同时利用自定义指标，进行数据的监控和告警。
&lt;a href=&quot;/img/in-post/on-premise-log-metric-collection/zabbix.png&quot;&gt;&lt;img src=&quot;/img/in-post/on-premise-log-metric-collection/zabbix.png&quot; alt=&quot;zabbix.png&quot; /&gt;&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;利用 TICK (Telegraph、InfluxDB、Chronograf、Kapacitor) 做整体的监控基础组件。
&lt;a href=&quot;/img/in-post/on-premise-log-metric-collection/grafana.jpg&quot;&gt;&lt;img src=&quot;/img/in-post/on-premise-log-metric-collection/grafana.jpg&quot; alt=&quot;grafana.jpg&quot; /&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;方案2和3在需求上不能很好满足日志的收集和查看功能，所以排除掉了，目前日志方面能比较好满足需求的只有开源的 ELK 和商业化的 Splunk，由于预算原因，Splunk 也被排除了。&lt;/p&gt;

&lt;p&gt;方案1(ELK)根据我们的需求进一步细化：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;需要能快速部署：通过我们的 Jenkins 可以实现一键部署的功能。&lt;/li&gt;
  &lt;li&gt;部署组件简单：我们只部署 Elasticsearch 和 Kibana 组件，同时 Elasticsearch 本身作为最基础的组件是自包含的，不依赖任何外部组件。而我们也不使用集群，只用单机部署，保证 Elasticsearch 部署的简单和稳定。&lt;/li&gt;
  &lt;li&gt;功能性优于稳定性：虽然业务使用的 Elasticsearch 停留在 5.5.3 版本，我们日志采集和分析使用的 Elasticsearch 直接升级到 7.6.0 版本，同时后续的版本升级也可以较为激进，如果遇到不兼容的情况，也不需要保留已有数据，删除数据重新部署即可。&lt;/li&gt;
  &lt;li&gt;性能要求不高：使用单机部署，Elasticsearch 和 Kibana 部署在同一台机器上。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;日志专用的elasticsearchkibanabeat&quot;&gt;日志专用的Elasticsearch、Kibana、Beat&lt;/h3&gt;

&lt;p&gt;为了避免日志使用的 ES 和业务使用的 ES 在资源或者配置上发生冲突，日志专用的 ES 单独做了一个部署，使用约 3G 内存。&lt;/p&gt;

&lt;p&gt;日志采集：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;我们在所有相关主机上使用 ansible 部署&lt;a href=&quot;https://www.elastic.co/beats/filebeat&quot;&gt;filebeat&lt;/a&gt; 进行日志的采集，为了简化系统，我们也没有使用 logstash 做日志的预处理，只是简单地配置了 filebeat 的配置文件，并加入了我们的 jenkins 一键部署套件中。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;日志的查看：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;由于日志直接通过 filebeat 收集到了 es 中，我们使用 Kibana 就能直接进行查看了。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&quot;/img/in-post/on-premise-log-metric-collection/filebeat.gif&quot;&gt;&lt;img src=&quot;/img/in-post/on-premise-log-metric-collection/filebeat.gif&quot; alt=&quot;filebeat.gif&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;系统指标收集：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;我们在所有相关主机上使用 ansible 部署 &lt;a href=&quot;https://www.elastic.co/beats/metricbeat&quot;&gt;metricbeat&lt;/a&gt; 进行指标的收集，通过配置文件的配置，可以采集到 docker 的资源使用、系统CPU、内存、磁盘、网络的使用状态，同时也开放了 statsd 格式的指标收集端口。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&quot;/img/in-post/on-premise-log-metric-collection/metricbeat.jpg&quot;&gt;&lt;img src=&quot;/img/in-post/on-premise-log-metric-collection/metricbeat.jpg&quot; alt=&quot;metricbeat.jpg&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;在现场状态检测：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;我们在网关机器上使用 ansible 部署 &lt;a href=&quot;https://www.elastic.co/beats/heartbeat&quot;&gt;heartbeat&lt;/a&gt; 进行主动的资源可用性探测，对系统相关的数据库、http服务等监控其相应状态，并将其发送至默认的 ES 储存索引中。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&quot;/img/in-post/on-premise-log-metric-collection/heartbeat.png&quot;&gt;&lt;img src=&quot;/img/in-post/on-premise-log-metric-collection/heartbeat.png&quot; alt=&quot;heartbeat.png&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;基于es的告警&quot;&gt;基于ES的告警&lt;/h3&gt;

&lt;p&gt;Elasticsearch 的告警是付费功能，所以这里用了一个开源的项目 &lt;a href=&quot;https://elastalert.readthedocs.io/en/latest/&quot;&gt;elastalert&lt;/a&gt; 实现告警。Elastalert 是 Yelp 公司（美国的大众点评）开发的基于 python 和 Elasticsearch 的告警系统，可以对接的告警途径很多，但是大部分都是国外的工具例如Slack、HipChat、PagerDuty，所以我们目前只使用了最基础的邮件告警功能。&lt;/p&gt;

&lt;p&gt;Elastalert 可以配置多种告警类型，例如&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;某条件连续触发 N 次（frequency类型）&lt;/li&gt;
  &lt;li&gt;某指标出现的频率增加或者减少（spike 类型）&lt;/li&gt;
  &lt;li&gt;N 分钟未检测到某指标（flatline类型）等。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;每个告警的配置核心其实是一个 elasticsearch 的查询语句，通过查询语句返回的条目数来进行判断。&lt;/p&gt;

&lt;p&gt;目前我们也只使用了最基础的 frequency 类型告警。由于这个告警是针对特定几个私有化部署的系统，所以我们提前配置好了若干个告警的配置文件，在部署脚本中，如果没有特别需求，就全部复制到 elastalert 的系统中，不需要任何手工配置。&lt;/p&gt;

&lt;h3 id=&quot;监控大盘&quot;&gt;监控大盘&lt;/h3&gt;

&lt;p&gt;利用 Kibana 的可视化功能，我们可以针对每个业务系统创建一个监控大盘，直观地看到所有系统组件的情况，以及宿主主机的健康情况：&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/img/in-post/on-premise-log-metric-collection/dashboard1.png&quot;&gt;&lt;img src=&quot;/img/in-post/on-premise-log-metric-collection/dashboard1.png&quot; alt=&quot;dashboard1.png&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/img/in-post/on-premise-log-metric-collection/dashboard2.png&quot;&gt;&lt;img src=&quot;/img/in-post/on-premise-log-metric-collection/dashboard2.png&quot; alt=&quot;dashboard2.png&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/img/in-post/on-premise-log-metric-collection/dashboard3.png&quot;&gt;&lt;img src=&quot;/img/in-post/on-premise-log-metric-collection/dashboard3.png&quot; alt=&quot;dashboard3.png&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h4 id=&quot;kibana配置自动化&quot;&gt;Kibana配置自动化&lt;/h4&gt;
&lt;p&gt;Kibana 当中所有持久化了的配置都是一个 &lt;a href=&quot;https://www.elastic.co/guide/en/kibana/current/managing-saved-objects.html&quot;&gt;Saved Object&lt;/a&gt;，包括：快捷搜索、监控大盘、可视化面板、索引配置。&lt;/p&gt;

&lt;p&gt;我们在内部的测试环境中配置好了一个监控用的 Kibana 后，将配置文件通过 CI 系统定期导出储存于 git 仓库中，下一次更新基础组件时，更新脚本就会自动将对应的 kibana 配置导入到私有化部署的环境中，在部署时不需要任何手工配置，实现 Infrastructure as Code。&lt;/p&gt;

&lt;h3 id=&quot;扩展监控范围&quot;&gt;扩展监控范围&lt;/h3&gt;
&lt;p&gt;这套部署组件在扩展上也是有一个标准流程的。&lt;/p&gt;

&lt;h4 id=&quot;监控更多的应用组件&quot;&gt;监控更多的应用组件&lt;/h4&gt;
&lt;p&gt;当我们需要监控新增的应用组件时。&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;对于服务状态，我们可以简单地将应用组件的访问地址加入 hearbeat 的配置中，就可以在监控面板看到对应组件的状态了。&lt;/li&gt;
  &lt;li&gt;对于应用日志，我们可以将日志的文件路径加入 filebeat 的配置中，就可以在 Kibana 中搜索到了。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;监控应用相关的指标&quot;&gt;监控应用相关的指标&lt;/h4&gt;
&lt;p&gt;当我们需要监控应用相关的指标时，我们可以通过 statsd 的接口，将指标发布至 metricbeat，统一收集至 Elasticsearch 当中。 statsd 底层规则相对简单，所以在每个编程语言中都有相应的 SDK 可以直接使用，并没有复杂的依赖： &lt;a href=&quot;https://github.com/statsd/statsd/wiki&quot;&gt;https://github.com/statsd/statsd/wiki&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;但是目前 metricbeat 收集来的 statsd 信息是不支持 tag 的，所以还只能做一些简单的指标收集，并不能对同一指标的不同维度做聚合分析。&lt;/strong&gt;&lt;/p&gt;

&lt;h4 id=&quot;增加服务-tracing&quot;&gt;增加服务 tracing&lt;/h4&gt;
&lt;p&gt;Elasticsearch 当中也带了 APM 服务 &lt;a href=&quot;/img/in-post/on-premise-log-metric-collection/tracing.png&quot;&gt;&lt;img src=&quot;/img/in-post/on-premise-log-metric-collection/tracing.png&quot; alt=&quot;tracing.png&quot; /&gt;&lt;/a&gt; 这个暂时还没有尝试接入，如果可以使用的话，是一个性能监控和分析的利器。&lt;/p&gt;

&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;
&lt;p&gt;私有化部署的环境中，日志的收集和监控不像互联网产品一样需要较强的性能和可扩容性，开箱即用和功能的强大就较为重要。7.6.0 版本的 Elasticsearch 和 Kibana 在这方面能很好地满足需求，只需要对部署流程进行标准化，并提前准备好配置文件，就可以在半小时内搭建好一整套监控体系。&lt;/p&gt;
</description>
        <pubDate>Tue, 03 Dec 2019 08:15:00 +0800</pubDate>
        <link>http://0.0.0.0:4000/2019/12/03/on-premise-log-metric-collection/</link>
        <guid isPermaLink="true">http://0.0.0.0:4000/2019/12/03/on-premise-log-metric-collection/</guid>
        
        <category>Tech</category>
        
        <category>ELK</category>
        
        
      </item>
    
      <item>
        <title>Performance Optimization</title>
        <description>&lt;h2 id=&quot;前言&quot;&gt;前言&lt;/h2&gt;

&lt;p&gt;在工作中发现关于性能优化相关的工作，大部分人都较少涉猎，也缺少相关的经验，所以把我的经验记录下来，抛砖引玉。&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;需求&quot;&gt;需求&lt;/h2&gt;

&lt;h3 id=&quot;性能需求&quot;&gt;性能需求&lt;/h3&gt;

&lt;p&gt;在一个系统运行的过程中，遇到性能上的需求无法满足是非常常见的。例如：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;一个 HTTP 服务器的某个请求响应时间过长。&lt;/li&gt;
  &lt;li&gt;一个消息队列同时可以发送、储存的消息数量不足。&lt;/li&gt;
  &lt;li&gt;一个脚本的执行时间过长。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;高性能往往可以具体拆解为低延迟和高吞吐量。只不过对于每个系统来说，低延迟和高吞吐量的衡量标准有所不同。在开始进行性能优化之前，我们先要确定需要优化的是什么。&lt;/p&gt;

&lt;h3 id=&quot;性能优化思路&quot;&gt;性能优化思路&lt;/h3&gt;

&lt;p&gt;对于大部分的系统来说，性能优化都可以拆解为几个通用步骤：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;性能测量。针对需要优化的系统，确认一个可重复、可测量的指标作为性能的衡量标准。优化目标就是将该指标增大或者减小。&lt;/li&gt;
  &lt;li&gt;性能分析。针对我们需要优化的系统，分析系统完成特定任务时进行过的操作，以及各操作所消耗的时间、资源。&lt;/li&gt;
  &lt;li&gt;尝试优化方案。根据上一步得到的信息，进行理论上的分析，找到可以进行优化的方案，并尝试实施对应方案。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;a href=&quot;/img/in-post/performance-optimization/performance-optimization-progress.png&quot;&gt;&lt;img src=&quot;/img/in-post/performance-optimization/performance-optimization-progress.png&quot; alt=&quot;performance-optimization-progress.png&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;下面我抛出3个常见的优化场景，并且举几个例子说明怎样将这个优化思路落地：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;低延迟优化：有一个 Django 服务的某个请求响应时间过长，需要 3 秒左右返回。&lt;/li&gt;
  &lt;li&gt;高吞吐量优化：有一个消息队列同时可以发送的消息数为 5000 条/秒，需要能达到 50000 条/秒。&lt;/li&gt;
  &lt;li&gt;低延迟优化：有一个 python 脚本的执行时间过长，需要 20 分钟完成。&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;性能的衡量标准&quot;&gt;性能的衡量标准&lt;/h4&gt;

&lt;p&gt;对于低延迟的系统，衡量标准就是时间，在完成某个特定任务的情况下，衡量每个任务的完成时间。在衡量时需要尽量保证可重复、可测量。&lt;/p&gt;

&lt;p&gt;可重复：对于许多系统的优化任务来说，不符合需求的性能场景可能无法稳定复现，例如响应时间过长的问题不是每个请求都会出现。那么我们的第一件事是找到复现这个响应时间过长的情况。因为如果响应时间过长的问题不是稳定出现的话，做出来的性能分析也不是针对出问题的场景，那我们就没办法进一步做性能分析了。如果系统的表现不稳定的话，可以尝试将衡量的组件范围减少，当每次执行任务的时候涉及的组件、模块、功能越少，则表现也就相对会越稳定。&lt;/p&gt;

&lt;p&gt;可测量：对于系统优化的任务，一定要有一个可测量的指标用于衡量性能。如果不能测量，只是靠感觉的话，那优化任务就没有一个尽头了。所以一定要有一个可测量的指标，用于衡量优化的效果。&lt;/p&gt;

&lt;h4 id=&quot;性能的分析方法&quot;&gt;性能的分析方法&lt;/h4&gt;

&lt;p&gt;性能的分析主要目的是：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;对于延迟类的性能需求，找到时间花在哪了。&lt;/li&gt;
  &lt;li&gt;对于吞吐量的性能需求，找到当吞吐量达到最大值时，同时达到瓶颈的资源。这个瓶颈可能是网络带宽、磁盘 IO、端口数等等。&lt;/li&gt;
&lt;/ol&gt;

&lt;h5 id=&quot;系统延迟的分析&quot;&gt;系统延迟的分析&lt;/h5&gt;

&lt;p&gt;当我们要分析时间花在哪的时候，首先尽量把任务隔离成单线程/单进程任务，对每个线性处理流程分析完毕后，再进行多线程/多进程的分析，这样可以隔离分析的复杂度。&lt;/p&gt;

&lt;h6 id=&quot;线性系统的profiling&quot;&gt;线性系统的Profiling&lt;/h6&gt;

&lt;p&gt;要找时间花在哪时，一定会用到 Profile。Profile 的意思是测量，测量一段代码的时间使用/内存使用/IO使用情况。对于每个系统，Profile 的方法会有所区别。这里拿代码的执行时间使用的 Profile 做例子。&lt;/p&gt;

&lt;p&gt;对于一段 Python 代码，常用的工具可以用 cProfile，cProfile 内置在 Python 的标准库中，可以将每个方法调用所消耗的时间记录下来：&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;err&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;python3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cProfile&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cumtime&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_smtp&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;py&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;less&lt;/span&gt;

&lt;span class=&quot;p&quot;&gt;{}&lt;/span&gt;
         &lt;span class=&quot;mi&quot;&gt;36884&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;function&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;calls&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;35925&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;primitive&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;calls&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.438&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seconds&lt;/span&gt;

   &lt;span class=&quot;n&quot;&gt;Ordered&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;by&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cumulative&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;

   &lt;span class=&quot;n&quot;&gt;ncalls&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;tottime&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;percall&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;cumtime&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;percall&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lineno&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
     &lt;span class=&quot;mi&quot;&gt;52&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;0.003&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;0.000&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;0.438&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;0.438&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;built&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;method&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;builtins&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;exec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;0.000&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;0.000&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;0.438&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;0.438&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_smtp&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;py&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;module&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;0.000&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;0.000&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;0.237&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;0.034&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;smtplib&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;py&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;369&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;getreply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
       &lt;span class=&quot;mi&quot;&gt;12&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;0.000&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;0.000&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;0.237&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;0.020&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;method&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'readline'&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'_io.BufferedReader'&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;objects&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;0.000&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;0.000&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;0.237&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;0.034&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;socket&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;py&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;572&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;readinto&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;0.000&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;0.000&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;0.237&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;0.034&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ssl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;py&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1001&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;recv_into&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;0.000&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;0.000&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;0.237&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;0.034&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ssl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;py&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;866&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;上面的这个信息也可以导出一个文件后，通过第三方的画图工具，画成一个火焰图，火焰图可以更直观地对每个函数之间的调用关系和耗时进行下钻分析。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/img/in-post/performance-optimization/flame_graph.png&quot;&gt;&lt;img src=&quot;/img/in-post/performance-optimization/flame_graph.png&quot; alt=&quot;flame_graph.png&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;同理，对于 java、c++ 可以用 VTune 之类的工具，在执行代码的同时记录每个函数的执行时间。在 Google 上搜索 语言 + profile 一般就可以找到适合的分析器了&lt;/p&gt;

&lt;p&gt;在看到了每个函数的执行时间之后，我们分析可优化的点就可以按照几个思路来推进：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;分析耗时最长的部分。由于我们能看到每个部分的耗时，从耗时最长的部分一层层往下找，看是否有可以优化的地方。&lt;/li&gt;
  &lt;li&gt;分析耗时是否合理。分析耗时的合理性时，要从两方面分析，
    &lt;ul&gt;
      &lt;li&gt;整体执行的代码内容是否合理，是否调用了不需要调用的代码。例如在一个循环内不断调用 SQL 查询语句，是一个常见的不该出现的情况，在使用 ORM 时，如果没注意联合查询的使用，会导致调用大量的 SQL 从而拖慢整体速度。或者在一个循环内不断出现 fetch_many 的数据库调用，可能是查询时拉取了文本或者 glob 字段的内容，导致每个批次数据拉取速度比较慢。&lt;/li&gt;
      &lt;li&gt;代码内每个步骤的时间是否合理。有一部分操作可能在代码的 profile 上看不出细节，例如将一个文本类型的时间转为时间对象，在格式不确定的情况下需要穷举可能匹配的格式（YYYY-DD-MM 或者 YYYY-MM-DD)，会耗时很长 ～200ms。但是在格式确定的情况下，通过正则或者原声的 strptime 这类方法，可以利用正则状态机的方法，实现 O(1) 的转换时间，约 ～1ms。或者例如一个看起来简单的 sql 的执行可能花了10秒的时间，但是从代码的 profile 上看不出为什么花了10秒的时间。此时就可以用 sql 的 profile 分析器去查看 sql 执行的每个步骤所花的时间。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;代码执行的逻辑是否可以优化。例如 O(n^2) 的代码是否可以通过缓存简化为 O(n)。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;对于 SQL 语句的性能分析，我们可以使用 SQL 分析器，也叫 sql 解释器，在 Google 上搜索 具体的数据库 + “sql analyzer” 一般就可以找到适合的工具了。&lt;/p&gt;

&lt;p&gt;SQL 分析器可以把 sql 语句的执行过程拆解为在数据库端的索引查询、原文提取等步骤，利用这个信息，我们可以进一步分析数据库端，整体时间消耗在了哪，例如是不是有缺少索引导致的全表扫描，或者缺少联合索引导致的大数据量的 join。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/img/in-post/performance-optimization/sql_analyzer.png&quot;&gt;&lt;img src=&quot;/img/in-post/performance-optimization/sql_analyzer.png&quot; alt=&quot;sql&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;同理，对于 Elasticsearch 等 NoSQL 数据库，也可以利用 Kibana 中的 Profile 工具，查看 Elasticsearch 搜索时底层的耗时，从而判断可以进行优化的点。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/img/in-post/performance-optimization/es_profile.png&quot;&gt;&lt;img src=&quot;/img/in-post/performance-optimization/es_profile.png&quot; alt=&quot;es_profile&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;对于一些较复杂的问题，可能会涉及到更低层的 profiling，例如我们发现某个文件的读写花的时间比预期长，那我们可以使用 strace 对每个 system call 的耗时进行 profile，例如 open, fstat 等。或者我们发现某个 tcp 连接的耗时较长，那我们可以使用 tcpdump 对 tcp 的三次握手包进行抓包，通过在不同节点进行抓包，可以找到网络请求慢的节点，从而进一步分析。&lt;/p&gt;

&lt;h6 id=&quot;django的在线性能分析&quot;&gt;Django的在线性能分析&lt;/h6&gt;

&lt;p&gt;针对目前公司内使用的 Django 框架，可以使用 silk 库进行性能分析。由于性能分析需要测量并记录大量数据，会极大影响整体的性能，我们需要能在生产环境或者测试环境便捷地开关性能分析。此时可以对 silk 的接入做一些改造，通过环境变量控制是否打开性能分析。&lt;/p&gt;

&lt;p&gt;settings.py&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ENABLE_SILK = os.environ.get(&quot;ENABLE_SILK&quot;, &quot;False&quot;).lower() == &quot;true&quot;

if ENABLE_SILK:
    INSTALLED_APPS.append(&quot;silk&quot;)
    MIDDLEWARE.append('silk.middleware.SilkyMiddleware')
    # 启用cProfiler
    SILKY_PYTHON_PROFILER = True
    # 查看SILK本身带来的延迟
    SILKY_META = True
    # 最多储存 1000 条数据
    SILKY_MAX_RECORDED_REQUESTS = 10**3
    SILKY_MAX_RECORDED_REQUESTS_CHECK_PERCENT = 10
    # 动态profile
    SILKY_DYNAMIC_PROFILING = []
    # eg. 通过配置修改需要profile哪些代码 
    # export ENABLE_SILK=true
    # export SILK_MODULE=users.views
    # export SILK_FUNCTION=UserAccountLogin.post
    silk_module = os.environ.get(&quot;SILK_MODULE&quot;)
    silk_function = os.environ.get(&quot;SILK_FUNCTION&quot;)
    if silk_module is not None and silk_function is not None:
        SILKY_DYNAMIC_PROFILING.append({
            'module': silk_module,
            'function': silk_function
        }) 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;通过环境变量，我们可以通过控制 ENABLE_SILK 来开启或关闭 silk 是否加入 middleware 中。从而可以看到整体系统的请求延迟统计。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/img/in-post/performance-optimization/silk1.png&quot;&gt;&lt;img src=&quot;/img/in-post/performance-optimization/silk1.png&quot; alt=&quot;silk1.png&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;同时，我们也可以通过 SILK_MODULE 和 SILK_FUNCTION 来使用 SILKY_DYNAMIC_PROFILING 的功能，动态地配置 silk 对某个类的某个函数进行 profile。看到每个请求具体在每一行代码的耗时，以及其中调用过的 SQL 和对应 SQL 的耗时。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/img/in-post/performance-optimization/silk2.png&quot;&gt;&lt;img src=&quot;/img/in-post/performance-optimization/silk2.png&quot; alt=&quot;silk2.png&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/img/in-post/performance-optimization/silk3.png&quot;&gt;&lt;img src=&quot;/img/in-post/performance-optimization/silk3.png&quot; alt=&quot;silk3.png&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h5 id=&quot;系统吞吐量的分析&quot;&gt;系统吞吐量的分析&lt;/h5&gt;

&lt;p&gt;对于系统吞吐量的性能分析会相对比较复杂，一个系统的吞吐量瓶颈来源一般是系统中某个节点的资源瓶颈，例如 CPU、内存、磁盘、网络、文件句柄、端口数、线程池等等。这个时候我一般会把整个系统拆分为可以独立测试的子系统，例如 mock 一个子系统的输入，通过压测的方式判断这个子系统的吞吐量上限，从而判断在实际环境中，可能达到上限的资源使用量是多少。&lt;/p&gt;

&lt;p&gt;例如一个常见的后端系统中，可能会涉及到 MySQL、ES、后端的HTTP服务器、负载均衡。此时对每个组件做压力测试后，我们可以了解到&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;MySQL 常见的瓶颈为 CPU、连接数、内存大小&lt;/li&gt;
  &lt;li&gt;ES 常见的瓶颈为网络 IO，磁盘IO延迟，数据解析的节点的 CPU&lt;/li&gt;
  &lt;li&gt;后端的 HTTP 服务器常见的瓶颈是 CPU、内存&lt;/li&gt;
  &lt;li&gt;负载均衡的瓶颈是端口数、CPU、网络带宽&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;那么此时我们对整个系统就可以建立一个监控面板，在压测的同时观察哪个子系统的资源先达到瓶颈，再针对性的提出优化方案，例如扩容对应子系统的资源。&lt;/p&gt;

&lt;h4 id=&quot;常见系统性能优化方案&quot;&gt;常见系统性能优化方案&lt;/h4&gt;

&lt;h5 id=&quot;缓存&quot;&gt;缓存&lt;/h5&gt;
&lt;p&gt;业界常说 90% 的性能优化都是在加缓存，确实有许多问题是可以通过空间换时间，对代码关键路径上静态的信息做缓存实现，同时整个系统中对于大数据流的关键路径，也是可以尝试用缓存实现优化。&lt;/p&gt;

&lt;p&gt;同时一部分数据从磁盘缓存到内存里，或者从远程机器缓存到本地机器，也是一个常见的缓存思路。&lt;/p&gt;

&lt;h5 id=&quot;优化数据库查询&quot;&gt;优化数据库查询&lt;/h5&gt;
&lt;p&gt;另外一个常见的优化方向是数据库查询。目前大部分的业务逻辑还是使用 SQL 数据库来完成的，而数据库的复杂查询往往也是耗时较多的一个来源。例如查询时对涉及的字段加索引，或者优化查询语句，只提取需要的字段，避免 select * 语句。&lt;/p&gt;

&lt;p&gt;数据库查询的优化在进行时，也是可以遵循上述的先 profile 分析，再优化的方式，避免瞎猜测原因。&lt;/p&gt;

&lt;h4 id=&quot;性能的分析工具以及阅读材料&quot;&gt;性能的分析工具以及阅读材料&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://docs.python.org/3.6/library/profile.html&quot;&gt;cProfile - Python profile https://docs.python.org/3.6/library/profile.html&lt;/a&gt; Python 内置的 profiler&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://software.intel.com/zh-cn/vtune&quot;&gt;因特尔 Vtune https://software.intel.com/zh-cn/vtune&lt;/a&gt; 支持几乎所有主流编程语言 C / C++ / C# / Fortran / Java / Python / Go / 汇编&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://www.brendangregg.com/flamegraphs.html&quot;&gt;火焰图 Flame graph http://www.brendangregg.com/flamegraphs.html&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

</description>
        <pubDate>Fri, 01 Nov 2019 08:15:00 +0800</pubDate>
        <link>http://0.0.0.0:4000/2019/11/01/performance-optimization/</link>
        <guid isPermaLink="true">http://0.0.0.0:4000/2019/11/01/performance-optimization/</guid>
        
        <category>Tech</category>
        
        <category>Linux</category>
        
        
      </item>
    
      <item>
        <title>Weird bugs - 4</title>
        <description>&lt;h2 id=&quot;前言&quot;&gt;前言&lt;/h2&gt;

&lt;p&gt;这次记录的 bug 是主要是涉及网络知识比较多，排查中主要用到了 tcpdump 以及一些运气。&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;问题以及排查过程&quot;&gt;问题以及排查过程&lt;/h2&gt;

&lt;h3 id=&quot;问题表象&quot;&gt;问题表象&lt;/h3&gt;

&lt;p&gt;在一台 vmware 部署的 Redhat 系统上安装 docker，使用的是阿里云的镜像源，安装命令如下&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;yum remove  docker \
            docker-client \
            docker-client-latest \
            docker-common \
            docker-latest \
            docker-latest-logrotate \
            docker-logrotate \
            docker-selinux \
            docker-engine-selinux \
            docker-engine
 
 
# Set up repository
sudo yum install -y yum-utils device-mapper-persistent-data lvm2
  
# Use Aliyun Docker
sudo yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo
 
 
# install the latest version docker
yum install docker-ce
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;在安装完成后发现 docker 可以正常启动，未报错，但是启动后对应的 http 端口无法连通，具体表现为错误 “curl: (56) Recv Failure: Connection reset by peer.”&lt;/p&gt;

&lt;h3 id=&quot;问题排查和解决&quot;&gt;问题排查和解决&lt;/h3&gt;

&lt;h4 id=&quot;定位错误组件&quot;&gt;定位错误组件&lt;/h4&gt;
&lt;p&gt;首先尝试进行横向分段排查，定位具体是哪个组件为正常运行。&lt;/p&gt;

&lt;p&gt;docker 所在的主机 ip 为 10.0.10.1
docker 建立的 NAT 网段为 172.17.0.1/16
启动的 docker 对外暴露的端口为 9200，启动命令类似：&lt;code class=&quot;highlighter-rouge&quot;&gt;docker run -p 9200:9200 mydocker&lt;/code&gt;
启动后的 docker 在 docker 的网段内 ip 为 172.17.0.2&lt;/p&gt;

&lt;p&gt;首先尝试在宿主主机访问对应端口： &lt;code class=&quot;highlighter-rouge&quot;&gt;$ curl 10.0.10.1:9200&lt;/code&gt;，报 “No route to host” 错误。
同时尝试使用 telnet 连接该端口 &lt;code class=&quot;highlighter-rouge&quot;&gt;$ telnet 10.0.10.1:9200&lt;/code&gt;，同样报 “No route to host” 错误。我们知道 tcp 连接的第一步是三次握手建立连接，报 “No route to host” 说明连握手都无法完成，问题应该出在网络的第4层以下。&lt;/p&gt;

&lt;p&gt;在宿主主机上尝试 ping 对应的 docker NAT 网关内的 ip：&lt;code class=&quot;highlighter-rouge&quot;&gt;$ping 172.17.0.2&lt;/code&gt;，发现ping不通。尝试反向ping，从 docker 内 ping 172.17.0.1 发现也无法 ping 通，说明 docker 的网桥可能未正常工作。&lt;/p&gt;

&lt;p&gt;docker 的网络包是通过 iptables 进行配置转发的，所以首先排查宿主主机上的 iptables 配置是否正常。
&lt;code class=&quot;highlighter-rouge&quot;&gt;$ iptables --list&lt;/code&gt; 查看所有 iptables 规则，iptables 内 DOCKER-USER 和 DOCKER 是检验所有发到 docker 容器的规则，这两部分在主机的 iptables 配置里都是空的，或 all anywhere，所以理论上不会对 tcp 包进行拦截。这部分没发现有异常。&lt;/p&gt;

&lt;p&gt;接下来尝试使用 tcpdump 抓流量包，查看在链路的哪个部分无法连通。还是使用分段排查的方式，先排查 docker0 网卡的流量包，看是否包含 telnet 的握手请求。使用 &lt;code class=&quot;highlighter-rouge&quot;&gt;$tcpdump -w docker.pcap -i docker0&lt;/code&gt; 在一个 ssh 窗口中进行抓包，然后使用 &lt;code class=&quot;highlighter-rouge&quot;&gt;$telnet 172.17.0.1 9200&lt;/code&gt; 发起 tcp 连接。此时发现了一个奇怪的现象，在 tcpdump 运行的时候，所有网络请求都能通了！ telnet 可以正常连接，curl 命令也能返回预期的信息。关闭 tcpdump 后，又变回了原来无法连通的情况。&lt;/p&gt;

&lt;h4 id=&quot;解决方法&quot;&gt;解决方法&lt;/h4&gt;

&lt;p&gt;根据之前发现的情况，Google 搜索 “docker tcpdump 抓包后通了”，发现了一篇类似情况的排查博客：&lt;a href=&quot;https://ieevee.com/tech/2016/11/24/promisc.html&quot;&gt;从混杂模式开始说起&lt;/a&gt;。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;但前几天BJ机房掉电，重启后发现宿主机无法登陆，网络不通。ipmi登陆上去，检查team0状态、br0状态都正常，tcpdump抓包发现，报文能够到达team0的子接口(eno0），但无法送到br0，因此ping宿主机不通。&lt;/p&gt;

  &lt;p&gt;偶然发现，从外面ping宿主机网络，如果在team0口、eno0口都执行tcpdump，宿主机、docker容器，网络均可达。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;从现象上看，他遇到的问题和我的表现是一样的。在该博客中也提到了该问题的根源：物理网卡进入了混杂模式，但是子接口并没有进入，导致子接口无法获取对应的网络包。我在问题宿主主机上做了验证：&lt;/p&gt;

&lt;p&gt;查看系统日志，并计算进入混杂模式但是未退出的网卡：&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ cat /var/log/messages | grep promisc | grep enter | cut -d &quot; &quot; -f 8 | sort | uniq -c | sort -n &amp;gt; card_list_enter
$ cat /var/log/messages | grep promisc | grep enter | cut -d &quot; &quot; -f 8 | sort | uniq -c | sort -n &amp;gt; card_list_left
$ diff card_list_enter card_list_left
...
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;上面的 shell 先统计了所有网卡进入混杂模式的次数，然后统计了所有网卡退出混杂模式的次数，再 diff 找到进入了混杂模式，但是未退出的网卡。然后再去 &lt;code class=&quot;highlighter-rouge&quot;&gt;$cat /sys/class/net/docker0/flags&lt;/code&gt;, 看具体的标志位是否打开，发现除了 docker0 网卡之外，其他有若干网卡打开了混杂模式。而同时，查看 &lt;code class=&quot;highlighter-rouge&quot;&gt;/var/log/messages&lt;/code&gt; 也发现每次 tcpdump 的时候，docker0 网卡都会进入混杂模式。&lt;/p&gt;

&lt;p&gt;尝试使用命令 &lt;code class=&quot;highlighter-rouge&quot;&gt;$ifconfig docker0 PROMISC&lt;/code&gt; 手动打开 docker0 的混杂模式后，docker 就能正常运行了。&lt;/p&gt;

&lt;h3 id=&quot;原理&quot;&gt;原理&lt;/h3&gt;

&lt;h4 id=&quot;混杂模式是什么&quot;&gt;混杂模式是什么&lt;/h4&gt;

&lt;p&gt;&lt;a href=&quot;https://zh.wikipedia.org/wiki/%E6%B7%B7%E6%9D%82%E6%A8%A1%E5%BC%8F&quot;&gt;混杂模式&lt;/a&gt;是网卡在链路层工作的一个工作模式。简单来说，一般网卡网卡只接受来自网络端口的目的地址指向自己的数据，但是混杂模式下会接受所有数据。判断标准就是数据的 MAC 地址是否相同。&lt;/p&gt;

&lt;h4 id=&quot;为什么tcpdump需要打开对应网卡的混杂模式&quot;&gt;为什么tcpdump需要打开对应网卡的混杂模式&lt;/h4&gt;

&lt;p&gt;tcpdump 需要监听特定网络接口或者进程的网络请求，这些网络请求并不一定是发给自己的，所以需要打开网卡的混杂模式，从而获取到所有相关数据。&lt;/p&gt;

&lt;h4 id=&quot;为什么不混杂模式无法连接主机&quot;&gt;为什么不混杂模式无法连接主机&lt;/h4&gt;

&lt;p&gt;这个原因仍然没有得到100%的确认和复现，因为出问题的主机是在客户的环境中，我们能访问的时间非常有限。应该是由于数据包的 MAC 地址在 iptables 或者虚拟机的网卡转发时被修改了，修改后的值与 docker0 的 MAC 地址不一致，所以 docker0 在没有打开混杂模式前无法获取到对应数据包。如果要从根本上解决这个问题，还需要 RedHat 以及 Vmware 的工程师介入，在这个 case 中我们没有相关的权限要求，只能先解决问题的表现了。&lt;/p&gt;

&lt;h3 id=&quot;推荐阅读&quot;&gt;推荐阅读&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://docs.docker.com/network/iptables/&quot;&gt;Docker and iptables&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://ieevee.com/tech/2016/11/24/promisc.html&quot;&gt;从混杂模式开始说起&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;p&gt;如果你看到这里，一定是真爱！欢迎看看我的其他 &lt;a href=&quot;http://chendi.me/&quot;&gt;blog&lt;/a&gt;。O(∩_∩)O&lt;/p&gt;
</description>
        <pubDate>Mon, 07 Oct 2019 08:15:00 +0800</pubDate>
        <link>http://0.0.0.0:4000/2019/10/07/weird-bug-4/</link>
        <guid isPermaLink="true">http://0.0.0.0:4000/2019/10/07/weird-bug-4/</guid>
        
        <category>Tech</category>
        
        <category>Bug</category>
        
        <category>Linux</category>
        
        
      </item>
    
      <item>
        <title>Sync Outlook Calendar And Conference Room</title>
        <description>&lt;h2 id=&quot;起因&quot;&gt;起因&lt;/h2&gt;

&lt;p&gt;由于系统A实现上的需求，我们需要将 outlook 中的会议室的使用信息，以及对应每个用户的日程信息同步至内部开发的系统A中。主要需求包括：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;outlook上的会议室使用情况涉及到不使用系统A的用户，所以outlook上的会议室预约信息会比系统A中的多，我们需要把这些额外的预约信息同步至系统A中，这样系统A中的用户在预约会议室时，可以考虑到其他用户的冲突。&lt;/li&gt;
  &lt;li&gt;用户已经习惯使用 outlook 将日程和会议室信息同步至手机端，所以系统A中增加的日程需要同步至 outlook 中，包括会议室订阅也需要增加。&lt;/li&gt;
  &lt;li&gt;当系统A中日程的属性变化时，outlook中需要对应发生变化。&lt;/li&gt;
  &lt;li&gt;当outlook中日程的属性发生变化时，系统A中也需要对应发生变化&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;探索调研&quot;&gt;探索调研&lt;/h2&gt;

&lt;h3 id=&quot;搭建测试环境&quot;&gt;搭建测试环境&lt;/h3&gt;

&lt;p&gt;为了便于测试，我们需要搭建一套基于 outlook 的邮件以及会议室系统，这里需要以下资源：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Windows Server 2012r2.
    &lt;ul&gt;
      &lt;li&gt;2 核心&lt;/li&gt;
      &lt;li&gt;16G 内存&lt;/li&gt;
      &lt;li&gt;300G 磁盘&lt;/li&gt;
      &lt;li&gt;云服务商上对外 25 端口默认是禁止使用的，需要单独申请开放，例如 &lt;a href=&quot;https://help.aliyun.com/knowledge_detail/56130.html&quot;&gt;阿里云25端口解封&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;在 1 中的 windows 服务器上配置 AD 以及 Exchange Server 2016&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;需要配置一个域名以及 DNS 记录
    &lt;ul&gt;
      &lt;li&gt;需要给 exchange 服务器挂一个域名，例如 mail.abc.com，这个会作为邮件发送的服务器地址。&lt;/li&gt;
      &lt;li&gt;需要配置 autodiscover 域名，例如 autodiscover.abc.com，这个域名会用来给客户端自动发现邮箱配置。&lt;/li&gt;
      &lt;li&gt;需要配置一条 MX 记录，主机名 @，记录指向 mail.abc.com&lt;/li&gt;
      &lt;li&gt;域名最好能申请 CA 签发的正规 https 证书，否则用自签名证书可能会遇到诸多不便。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;配置用户以及模拟权限&quot;&gt;配置用户以及模拟权限&lt;/h3&gt;

&lt;p&gt;我们需要为系统A建立一个服务账号，这个账号的会使用代码进行登录。同时，我们希望这个账号可以代所有其他用户账号管理会议日程信息，所以我们需要赋予这个账号 Impersonation 权限，也叫模拟权限。&lt;/p&gt;

&lt;p&gt;我们可以通过后台管理 ecp 界面上的权限管理配置服务账号的权限：
&lt;a href=&quot;/img/in-post/outlook-calendar/pic1.png&quot;&gt;&lt;img src=&quot;/img/in-post/outlook-calendar/pic1.png&quot; alt=&quot;pic1&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;其中配置的 ApplicationImpersonation 会赋予其模拟他人账号登录的权限
&lt;a href=&quot;/img/in-post/outlook-calendar/pic2.png&quot;&gt;&lt;img src=&quot;/img/in-post/outlook-calendar/pic2.png&quot; alt=&quot;pic2&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;同时，我们也需要建立几个会议室邮箱，这样我们才能有公共的 “会议室” 以供预定。&lt;/p&gt;

&lt;h3 id=&quot;exchangelib的使用&quot;&gt;exchangelib的使用&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/ecederstrand/exchangelib&quot;&gt;exchangelib&lt;/a&gt; 提供了一个可以使用 python 代码访问 exchange 服务的库，并且在使用上去 Django 的 ORM 极其类似。&lt;/p&gt;

&lt;p&gt;安装：
&lt;code class=&quot;highlighter-rouge&quot;&gt;pip3 install exchangelib&lt;/code&gt;&lt;/p&gt;

&lt;h4 id=&quot;登陆-exchange-账号&quot;&gt;登陆 exchange 账号&lt;/h4&gt;

&lt;p&gt;如果 exchange 服务器使用的是自签名的 https 证书，则需要跳过 https 证书验证环节：&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# 自签名服务器需要跳过 HTTPS 的证书检查
&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;exchangelib.protocol&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BaseProtocol&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;NoVerifyHTTPAdapter&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;BaseProtocol&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;HTTP_ADAPTER_CLS&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;NoVerifyHTTPAdapter&lt;/span&gt;

&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;urllib3&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;urllib3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;disable_warnings&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;声明登陆服务器所使用的版本号、账号、密码、服务器连接地址：&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;version&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Version&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;build&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Build&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;15&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;12&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;34&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;credentials&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Credentials&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'administrator'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'xxxxxxx'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Configuration&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;server&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'mail.abc.com'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;credentials&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;credentials&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;version&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;version&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;auth_type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;NTLM&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;以用户 abc 的身份登陆，IMPERSONATION 字段表示以用之前配置的账号密码，模拟用户 zhangsan@abc.com 登陆：&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;account&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Account&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'zhangsan@abc.com'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;credentials&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;credentials&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;access_type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;IMPERSONATION&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;创建新的日程&quot;&gt;创建新的日程&lt;/h4&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# 新建一个日程对象
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;new_meeting&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;CalendarItem&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;account&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;account&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# 需要绑定一个发起人账号
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;folder&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;account&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;calendar&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# 默认加入该账号的日历文件夹
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;account&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;default_timezone&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;localize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;EWSDateTime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2019&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;21&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;#带时区的开始和结束时间
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;end&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;account&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;default_timezone&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;localize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;EWSDateTime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2019&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;21&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;#带时区的开始和结束时间
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;subject&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;final test 6&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# 会议名称
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;body&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Hello from Python'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# 会议内容
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;location&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'2楼广寒宫'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# 会议室地点，只需要文字描述，与实际会议室账号无关
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;required_attendees&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'abc@abc.com'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;guanghan@abc.com&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;new_meeting&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;save&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;send_meeting_invitations&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SEND_TO_ALL_AND_SAVE_COPY&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 切换至会议室账号并接受邀请
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;room_account&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Account&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'guanghan@abc.com'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;credentials&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;credentials&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;access_type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;IMPERSONATION&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;item&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;room_account&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;calendar&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;all&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;order_by&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'-datetime_received'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;accept&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;注意：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;如果需要对这个日程绑定一个会议室，需要将这个会议室对应的邮箱加到参与者列表里，然后再更换登录账号，接受所有的会议邀请。&lt;/li&gt;
  &lt;li&gt;保存时需要增加参数 &lt;code class=&quot;highlighter-rouge&quot;&gt;send_meeting_invitations=SEND_TO_ALL_AND_SAVE_COPY&lt;/code&gt;，否则参与者不会收到邀请信息。&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;查询日程并以某条件过滤&quot;&gt;查询日程并以某条件过滤&lt;/h4&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;start&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;account&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;default_timezone&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;localize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;EWSDateTime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2019&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;21&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;end&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;account&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;default_timezone&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;localize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;EWSDateTime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2019&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;21&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;items&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;account&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;calendar&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;last_modified_time__range&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;end&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;item&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;items&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# 每个会议都有一个 ID
&lt;/span&gt;	&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;subject&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# 会议标题
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;查询会议室的使用情况&quot;&gt;查询会议室的使用情况&lt;/h4&gt;

&lt;p&gt;会议室和用户没有本质上的区别。可以通过 Impersonation 登录会议室的邮箱账号，查看其日历上的内容来获取使用情况。&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;start&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;account&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;default_timezone&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;localize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;EWSDateTime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2019&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;21&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;end&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;account&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;default_timezone&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;localize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;EWSDateTime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2019&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;21&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;items&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;account&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;calendar&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;last_modified_time__range&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;end&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;item&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;items&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# 每个会议都有一个 ID
&lt;/span&gt;	&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# 会议开始时间
&lt;/span&gt;	&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;end&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# 会议结束时间
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;获取到该会议室的使用情况后，就可以检查该时间段内是否有人使用了。&lt;/p&gt;

&lt;h3 id=&quot;系统设计&quot;&gt;系统设计&lt;/h3&gt;

&lt;h4 id=&quot;outlook-中会议室使用情况同步至系统内&quot;&gt;outlook 中会议室使用情况同步至系统内&lt;/h4&gt;

&lt;p&gt;为了保证会议室使用情况的实时以及查询的稳定性，我们定期将会议室的使用情况同步至系统内&lt;/p&gt;

&lt;p&gt;同步任务需要实现：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;系统A中的会议室使用记录内增加 outlook id，字符串类型，用于记录 outlook 中的会议ID&lt;/li&gt;
  &lt;li&gt;每次查询获取所有会议室最近一段时间内的日程列表，使用 last_modifed_time 字段进行过滤，只取上次同步任务之后变更的日程，与系统内的记录对比并更新&lt;/li&gt;
  &lt;li&gt;如果有系统A中不存在的日程，标记为外部创建日程即可&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;如果有同步需求，也可以通过代码手动调用同步任务触发。
正常情况下设置定时任务，每10分钟同步一次即可。&lt;/p&gt;

&lt;h4 id=&quot;系统中增加日程&quot;&gt;系统中增加日程&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;检查对应会议室在 xx 时间段内是否有被预定&lt;/li&gt;
  &lt;li&gt;绑定会议室后，系统A内创建会议室日程。&lt;/li&gt;
  &lt;li&gt;日程保存时，检测是否有 outlook 日程绑定，同时检测 outlook 日程是否仍然存在，如果不存在，则创建outlook日程并绑定会议室，outlook中创建日程的用户与系统登录用户一致。&lt;/li&gt;
  &lt;li&gt;绑定 outlook 会议室的操作即发送会议邀请给对应的会议室账号，再登陆会议室账号接受邀请即可。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;系统中修改日程&quot;&gt;系统中修改日程&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;系统中修改日程属性，如开始时间、结束时间、会议室等。&lt;/li&gt;
  &lt;li&gt;修改后在保存时通过会议 ID 查询 outlook 中会议的对象，修改对应字段后保存 outlook 对象即可。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;系统中删除日程&quot;&gt;系统中删除日程&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;系统内标记日程位删除，同时 soft delete 删除 outlook 中的日程。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;

&lt;p&gt;outlook 对于会议室的设计感觉像是有历史遗留问题，每个会议室都必须分配一个邮箱，同时用邮箱来管理。但是目前来看，这个设计也有可取之处，就是对于会议室的操作可以复用用户的操作，学习成本更低一些。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;如果你看到这里，一定是真爱！欢迎看看我的其他 &lt;a href=&quot;http://chendi.me/&quot;&gt;blog&lt;/a&gt;。O(∩_∩)O&lt;/p&gt;
</description>
        <pubDate>Sun, 08 Sep 2019 08:15:00 +0800</pubDate>
        <link>http://0.0.0.0:4000/2019/09/08/sync-outlook-calendar/</link>
        <guid isPermaLink="true">http://0.0.0.0:4000/2019/09/08/sync-outlook-calendar/</guid>
        
        <category>Tech</category>
        
        
      </item>
    
      <item>
        <title>Leverage Datalake cloud service in ETL</title>
        <description>&lt;h2 id=&quot;起因&quot;&gt;起因&lt;/h2&gt;

&lt;p&gt;在数据采集和分析的流程中，目前有3个痛点不好解决：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;数据采集之后是以多个小 json 文件储存在类似 AWS S3 的对象储存中的，当我们要核验数据的特征，例如最大值，数据总数之类的，需要使用 MapReduce 或者 spark 才能实现，而这个操作门槛相对较高。并且由于数据是以多个小文件的形式存在，批处理脚本的执行效率低，每次都需要较长时间才能完成一个简单的数据查询。&lt;/li&gt;
  &lt;li&gt;数据清洗的时候不了解数据特性，例如空值，异常值的情况，所以容易在清洗过程中欠缺对异常情况的处理。&lt;/li&gt;
  &lt;li&gt;数据分析的迭代周期长，出了问题回溯困难。因为统计需要使用专业的数据处理脚本，所以需求提出之后，需要经过代码实现，测试，批量执行之后才能看到结果，迭代周期往往以天计算。同时某个数据的统计值与预期不符时，缺少合适的工具帮助回溯到原始数据。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;这里使用的是阿里云 Data Lake Analytics 服务帮助解决这个问题。同时用阿里云的 OSS 作为数据源储存。&lt;/p&gt;

&lt;p&gt;Data Lake Analytics 将一些简单的 ETL 任务封装成 SAAS 服务了，所以绝大部分的操作是在阿里云的控制台上执行的。&lt;/p&gt;

&lt;h2 id=&quot;简化将小文件合并成大文件的过程&quot;&gt;简化将小文件合并成大文件的过程&lt;/h2&gt;

&lt;p&gt;首先，我们来解决痛点1。&lt;/p&gt;

&lt;p&gt;对于小文件查询慢的问题，传统的解决方法是写一个 spark 的数据清洗脚本来将其转为 parquet 格式，然后再用 zepplin 之类的工具进行查询分析。&lt;/p&gt;

&lt;p&gt;Data Lake Analytics 的处理分成以下几个步骤：&lt;/p&gt;

&lt;h3 id=&quot;建立一个外表连接到需要处理的-oss-路径&quot;&gt;建立一个外表连接到需要处理的 OSS 路径。&lt;/h3&gt;

&lt;p&gt;这里可以使用阿里云的建表向导来进行。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/img/in-post/aliyun-datalake/datalake1.png&quot;&gt;&lt;img src=&quot;/img/in-post/aliyun-datalake/datalake1.png&quot; alt=&quot;datalake1&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;填入几个关于数据源的信息后，会自动生成一个建表的 schema。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/img/in-post/aliyun-datalake/datalake2.png&quot;&gt;&lt;img src=&quot;/img/in-post/aliyun-datalake/datalake2.png&quot; alt=&quot;datalake2&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;这里建议大家手动审核调整一下建表的 sql，然后在 sql 界面进行建表。&lt;/p&gt;

&lt;h3 id=&quot;使用-data-lake-的-mysql-接口连接其数据库&quot;&gt;使用 Data Lake 的 MySQL 接口连接其数据库&lt;/h3&gt;

&lt;p&gt;在阿里云控制台可以获取到连接的参数信息。建议根据 &lt;a href=&quot;https://help.aliyun.com/document_detail/98381.html?spm=a2c4g.11186623.6.557.6aff7b8cAX4zoH&quot;&gt;文档&lt;/a&gt; 配置子账号并用子账号创建新表。&lt;/p&gt;

&lt;p&gt;连接上之后，我们就可以用刚才阿里云生成的建表 sql 创建一个新的外表了。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/img/in-post/aliyun-datalake/datalake3.png&quot;&gt;&lt;img src=&quot;/img/in-post/aliyun-datalake/datalake3.png&quot; alt=&quot;datalake3&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;建立-parquet-格式的外表&quot;&gt;建立 Parquet 格式的外表&lt;/h3&gt;

&lt;p&gt;使用前面阿里云建表向导提供的建表 SQL，我们可以做一些修改，例如将 &lt;code class=&quot;highlighter-rouge&quot;&gt;STORE AS JSON&lt;/code&gt; 改为 &lt;code class=&quot;highlighter-rouge&quot;&gt;STORE AS PARQUET&lt;/code&gt; 然后建立一个指向新的 OSS 路径的外表。&lt;/p&gt;

&lt;p&gt;然后我们可以使用下面的 SQL 将 JSON 格式的文件导入到 PARQUET 格式的文件中去，完成小文件合并的任务。&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;cm&quot;&gt;/*+run_async=true*/&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;INTO&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parquet_table&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;json_table&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;记得加上面的 &lt;code class=&quot;highlighter-rouge&quot;&gt;/*+run_async=true*/&lt;/code&gt; 标注，因为这个执行过程比较久，将其设置为异步执行可以避免由于 mysql 客户端超时导致的任务失败。&lt;/p&gt;

&lt;h2 id=&quot;在parquet文件上进行数据特性分析&quot;&gt;在Parquet文件上进行数据特性分析&lt;/h2&gt;

&lt;p&gt;当我们将数据从 json 文件插入至 parquet 文件后，我们就可以从 parquet 文件对应的表进行 sql 查询了。由于文件已经被合并成大的 parquet 文件，查询性能也会大大提高。&lt;/p&gt;

&lt;h2 id=&quot;回溯问题文件&quot;&gt;回溯问题文件&lt;/h2&gt;

&lt;p&gt;当我们发现数据的统计值不符合我们的预期时，往往需要回溯寻找出问题的原始数据是什么，Datalake 也是做这类工作的一个利器。&lt;/p&gt;

&lt;p&gt;当我们使用 OSS 作为外表进行查询时，我们可以使用 &lt;code class=&quot;highlighter-rouge&quot;&gt;$path&lt;/code&gt; 获取外表数据源的文件名称。&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;json_table&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;hr /&gt;

&lt;p&gt;如果你看到这里，一定是真爱！欢迎看看我的其他 &lt;a href=&quot;http://chendi.me/&quot;&gt;blog&lt;/a&gt;。O(∩_∩)O&lt;/p&gt;
</description>
        <pubDate>Mon, 28 Jan 2019 16:15:00 +0800</pubDate>
        <link>http://0.0.0.0:4000/2019/01/28/leverage-datalake-service-in-etl/</link>
        <guid isPermaLink="true">http://0.0.0.0:4000/2019/01/28/leverage-datalake-service-in-etl/</guid>
        
        <category>Tech</category>
        
        
      </item>
    
      <item>
        <title>Snappy-python is not fully compatible with hadoop-snappy</title>
        <description>&lt;h2 id=&quot;起因&quot;&gt;起因&lt;/h2&gt;

&lt;p&gt;在我当前项目中，有一部分技术架构涉及到数据在 python 脚本中用 json + &lt;a href=&quot;https://github.com/google/snappy&quot;&gt;snappy&lt;/a&gt; 的格式压缩之后储存起来，json 是作为数据序列化的格式，而 snappy 则是作为数据压缩的格式。在下游处理中，spark 任务会读取这部分数据进行处理。这套方案理论上是没有问题的，在我们的调研中，也确认了 python 中上传的数据，在 spark 中可以被正确解读。但是在实际广泛使用时，我们发现有某些数据在 python 端能正常地被压缩以及解压，但是在 spark 端就报了下面的错误：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;java.lang.InternalError: Could not decompress data. Input is invalid.
at org.apache.hadoop.io.compress.snappy.SnappyDecompressor.decompressBytesDirect(Native Method) 
at org.apache.hadoop.io.compress.snappy.SnappyDecompressor.decompress(SnappyDecompressor.java:239)
at org.apache.hadoop.io.compress.BlockDecompressorStream.decompress(BlockDecompressorStream.java:88)
at org.apache.hadoop.io.compress.DecompressorStream.read(DecompressorStream.java:85)
...
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;这里记录的是解决这个问题的过程和结果。&lt;/p&gt;

&lt;h2 id=&quot;分析错误原因&quot;&gt;分析错误原因&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;首先缩小一下问题出现的范围&lt;/strong&gt;。&lt;/p&gt;

    &lt;p&gt;这个错误大概在1万个文件中才会出现一次，并且我们将出错的文件重新用 python 库解压之后，spark 仍然无法解析。所以基本可以认定这个文件指出了 spark 和 python 中 snappy SDK 的一些不兼容之处。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;缩小测试用例，找出最小可以复现问题的测试用例&lt;/strong&gt;。&lt;/p&gt;

    &lt;p&gt;原始的错误文件大概有2.6MB，压缩之后是2.5MB，压缩比例很差。好在文件并不大，决定用二分法找出有问题的数据内容。在将数据分为两份之后，发现只有其中一份用 python sdk 压缩之后 spark 无法解析，另一份则没有问题。在不断缩小范围之后，定位到了一段 base64 encode 的数据上。这部分 base64 encode 的数据大概有1.5MB。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;构建最小可以复现问题的测试用例&lt;/strong&gt;。&lt;/p&gt;

    &lt;p&gt;在比较正常压缩文件和该错误压缩文件之后，发现 base64 encode 的数据几乎没有被压缩，原文和压缩后的文件几乎是相同的。此时我们大胆猜测，当压缩后的文件与原文相同时，snappy 解压时会因为找不到所需的元数据而报错。在编写了一个随机字符生成器后，我们基本验证了我们的猜测：&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import random
import string
N=1000000
print(''.join(random.choices(string.ascii_uppercase + string.digits, k=N)))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;p&gt;并且在 N 在大于 100 万的情况下必然复现。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;寻找解决问题的方法&quot;&gt;寻找解决问题的方法&lt;/h2&gt;

&lt;h3 id=&quot;对比测试结果&quot;&gt;对比测试结果&lt;/h3&gt;
&lt;p&gt;在找到复现的 test case 之后，下一步我们要找问题的根源。对于一个序列化和反序列化的算法，不同语言的实现应该遵从同一套标准，那么同一段数据压缩后的二进制文件应该也是相同的。&lt;/p&gt;

&lt;p&gt;将 snappy-python 压缩后的文件命名为 python_result.snappy&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;python3 -m snappy -t hadoop_snappy -c test.txt &amp;gt; test_python.txt.snappy
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;此时我们还需要 hadoop-snappy 编译出来的二进制文件&lt;/p&gt;

&lt;h3 id=&quot;编译-hadoop-snappy-测试用例&quot;&gt;编译 hadoop-snappy 测试用例&lt;/h3&gt;
&lt;p&gt;hadoop-snappy 的源码在 &lt;a href=&quot;https://code.google.com/archive/p/hadoop-snappy/&quot;&gt;Hadoop snappy google code&lt;/a&gt;。可以从&lt;a href=&quot;https://storage.googleapis.com/google-code-archive-source/v2/code.google.com/hadoop-snappy/source-archive.zip&quot;&gt;这里&lt;/a&gt;下载源码。&lt;/p&gt;

&lt;p&gt;源码编译时需要先安装 snappy 库，同时配置 snappy 库的到 java 的 VM Options 中。例如我在 Mac OS 上用 brew 安装的 snappy。&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ brew install snappy
$ ls /usr/local/Cellar/snappy/1.1.7_1
AUTHORS              INSTALL_RECEIPT.json README.md            lib
COPYING              NEWS                 include
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;snappy 库的路径是 /usr/local/Cellar/snappy/1.1.7_1，那么就配置 -Dsnappy.prefix=/usr/local/Cellar/snappy/1.1.7_1&lt;/p&gt;

&lt;p&gt;同时要注意，老版本的 hadoop-snappy 有一个提示错误，当 snappy 格式错误时，提示的是找不到 snappy 库，可以用以下方式修改 &lt;code class=&quot;highlighter-rouge&quot;&gt;src/main/native/src/org/apache/hadoop/io/compress/snappy/SnappyDecompressor.c&lt;/code&gt;，然后重新编译来解决。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;   if (ret == SNAPPY_BUFFER_TOO_SMALL){
-    THROW(env, &quot;Ljava/lang/InternalError&quot;, &quot;Could not decompress data. Buffer length is too small.&quot;);
+    THROW(env, &quot;java/lang/InternalError&quot;, &quot;Could not decompress data. Buffer length is too small.&quot;);
   } else if (ret == SNAPPY_INVALID_INPUT){
-    THROW(env, &quot;Ljava/lang/InternalError&quot;, &quot;Could not decompress data. Input is invalid.&quot;);
+    THROW(env, &quot;java/lang/InternalError&quot;, &quot;Could not decompress data. Input is invalid.&quot;);
   } else if (ret != SNAPPY_OK){
-    THROW(env, &quot;Ljava/lang/InternalError&quot;, &quot;Could not decompress data.&quot;);
+    THROW(env, &quot;java/lang/InternalError&quot;, &quot;Could not decompress data.&quot;);
   }
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;编译之后可以使用测试用例来触发 snappy 的压缩，测试用例在 &lt;code class=&quot;highlighter-rouge&quot;&gt;src/test/java/org/apache/hadoop/io/compress/snappy/TestSnappyCodec.java&lt;/code&gt;。压缩之后我们得到了 test_java.txt.snappy&lt;/p&gt;

&lt;p&gt;我们比较一下 test_java.txt.snappy 和 test_python.txt.snappy，发现 test_python.txt.snappy 整个文件中，如果用 utf-8 编码格式打开，只有最开头有一段乱码的二进制头信息。但是 test_java.txt.snappy 则每隔 256K 就会有一段二进制头信息。&lt;/p&gt;

&lt;p&gt;在这时，我们可以初步断定是两个语言的头信息写入不一致导致的文件格式不兼容。&lt;/p&gt;

&lt;h3 id=&quot;查看源码&quot;&gt;查看源码&lt;/h3&gt;
&lt;p&gt;snappy 的压缩和代码在 java 中其实并不复杂，主要都集中在 &lt;code class=&quot;highlighter-rouge&quot;&gt;src/main/java/org/apache/hadoop/io/compress/snappy/&lt;/code&gt;，本质上是在 java 中将 byte 流读入后，将数据分块，再对每一块进行压缩。而我们看到的文件里的的二进制头信息其实就是每一块数据的元数据，例如每一块数据的长度等。那么是什么决定了数据块的默认大小呢？有两个变量可能会造成影响。&lt;/p&gt;

&lt;p&gt;一个是 DEFAULT_DIRECT_BUFFER_SIZE:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ grep DEFAULT_DIRECT_BUFFER_SIZE src/main/java/org/apache/hadoop/io/compress/snappy/SnappyCompressor.java
$   private static final int DEFAULT_DIRECT_BUFFER_SIZE = 64 * 1024;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;这里是代码定义的默认大小，64K。但是在测试用例中我们发现，调整这个数值并不会改变最后生成的数据块大小。&lt;/p&gt;

&lt;p&gt;另一个是 IO_COMPRESSION_CODEC_SNAPPY_BUFFERSIZE_DEFAULT：&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ grep -b2 IO_COMPRESSION_CODEC_SNAPPY_BUFFERSIZE_DEFAULT src/main/java/org/apache/hadoop/io/compress/SnappyCodec.java
1527-
1528-  /** Default value for IO_COMPRESSION_CODEC_SNAPPY_BUFFERSIZE_KEY */
1598:  public static final int IO_COMPRESSION_CODEC_SNAPPY_BUFFERSIZE_DEFAULT =
1673-      256 * 1024;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;这个配置文件控制了在作为 Hadoop Codec 组件实例化时，使用的数据块大小。如果我们将这个值调为 256，我们会发现测试用例中数据块的分块确实变化了。&lt;/p&gt;

&lt;p&gt;这时候，我们可以大致明白，之所以 python-snappy 压缩的文件在 hadoop-snappy 中无法解析，其实本质上是因为 python-snappy 在一整个 256K 数据块中的任何一块地方生成元数据头，导致 hadoop-snappy 一次性读取进来的 256K 全是数据，没有数据块头，也就无法解析出对应的数据块长度，最终报了 “ Input is invalid.” 错误。&lt;/p&gt;

&lt;p&gt;那么为什么其他数据没问题， base64 的数据就会出问题呢？&lt;/p&gt;

&lt;p&gt;首先，并不是一定 256K 的位置才会生成一个数据块头信息，而是每一个可以被截断并压缩的数据块就会生成一个头信息。但是对于 base64 的文字，基本是原文读入，原文写出的，所以连续的 256K base64 编码数据中，如果没有强行截断的话，就不会生成数据头。这个应该是 python-snappy sdk 的一个bug，不过由于时间原因，没办法细看 python-snappy sdk 并修复这个问题。&lt;/p&gt;

&lt;h3 id=&quot;最终解决方法&quot;&gt;最终解决方法&lt;/h3&gt;
&lt;p&gt;首先我们尝试调大 hadoop-snappy 的解压区块大小，当 hadoop-snappy 的 IO_COMPRESSION_CODEC_SNAPPY_BUFFERSIZE_DEFAULT 设置为 512K 时，我们发现 python-snappy 压缩的 base64 encode 文件可以被正常解压。但是在 hadoop 集群上，这样有可能导致这样保存下来的 snappy.json 文件无法被其他未修改配置的 hadoop 组件读取。&lt;/p&gt;

&lt;p&gt;还有一个思路就是调小 python-snappy 的区块大小。虽然文档中没有提到修改的方式，但是从 API 的签名中我们发现，在 &lt;a href=&quot;https://github.com/andrix/python-snappy/blob/master/snappy/hadoop_snappy.py&quot;&gt;hadoop-snappy.py&lt;/a&gt; 文件中也定义了 &lt;code class=&quot;highlighter-rouge&quot;&gt;SNAPPY_BUFFER_SIZE_DEFAULT&lt;/code&gt; 变量，控制默认的区块大小。而在 stream_compress 函数的签名中也有 blocksize 变量，默认值就是 SNAPPY_BUFFER_SIZE_DEFAULT。所以只要在调用 stream_compress 的时候将 blocksize 调为 128K 即可。&lt;/p&gt;

&lt;p&gt;最后联调后发现，这个方法生成的 python-snappy 文件是可以被 hadoop-snappy 成功解析的。最后我们的解决方法就是在 stream_compress 设置 blocksize 为 128K。&lt;/p&gt;

&lt;h1 id=&quot;经验总结&quot;&gt;经验总结&lt;/h1&gt;

&lt;p&gt;首先这个问题其实本质上还是一个算法，多个语言实现导致的问题。虽然底层的压缩算法使用的是同一套库，但是上层数据块的切分实现可能有细微差别，导致这个问题的发生。这个问题的解决其实关键是有一个可以复现的测试用例，有了这个测试用例之后就能帮我们不断缩小问题的范围，最后找到一个相对实现起来比较容易的解决方案。&lt;/p&gt;

&lt;h2 id=&quot;题外话&quot;&gt;题外话&lt;/h2&gt;

&lt;p&gt;在看 Google snappy 的代码时，发现一个 &lt;a href=&quot;https://github.com/google/snappy/commit/824e6718b5b5a50d32a89124853da0a11828b25c&quot;&gt;commit&lt;/a&gt;。Google 的工程师在做 regression 性能测试的时候发现，LLVM 的一个内存对齐的相关改动，导致 snappy 的性能下降了 3%，这个改动影响到了多个 intel 架构。最后虽然没能理解出现的原因，但是强行在 x86 架构上增加一个补位元素，抵消了 LLVM 上游的副作用，使得 snappy 的性能恢复到 LLVM 修改之前。&lt;/p&gt;

&lt;p&gt;这看起来是个小优化，但是也看到了 Google 背后完整的基础架构，能支持工程师定期进行性能测试，并且将性能测试在不同架构上进行复现。确实厉害。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;如果你看到这里，一定是真爱！欢迎看看我的其他 &lt;a href=&quot;http://chendi.me/&quot;&gt;blog&lt;/a&gt;。O(∩_∩)O&lt;/p&gt;
</description>
        <pubDate>Sun, 11 Nov 2018 05:15:00 +0800</pubDate>
        <link>http://0.0.0.0:4000/2018/11/11/snappy-python-incompatibility/</link>
        <guid isPermaLink="true">http://0.0.0.0:4000/2018/11/11/snappy-python-incompatibility/</guid>
        
        <category>Tech</category>
        
        
      </item>
    
  </channel>
</rss>
