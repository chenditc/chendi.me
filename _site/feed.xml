<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Di's Blog</title>
    <description></description>
    <link>http://localhost:4000/</link>
    <atom:link href="http://localhost:4000/feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Sun, 26 Apr 2020 11:32:23 +0800</pubDate>
    <lastBuildDate>Sun, 26 Apr 2020 11:32:23 +0800</lastBuildDate>
    <generator>Jekyll v4.0.0</generator>
    
      <item>
        <title>Tech Team Management Note</title>
        <description>&lt;h1 id=&quot;整体思路&quot;&gt;整体思路&lt;/h1&gt;
&lt;ol&gt;
  &lt;li&gt;每个人需求不同，单独沟通并在管理过程中尽量满足。需求包括：
    &lt;ul&gt;
      &lt;li&gt;职业发展需求&lt;/li&gt;
      &lt;li&gt;经济需求（薪资、奖金、期权）&lt;/li&gt;
      &lt;li&gt;个人成就需求&lt;/li&gt;
      &lt;li&gt;社会地位需求（办公环境、公司地位、公司福利）&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;以激发团队的主观能动性为主，以被动监督团队成员为辅。&lt;/li&gt;
  &lt;li&gt;公平交换。每个人只要有付出就有回报，同时相互理解，公司在个人遇到困难时给予灵活的支持和政策，个人在公司项目需要时额外加班或者做其他贡献。&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;具体措施&quot;&gt;具体措施&lt;/h1&gt;
&lt;h2 id=&quot;目标设定&quot;&gt;目标设定&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;设置跳一跳能够到的目标，不要太容易达到，也不要不切实际
 	- 研发：时间、难度、质量、工作量
 	- 测试：质量、工作量
 	- 产品、UI：质量、沟通效果、工作量&lt;/li&gt;
  &lt;li&gt;每个人的状态会波动，很正常。长期来看，保持相对紧凑，但是可完成的目标才是产能的最大化。对于每一个阶段的超额或者未达标可以给予一定反馈，但是不需要太夸张。&lt;/li&gt;
  &lt;li&gt;以能稳定完成，可预期为第一目标。如果无法预期结果，则无法保证项目的如期交付。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;目标评估&quot;&gt;目标评估&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;能直接评估的目标才有意义，如果没法评估的目标就只是个口号。&lt;/li&gt;
  &lt;li&gt;工作量由研发自己评估，自己估的同时，也作为一个 commitment，一个承诺。&lt;/li&gt;
  &lt;li&gt;工作质量由同事的代码审核和整体项目的结果评估。&lt;/li&gt;
  &lt;li&gt;沟通效果由同事之间的调查或者吐槽来评估。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;激励&quot;&gt;激励&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;激励越及时越好。&lt;/li&gt;
  &lt;li&gt;当员工付出了超额的努力，就需要有正反馈，结果未必好，但是如果没有正反馈，就不会有下一次努力。&lt;/li&gt;
  &lt;li&gt;多维度激励本质是提高激励的频率，拆得更细，让大家觉得自己的付出是被认可的。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;惩罚&quot;&gt;惩罚&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;惩罚越及时越好&lt;/li&gt;
  &lt;li&gt;惩罚由于主观原因导致的目的不达标。&lt;/li&gt;
  &lt;li&gt;口头批评但是不惩罚由于客观原因的不达标。&lt;/li&gt;
  &lt;li&gt;惩罚或者口头批评的同时给出提升的路径。&lt;/li&gt;
  &lt;li&gt;提升之后给予正反馈，口头或者物质都可以。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;背景沟通&quot;&gt;背景沟通&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;做的事情，为什么要做这个项目，为什么要做这个需求，做完之后效果如何，了解了背景才能在细节作出最利于整个项目的抉择。&lt;/li&gt;
  &lt;li&gt;对外的人做团队的信息过滤器，传递给团队之前先想一下，对团队有正面还是负面效果。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;知识沉淀和分享&quot;&gt;知识沉淀和分享&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;技术成就感的来源之一，项目一定会遇到难题，再简单的项目也有难题，解决之后能分享出来就会让人有一定成就感。&lt;/li&gt;
  &lt;li&gt;技术能力评估的重要来源之一。高级工程师必须要给团队带来提升，是高级工程师的一个 must。&lt;/li&gt;
  &lt;li&gt;团队认可度的重要来源之一，让团队其他成员觉得我们的团队是一个牛逼的团队。&lt;/li&gt;
  &lt;li&gt;应该要对知识分享的行为给予奖励。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;其他制度设定&quot;&gt;其他制度设定&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;在家办公制度是独特优势，在满足目标作为评估点的前提下，可以很大程度上吸引优秀人才加入团队。&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Fri, 24 Apr 2020 08:15:00 +0800</pubDate>
        <link>http://localhost:4000/2020/04/24/tech-management-notes/</link>
        <guid isPermaLink="true">http://localhost:4000/2020/04/24/tech-management-notes/</guid>
        
        <category>Tech</category>
        
        <category>Management</category>
        
        
      </item>
    
      <item>
        <title>直觉（Cover）</title>
        <description>&lt;blockquote&gt;
  &lt;p&gt;“我喜欢你的眼睛你的睫毛你的侧脸，喜欢你嘟着嘴巴说教我吐烟圈。”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;video width=&quot;100%&quot; poster=&quot;/img/in-post/cover/zhijue.jpg&quot; controls=&quot;&quot; preload=&quot;none&quot; type=&quot;video/mp4&quot;&gt;  
&lt;source src=&quot;http://video.chendi.me/videos/20200111-zhijue.mp4&quot; /&gt;  
&lt;/video&gt;

&lt;p&gt;喜欢歌词，单曲循环了好多遍，就想试着录一下了。
第一次还是有点紧张。&lt;/p&gt;
</description>
        <pubDate>Tue, 21 Jan 2020 04:15:00 +0800</pubDate>
        <link>http://localhost:4000/2020/01/21/zhijue-recording-studio/</link>
        <guid isPermaLink="true">http://localhost:4000/2020/01/21/zhijue-recording-studio/</guid>
        
        <category>生活</category>
        
        <category>Cover</category>
        
        
      </item>
    
      <item>
        <title>On premise log and metric collection</title>
        <description>&lt;h2 id=&quot;前言&quot;&gt;前言&lt;/h2&gt;

&lt;p&gt;在私有化部署的系统中，系统可能会多次进行分布式组件的部署，而在私有化部署的环境中，可能没有完善的日志收集、指标收集和分析的工具，为了能便捷地进行日志、指标的收集和分析，这里提出一个简单的 ELK 指标收集方案。&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;背景&quot;&gt;背景&lt;/h2&gt;

&lt;p&gt;在当前的项目中，我们已经使用了 Elasticsearch 作为业务的数据储存，同时利用 ansible、docker、jenkins 组合了一套快速部署的工具。在配置好需要部署主机的 ssh 连接信息后，我们可以通过 jenkins 一键部署一个 Elasticsearch 和 Kibana。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/img/in-post/on-premise-log-metric-collection/jenkins.png&quot;&gt;&lt;img src=&quot;/img/in-post/on-premise-log-metric-collection/jenkins.png&quot; alt=&quot;jenkins.png&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;需求分析&quot;&gt;需求分析&lt;/h3&gt;

&lt;p&gt;在私有化部署的环境中，日志的收集使用有几个特点：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;需要能快速部署。由于客户的数量较多，我们需要能快速地部署监控系统，监控系统本身的运维压力需要较小。&lt;/li&gt;
  &lt;li&gt;部署组件要简单，且健壮性强。由于部署环境较为复杂，希望每个组件自身是健壮的，同时组件之间的交互尽量简单，避免复杂的网络拓扑。&lt;/li&gt;
  &lt;li&gt;功能性优于稳定性。由于日志和指标信息本身在宿主主机和应用上是有副本的，所以即时监控系统的数据丢失了，影响也不大。但是如果系统能提供更多强大的功能，对于分析是很有帮助的。&lt;/li&gt;
  &lt;li&gt;性能要求不高。由于私有化环境对接系统的容量和复杂度可控，可以使用单机部署，同时查询慢一些也没关系。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;同时需要满足几个需求：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;需要能采集分布式的日志，并且集中式地查看&lt;/li&gt;
  &lt;li&gt;需要能采集机器的基本信息，例如 CPU、磁盘，并进行监控&lt;/li&gt;
  &lt;li&gt;最好能采集应用的数据，例如导入数据的条目数，并进行监控&lt;/li&gt;
  &lt;li&gt;最好能实现异常指标的告警功能&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;方案分析&quot;&gt;方案分析&lt;/h3&gt;

&lt;p&gt;方案上有3个备选方案：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;利用 ELK （Elasticsearch、Logstash、Kibana） 做整体的监控基础组件，同时使用 Elastic 新推出的 beat 系列作为采集工具。
&lt;a href=&quot;/img/in-post/on-premise-log-metric-collection/dashboard1.png&quot;&gt;&lt;img src=&quot;/img/in-post/on-premise-log-metric-collection/dashboard1.png&quot; alt=&quot;dashboard1.png&quot; /&gt;&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;利用 Zabbix、Open-Falcon 等运维监控工具进行系统基础组件的监控。同时利用自定义指标，进行数据的监控和告警。
&lt;a href=&quot;/img/in-post/on-premise-log-metric-collection/zabbix.png&quot;&gt;&lt;img src=&quot;/img/in-post/on-premise-log-metric-collection/zabbix.png&quot; alt=&quot;zabbix.png&quot; /&gt;&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;利用 TICK (Telegraph、InfluxDB、Chronograf、Kapacitor) 做整体的监控基础组件。
&lt;a href=&quot;/img/in-post/on-premise-log-metric-collection/grafana.jpg&quot;&gt;&lt;img src=&quot;/img/in-post/on-premise-log-metric-collection/grafana.jpg&quot; alt=&quot;grafana.jpg&quot; /&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;方案2和3在需求上不能很好满足日志的收集和查看功能，所以排除掉了，目前日志方面能比较好满足需求的只有开源的 ELK 和商业化的 Splunk，由于预算原因，Splunk 也被排除了。&lt;/p&gt;

&lt;p&gt;方案1(ELK)根据我们的需求进一步细化：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;需要能快速部署：通过我们的 Jenkins 可以实现一键部署的功能。&lt;/li&gt;
  &lt;li&gt;部署组件简单：我们只部署 Elasticsearch 和 Kibana 组件，同时 Elasticsearch 本身作为最基础的组件是自包含的，不依赖任何外部组件。而我们也不使用集群，只用单机部署，保证 Elasticsearch 部署的简单和稳定。&lt;/li&gt;
  &lt;li&gt;功能性优于稳定性：虽然业务使用的 Elasticsearch 停留在 5.5.3 版本，我们日志采集和分析使用的 Elasticsearch 直接升级到 7.6.0 版本，同时后续的版本升级也可以较为激进，如果遇到不兼容的情况，也不需要保留已有数据，删除数据重新部署即可。&lt;/li&gt;
  &lt;li&gt;性能要求不高：使用单机部署，Elasticsearch 和 Kibana 部署在同一台机器上。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;日志专用的elasticsearchkibanabeat&quot;&gt;日志专用的Elasticsearch、Kibana、Beat&lt;/h3&gt;

&lt;p&gt;为了避免日志使用的 ES 和业务使用的 ES 在资源或者配置上发生冲突，日志专用的 ES 单独做了一个部署，使用约 3G 内存。&lt;/p&gt;

&lt;p&gt;日志采集：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;我们在所有相关主机上使用 ansible 部署&lt;a href=&quot;https://www.elastic.co/beats/filebeat&quot;&gt;filebeat&lt;/a&gt; 进行日志的采集，为了简化系统，我们也没有使用 logstash 做日志的预处理，只是简单地配置了 filebeat 的配置文件，并加入了我们的 jenkins 一键部署套件中。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;日志的查看：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;由于日志直接通过 filebeat 收集到了 es 中，我们使用 Kibana 就能直接进行查看了。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&quot;/img/in-post/on-premise-log-metric-collection/filebeat.gif&quot;&gt;&lt;img src=&quot;/img/in-post/on-premise-log-metric-collection/filebeat.gif&quot; alt=&quot;filebeat.gif&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;系统指标收集：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;我们在所有相关主机上使用 ansible 部署 &lt;a href=&quot;https://www.elastic.co/beats/metricbeat&quot;&gt;metricbeat&lt;/a&gt; 进行指标的收集，通过配置文件的配置，可以采集到 docker 的资源使用、系统CPU、内存、磁盘、网络的使用状态，同时也开放了 statsd 格式的指标收集端口。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&quot;/img/in-post/on-premise-log-metric-collection/metricbeat.jpg&quot;&gt;&lt;img src=&quot;/img/in-post/on-premise-log-metric-collection/metricbeat.jpg&quot; alt=&quot;metricbeat.jpg&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;在现场状态检测：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;我们在网关机器上使用 ansible 部署 &lt;a href=&quot;https://www.elastic.co/beats/heartbeat&quot;&gt;heartbeat&lt;/a&gt; 进行主动的资源可用性探测，对系统相关的数据库、http服务等监控其相应状态，并将其发送至默认的 ES 储存索引中。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&quot;/img/in-post/on-premise-log-metric-collection/heartbeat.png&quot;&gt;&lt;img src=&quot;/img/in-post/on-premise-log-metric-collection/heartbeat.png&quot; alt=&quot;heartbeat.png&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;基于es的告警&quot;&gt;基于ES的告警&lt;/h3&gt;

&lt;p&gt;Elasticsearch 的告警是付费功能，所以这里用了一个开源的项目 &lt;a href=&quot;https://elastalert.readthedocs.io/en/latest/&quot;&gt;elastalert&lt;/a&gt; 实现告警。Elastalert 是 Yelp 公司（美国的大众点评）开发的基于 python 和 Elasticsearch 的告警系统，可以对接的告警途径很多，但是大部分都是国外的工具例如Slack、HipChat、PagerDuty，所以我们目前只使用了最基础的邮件告警功能。&lt;/p&gt;

&lt;p&gt;Elastalert 可以配置多种告警类型，例如&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;某条件连续触发 N 次（frequency类型）&lt;/li&gt;
  &lt;li&gt;某指标出现的频率增加或者减少（spike 类型）&lt;/li&gt;
  &lt;li&gt;N 分钟未检测到某指标（flatline类型）等。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;目前我们也只使用了最基础的 frequency 类型告警。&lt;/p&gt;

&lt;h3 id=&quot;监控大盘&quot;&gt;监控大盘&lt;/h3&gt;

&lt;p&gt;利用 Kibana 的可视化功能，我们可以针对每个业务系统创建一个监控大盘，直观地看到所有系统组件的情况，以及宿主主机的健康情况：&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/img/in-post/on-premise-log-metric-collection/dashboard1.png&quot;&gt;&lt;img src=&quot;/img/in-post/on-premise-log-metric-collection/dashboard1.png&quot; alt=&quot;dashboard1.png&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/img/in-post/on-premise-log-metric-collection/dashboard2.png&quot;&gt;&lt;img src=&quot;/img/in-post/on-premise-log-metric-collection/dashboard2.png&quot; alt=&quot;dashboard2.png&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/img/in-post/on-premise-log-metric-collection/dashboard3.png&quot;&gt;&lt;img src=&quot;/img/in-post/on-premise-log-metric-collection/dashboard3.png&quot; alt=&quot;dashboard3.png&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;扩展监控范围&quot;&gt;扩展监控范围&lt;/h3&gt;
&lt;h4 id=&quot;监控更多的应用组件&quot;&gt;监控更多的应用组件&lt;/h4&gt;
&lt;p&gt;当我们需要监控新增的应用组件时。&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;对于服务状态，我们可以简单地将应用组件的访问地址加入 hearbeat 的配置中，就可以在监控面板看到对应组件的状态了。&lt;/li&gt;
  &lt;li&gt;对于应用日志，我们可以将日志的文件路径加入 filebeat 的配置中，就可以在 Kibana 中搜索到了。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;监控应用相关的指标&quot;&gt;监控应用相关的指标&lt;/h4&gt;
&lt;p&gt;当我们需要监控应用相关的指标时，我们可以通过 statsd 的接口，将指标发布至 metricbeat，统一收集至 Elasticsearch 当中。 statsd 底层规则相对简单，所以在每个编程语言中都有相应的 SDK 可以直接使用，并没有复杂的依赖： &lt;a href=&quot;https://github.com/statsd/statsd/wiki&quot;&gt;https://github.com/statsd/statsd/wiki&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;但是目前 metricbeat 收集来的 statsd 信息是不支持 tag 的，所以还只能做一些简单的指标收集，并不能对同一指标的不同维度做聚合分析。&lt;/strong&gt;&lt;/p&gt;

&lt;h4 id=&quot;增加服务-tracing&quot;&gt;增加服务 tracing&lt;/h4&gt;
&lt;p&gt;Elasticsearch 当中也带了 APM 服务 &lt;a href=&quot;/img/in-post/on-premise-log-metric-collection/tracing.png&quot;&gt;&lt;img src=&quot;/img/in-post/on-premise-log-metric-collection/tracing.png&quot; alt=&quot;tracing.png&quot; /&gt;&lt;/a&gt; 这个暂时还没有尝试接入，如果可以使用的话，是一个性能监控和分析的利器。&lt;/p&gt;

&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;
&lt;p&gt;私有化部署的环境中，日志的收集和监控不像互联网产品一样需要较强的性能和可扩容性，开箱即用和功能的强大就较为重要。7.6.0 版本的 Elasticsearch 和 Kibana 在这方面能很好地满足需求，只需要对部署流程进行标准化，并提前准备好配置文件，就可以在半小时内搭建好一整套监控体系。&lt;/p&gt;
</description>
        <pubDate>Tue, 03 Dec 2019 08:15:00 +0800</pubDate>
        <link>http://localhost:4000/2019/12/03/on-premise-log-metric-collection/</link>
        <guid isPermaLink="true">http://localhost:4000/2019/12/03/on-premise-log-metric-collection/</guid>
        
        <category>Tech</category>
        
        <category>ELK</category>
        
        
      </item>
    
      <item>
        <title>Performance Optimization</title>
        <description>&lt;h2 id=&quot;前言&quot;&gt;前言&lt;/h2&gt;

&lt;p&gt;在工作中发现关于性能优化相关的工作，大部分人都较少涉猎，也缺少相关的经验，所以把我的经验记录下来，抛砖引玉。&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;需求&quot;&gt;需求&lt;/h2&gt;

&lt;h3 id=&quot;性能需求&quot;&gt;性能需求&lt;/h3&gt;

&lt;p&gt;在一个系统运行的过程中，遇到性能上的需求无法满足是非常常见的。例如：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;一个 HTTP 服务器的某个请求响应时间过长。&lt;/li&gt;
  &lt;li&gt;一个消息队列同时可以发送、储存的消息数量不足。&lt;/li&gt;
  &lt;li&gt;一个脚本的执行时间过长。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;高性能往往可以具体拆解为低延迟和高吞吐量。只不过对于每个系统来说，低延迟和高吞吐量的衡量标准有所不同。在开始进行性能优化之前，我们先要确定需要优化的是什么。&lt;/p&gt;

&lt;h3 id=&quot;性能优化思路&quot;&gt;性能优化思路&lt;/h3&gt;

&lt;p&gt;对于大部分的系统来说，性能优化都可以拆解为几个通用步骤：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;性能测量。针对需要优化的系统，确认一个可重复、可测量的指标作为性能的衡量标准。优化目标就是将该指标增大或者减小。&lt;/li&gt;
  &lt;li&gt;性能分析。针对我们需要优化的系统，分析系统完成特定任务时进行过的操作，以及各操作所消耗的时间、资源。&lt;/li&gt;
  &lt;li&gt;尝试优化方案。根据上一步得到的信息，进行理论上的分析，找到可以进行优化的方案，并尝试实施对应方案。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;a href=&quot;/img/in-post/performance-optimization/performance-optimization-progress.png&quot;&gt;&lt;img src=&quot;/img/in-post/performance-optimization/performance-optimization-progress.png&quot; alt=&quot;performance-optimization-progress.png&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;下面我抛出3个常见的优化场景，并且举几个例子说明怎样将这个优化思路落地：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;低延迟优化：有一个 Django 服务的某个请求响应时间过长，需要 3 秒左右返回。&lt;/li&gt;
  &lt;li&gt;高吞吐量优化：有一个消息队列同时可以发送的消息数为 5000 条/秒，需要能达到 50000 条/秒。&lt;/li&gt;
  &lt;li&gt;低延迟优化：有一个 python 脚本的执行时间过长，需要 20 分钟完成。&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;性能的衡量标准&quot;&gt;性能的衡量标准&lt;/h4&gt;

&lt;p&gt;对于低延迟的系统，衡量标准就是时间，在完成某个特定任务的情况下，衡量每个任务的完成时间。在衡量时需要尽量保证可重复、可测量。&lt;/p&gt;

&lt;p&gt;可重复：对于许多系统的优化任务来说，不符合需求的性能场景可能无法稳定复现，例如响应时间过长的问题不是每个请求都会出现。那么我们的第一件事是找到复现这个响应时间过长的情况。因为如果响应时间过长的问题不是稳定出现的话，做出来的性能分析也不是针对出问题的场景，那我们就没办法进一步做性能分析了。如果系统的表现不稳定的话，可以尝试将衡量的组件范围减少，当每次执行任务的时候涉及的组件、模块、功能越少，则表现也就相对会越稳定。&lt;/p&gt;

&lt;p&gt;可测量：对于系统优化的任务，一定要有一个可测量的指标用于衡量性能。如果不能测量，只是靠感觉的话，那优化任务就没有一个尽头了。所以一定要有一个可测量的指标，用于衡量优化的效果。&lt;/p&gt;

&lt;h4 id=&quot;性能的分析方法&quot;&gt;性能的分析方法&lt;/h4&gt;

&lt;p&gt;性能的分析主要目的是：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;对于延迟类的性能需求，找到时间花在哪了。&lt;/li&gt;
  &lt;li&gt;对于吞吐量的性能需求，找到当吞吐量达到最大值时，同时达到瓶颈的资源。这个瓶颈可能是网络带宽、磁盘 IO、端口数等等。&lt;/li&gt;
&lt;/ol&gt;

&lt;h5 id=&quot;系统延迟的分析&quot;&gt;系统延迟的分析&lt;/h5&gt;

&lt;p&gt;当我们要分析时间花在哪的时候，首先尽量把任务隔离成单线程/单进程任务，对每个线性处理流程分析完毕后，再进行多线程/多进程的分析，这样可以隔离分析的复杂度。&lt;/p&gt;

&lt;h6 id=&quot;线性系统的profiling&quot;&gt;线性系统的Profiling&lt;/h6&gt;

&lt;p&gt;要找时间花在哪时，一定会用到 Profile。Profile 的意思是测量，测量一段代码的时间使用/内存使用/IO使用情况。对于每个系统，Profile 的方法会有所区别。这里拿代码的执行时间使用的 Profile 做例子。&lt;/p&gt;

&lt;p&gt;对于一段 Python 代码，常用的工具可以用 cProfile，cProfile 内置在 Python 的标准库中，可以将每个方法调用所消耗的时间记录下来：&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;err&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;python3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cProfile&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cumtime&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_smtp&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;py&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;less&lt;/span&gt;

&lt;span class=&quot;p&quot;&gt;{}&lt;/span&gt;
         &lt;span class=&quot;mi&quot;&gt;36884&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;function&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;calls&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;35925&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;primitive&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;calls&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.438&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seconds&lt;/span&gt;

   &lt;span class=&quot;n&quot;&gt;Ordered&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;by&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cumulative&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;

   &lt;span class=&quot;n&quot;&gt;ncalls&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;tottime&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;percall&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;cumtime&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;percall&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lineno&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
     &lt;span class=&quot;mi&quot;&gt;52&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;0.003&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;0.000&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;0.438&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;0.438&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;built&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;method&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;builtins&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;exec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;0.000&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;0.000&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;0.438&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;0.438&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_smtp&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;py&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;module&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;0.000&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;0.000&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;0.237&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;0.034&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;smtplib&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;py&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;369&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;getreply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
       &lt;span class=&quot;mi&quot;&gt;12&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;0.000&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;0.000&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;0.237&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;0.020&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;method&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'readline'&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'_io.BufferedReader'&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;objects&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;0.000&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;0.000&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;0.237&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;0.034&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;socket&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;py&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;572&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;readinto&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;0.000&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;0.000&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;0.237&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;0.034&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ssl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;py&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1001&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;recv_into&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;0.000&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;0.000&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;0.237&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;0.034&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ssl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;py&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;866&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;上面的这个信息也可以导出一个文件后，通过第三方的画图工具，画成一个火焰图，火焰图可以更直观地对每个函数之间的调用关系和耗时进行下钻分析。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/img/in-post/performance-optimization/flame_graph.png&quot;&gt;&lt;img src=&quot;/img/in-post/performance-optimization/flame_graph.png&quot; alt=&quot;flame_graph.png&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;同理，对于 java、c++ 可以用 VTune 之类的工具，在执行代码的同时记录每个函数的执行时间。在 Google 上搜索 语言 + profile 一般就可以找到适合的分析器了&lt;/p&gt;

&lt;p&gt;在看到了每个函数的执行时间之后，我们分析可优化的点就可以按照几个思路来推进：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;分析耗时最长的部分。由于我们能看到每个部分的耗时，从耗时最长的部分一层层往下找，看是否有可以优化的地方。&lt;/li&gt;
  &lt;li&gt;分析耗时是否合理。分析耗时的合理性时，要从两方面分析，
    &lt;ul&gt;
      &lt;li&gt;整体执行的代码内容是否合理，是否调用了不需要调用的代码。例如在一个循环内不断调用 SQL 查询语句，是一个常见的不该出现的情况，在使用 ORM 时，如果没注意联合查询的使用，会导致调用大量的 SQL 从而拖慢整体速度。或者在一个循环内不断出现 fetch_many 的数据库调用，可能是查询时拉取了文本或者 glob 字段的内容，导致每个批次数据拉取速度比较慢。&lt;/li&gt;
      &lt;li&gt;代码内每个步骤的时间是否合理。有一部分操作可能在代码的 profile 上看不出细节，例如将一个文本类型的时间转为时间对象，在格式不确定的情况下需要穷举可能匹配的格式（YYYY-DD-MM 或者 YYYY-MM-DD)，会耗时很长 ～200ms。但是在格式确定的情况下，通过正则或者原声的 strptime 这类方法，可以利用正则状态机的方法，实现 O(1) 的转换时间，约 ～1ms。或者例如一个看起来简单的 sql 的执行可能花了10秒的时间，但是从代码的 profile 上看不出为什么花了10秒的时间。此时就可以用 sql 的 profile 分析器去查看 sql 执行的每个步骤所花的时间。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;代码执行的逻辑是否可以优化。例如 O(n^2) 的代码是否可以通过缓存简化为 O(n)。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;对于 SQL 语句的性能分析，我们可以使用 SQL 分析器，也叫 sql 解释器，在 Google 上搜索 具体的数据库 + “sql analyzer” 一般就可以找到适合的工具了。&lt;/p&gt;

&lt;p&gt;SQL 分析器可以把 sql 语句的执行过程拆解为在数据库端的索引查询、原文提取等步骤，利用这个信息，我们可以进一步分析数据库端，整体时间消耗在了哪，例如是不是有缺少索引导致的全表扫描，或者缺少联合索引导致的大数据量的 join。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/img/in-post/performance-optimization/sql_analyzer.png&quot;&gt;&lt;img src=&quot;/img/in-post/performance-optimization/sql_analyzer.png&quot; alt=&quot;sql&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;同理，对于 Elasticsearch 等 NoSQL 数据库，也可以利用 Kibana 中的 Profile 工具，查看 Elasticsearch 搜索时底层的耗时，从而判断可以进行优化的点。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/img/in-post/performance-optimization/es_profile.png&quot;&gt;&lt;img src=&quot;/img/in-post/performance-optimization/es_profile.png&quot; alt=&quot;es_profile&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;对于一些较复杂的问题，可能会涉及到更低层的 profiling，例如我们发现某个文件的读写花的时间比预期长，那我们可以使用 strace 对每个 system call 的耗时进行 profile，例如 open, fstat 等。或者我们发现某个 tcp 连接的耗时较长，那我们可以使用 tcpdump 对 tcp 的三次握手包进行抓包，通过在不同节点进行抓包，可以找到网络请求慢的节点，从而进一步分析。&lt;/p&gt;

&lt;h6 id=&quot;django的在线性能分析&quot;&gt;Django的在线性能分析&lt;/h6&gt;

&lt;p&gt;针对目前公司内使用的 Django 框架，可以使用 silk 库进行性能分析。由于性能分析需要测量并记录大量数据，会极大影响整体的性能，我们需要能在生产环境或者测试环境便捷地开关性能分析。此时可以对 silk 的接入做一些改造，通过环境变量控制是否打开性能分析。&lt;/p&gt;

&lt;p&gt;settings.py&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ENABLE_SILK = os.environ.get(&quot;ENABLE_SILK&quot;, &quot;False&quot;).lower() == &quot;true&quot;

if ENABLE_SILK:
    INSTALLED_APPS.append(&quot;silk&quot;)
    MIDDLEWARE.append('silk.middleware.SilkyMiddleware')
    # 启用cProfiler
    SILKY_PYTHON_PROFILER = True
    # 查看SILK本身带来的延迟
    SILKY_META = True
    # 最多储存 1000 条数据
    SILKY_MAX_RECORDED_REQUESTS = 10**3
    SILKY_MAX_RECORDED_REQUESTS_CHECK_PERCENT = 10
    # 动态profile
    SILKY_DYNAMIC_PROFILING = []
    # eg. 通过配置修改需要profile哪些代码 
    # export ENABLE_SILK=true
    # export SILK_MODULE=users.views
    # export SILK_FUNCTION=UserAccountLogin.post
    silk_module = os.environ.get(&quot;SILK_MODULE&quot;)
    silk_function = os.environ.get(&quot;SILK_FUNCTION&quot;)
    if silk_module is not None and silk_function is not None:
        SILKY_DYNAMIC_PROFILING.append({
            'module': silk_module,
            'function': silk_function
        }) 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;通过环境变量，我们可以通过控制 ENABLE_SILK 来开启或关闭 silk 是否加入 middleware 中。从而可以看到整体系统的请求延迟统计。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/img/in-post/performance-optimization/silk1.png&quot;&gt;&lt;img src=&quot;/img/in-post/performance-optimization/silk1.png&quot; alt=&quot;silk1.png&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;同时，我们也可以通过 SILK_MODULE 和 SILK_FUNCTION 来使用 SILKY_DYNAMIC_PROFILING 的功能，动态地配置 silk 对某个类的某个函数进行 profile。看到每个请求具体在每一行代码的耗时，以及其中调用过的 SQL 和对应 SQL 的耗时。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/img/in-post/performance-optimization/silk2.png&quot;&gt;&lt;img src=&quot;/img/in-post/performance-optimization/silk2.png&quot; alt=&quot;silk2.png&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/img/in-post/performance-optimization/silk3.png&quot;&gt;&lt;img src=&quot;/img/in-post/performance-optimization/silk3.png&quot; alt=&quot;silk3.png&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h5 id=&quot;系统吞吐量的分析&quot;&gt;系统吞吐量的分析&lt;/h5&gt;

&lt;p&gt;对于系统吞吐量的性能分析会相对比较复杂，一个系统的吞吐量瓶颈来源一般是系统中某个节点的资源瓶颈，例如 CPU、内存、磁盘、网络、文件句柄、端口数、线程池等等。这个时候我一般会把整个系统拆分为可以独立测试的子系统，例如 mock 一个子系统的输入，通过压测的方式判断这个子系统的吞吐量上限，从而判断在实际环境中，可能达到上限的资源使用量是多少。&lt;/p&gt;

&lt;p&gt;例如一个常见的后端系统中，可能会涉及到 MySQL、ES、后端的HTTP服务器、负载均衡。此时对每个组件做压力测试后，我们可以了解到&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;MySQL 常见的瓶颈为 CPU、连接数、内存大小&lt;/li&gt;
  &lt;li&gt;ES 常见的瓶颈为网络 IO，磁盘IO延迟，数据解析的节点的 CPU&lt;/li&gt;
  &lt;li&gt;后端的 HTTP 服务器常见的瓶颈是 CPU、内存&lt;/li&gt;
  &lt;li&gt;负载均衡的瓶颈是端口数、CPU、网络带宽&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;那么此时我们对整个系统就可以建立一个监控面板，在压测的同时观察哪个子系统的资源先达到瓶颈，再针对性的提出优化方案，例如扩容对应子系统的资源。&lt;/p&gt;

&lt;h4 id=&quot;常见系统性能优化方案&quot;&gt;常见系统性能优化方案&lt;/h4&gt;

&lt;h5 id=&quot;缓存&quot;&gt;缓存&lt;/h5&gt;
&lt;p&gt;业界常说 90% 的性能优化都是在加缓存，确实有许多问题是可以通过空间换时间，对代码关键路径上静态的信息做缓存实现，同时整个系统中对于大数据流的关键路径，也是可以尝试用缓存实现优化。&lt;/p&gt;

&lt;p&gt;同时一部分数据从磁盘缓存到内存里，或者从远程机器缓存到本地机器，也是一个常见的缓存思路。&lt;/p&gt;

&lt;h5 id=&quot;优化数据库查询&quot;&gt;优化数据库查询&lt;/h5&gt;
&lt;p&gt;另外一个常见的优化方向是数据库查询。目前大部分的业务逻辑还是使用 SQL 数据库来完成的，而数据库的复杂查询往往也是耗时较多的一个来源。例如查询时对涉及的字段加索引，或者优化查询语句，只提取需要的字段，避免 select * 语句。&lt;/p&gt;

&lt;p&gt;数据库查询的优化在进行时，也是可以遵循上述的先 profile 分析，再优化的方式，避免瞎猜测原因。&lt;/p&gt;

&lt;h4 id=&quot;性能的分析工具以及阅读材料&quot;&gt;性能的分析工具以及阅读材料&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://docs.python.org/3.6/library/profile.html&quot;&gt;cProfile - Python profile https://docs.python.org/3.6/library/profile.html&lt;/a&gt; Python 内置的 profiler&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://software.intel.com/zh-cn/vtune&quot;&gt;因特尔 Vtune https://software.intel.com/zh-cn/vtune&lt;/a&gt; 支持几乎所有主流编程语言 C / C++ / C# / Fortran / Java / Python / Go / 汇编&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://www.brendangregg.com/flamegraphs.html&quot;&gt;火焰图 Flame graph http://www.brendangregg.com/flamegraphs.html&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

</description>
        <pubDate>Fri, 01 Nov 2019 08:15:00 +0800</pubDate>
        <link>http://localhost:4000/2019/11/01/performance-optimization/</link>
        <guid isPermaLink="true">http://localhost:4000/2019/11/01/performance-optimization/</guid>
        
        <category>Tech</category>
        
        <category>Linux</category>
        
        
      </item>
    
      <item>
        <title>Weird bugs - 4</title>
        <description>&lt;h2 id=&quot;前言&quot;&gt;前言&lt;/h2&gt;

&lt;p&gt;这次记录的 bug 是主要是涉及网络知识比较多，排查中主要用到了 tcpdump 以及一些运气。&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;问题以及排查过程&quot;&gt;问题以及排查过程&lt;/h2&gt;

&lt;h3 id=&quot;问题表象&quot;&gt;问题表象&lt;/h3&gt;

&lt;p&gt;在一台 vmware 部署的 Redhat 系统上安装 docker，使用的是阿里云的镜像源，安装命令如下&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;yum remove  docker \
            docker-client \
            docker-client-latest \
            docker-common \
            docker-latest \
            docker-latest-logrotate \
            docker-logrotate \
            docker-selinux \
            docker-engine-selinux \
            docker-engine
 
 
# Set up repository
sudo yum install -y yum-utils device-mapper-persistent-data lvm2
  
# Use Aliyun Docker
sudo yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo
 
 
# install the latest version docker
yum install docker-ce
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;在安装完成后发现 docker 可以正常启动，未报错，但是启动后对应的 http 端口无法连通，具体表现为错误 “curl: (56) Recv Failure: Connection reset by peer.”&lt;/p&gt;

&lt;h3 id=&quot;问题排查和解决&quot;&gt;问题排查和解决&lt;/h3&gt;

&lt;h4 id=&quot;定位错误组件&quot;&gt;定位错误组件&lt;/h4&gt;
&lt;p&gt;首先尝试进行横向分段排查，定位具体是哪个组件为正常运行。&lt;/p&gt;

&lt;p&gt;docker 所在的主机 ip 为 10.0.10.1
docker 建立的 NAT 网段为 172.17.0.1/16
启动的 docker 对外暴露的端口为 9200，启动命令类似：&lt;code class=&quot;highlighter-rouge&quot;&gt;docker run -p 9200:9200 mydocker&lt;/code&gt;
启动后的 docker 在 docker 的网段内 ip 为 172.17.0.2&lt;/p&gt;

&lt;p&gt;首先尝试在宿主主机访问对应端口： &lt;code class=&quot;highlighter-rouge&quot;&gt;$ curl 10.0.10.1:9200&lt;/code&gt;，报 “No route to host” 错误。
同时尝试使用 telnet 连接该端口 &lt;code class=&quot;highlighter-rouge&quot;&gt;$ telnet 10.0.10.1:9200&lt;/code&gt;，同样报 “No route to host” 错误。我们知道 tcp 连接的第一步是三次握手建立连接，报 “No route to host” 说明连握手都无法完成，问题应该出在网络的第4层以下。&lt;/p&gt;

&lt;p&gt;在宿主主机上尝试 ping 对应的 docker NAT 网关内的 ip：&lt;code class=&quot;highlighter-rouge&quot;&gt;$ping 172.17.0.2&lt;/code&gt;，发现ping不通。尝试反向ping，从 docker 内 ping 172.17.0.1 发现也无法 ping 通，说明 docker 的网桥可能未正常工作。&lt;/p&gt;

&lt;p&gt;docker 的网络包是通过 iptables 进行配置转发的，所以首先排查宿主主机上的 iptables 配置是否正常。
&lt;code class=&quot;highlighter-rouge&quot;&gt;$ iptables --list&lt;/code&gt; 查看所有 iptables 规则，iptables 内 DOCKER-USER 和 DOCKER 是检验所有发到 docker 容器的规则，这两部分在主机的 iptables 配置里都是空的，或 all anywhere，所以理论上不会对 tcp 包进行拦截。这部分没发现有异常。&lt;/p&gt;

&lt;p&gt;接下来尝试使用 tcpdump 抓流量包，查看在链路的哪个部分无法连通。还是使用分段排查的方式，先排查 docker0 网卡的流量包，看是否包含 telnet 的握手请求。使用 &lt;code class=&quot;highlighter-rouge&quot;&gt;$tcpdump -w docker.pcap -i docker0&lt;/code&gt; 在一个 ssh 窗口中进行抓包，然后使用 &lt;code class=&quot;highlighter-rouge&quot;&gt;$telnet 172.17.0.1 9200&lt;/code&gt; 发起 tcp 连接。此时发现了一个奇怪的现象，在 tcpdump 运行的时候，所有网络请求都能通了！ telnet 可以正常连接，curl 命令也能返回预期的信息。关闭 tcpdump 后，又变回了原来无法连通的情况。&lt;/p&gt;

&lt;h4 id=&quot;解决方法&quot;&gt;解决方法&lt;/h4&gt;

&lt;p&gt;根据之前发现的情况，Google 搜索 “docker tcpdump 抓包后通了”，发现了一篇类似情况的排查博客：&lt;a href=&quot;https://ieevee.com/tech/2016/11/24/promisc.html&quot;&gt;从混杂模式开始说起&lt;/a&gt;。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;但前几天BJ机房掉电，重启后发现宿主机无法登陆，网络不通。ipmi登陆上去，检查team0状态、br0状态都正常，tcpdump抓包发现，报文能够到达team0的子接口(eno0），但无法送到br0，因此ping宿主机不通。&lt;/p&gt;

  &lt;p&gt;偶然发现，从外面ping宿主机网络，如果在team0口、eno0口都执行tcpdump，宿主机、docker容器，网络均可达。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;从现象上看，他遇到的问题和我的表现是一样的。在该博客中也提到了该问题的根源：物理网卡进入了混杂模式，但是子接口并没有进入，导致子接口无法获取对应的网络包。我在问题宿主主机上做了验证：&lt;/p&gt;

&lt;p&gt;查看系统日志，并计算进入混杂模式但是未退出的网卡：&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ cat /var/log/messages | grep promisc | grep enter | cut -d &quot; &quot; -f 8 | sort | uniq -c | sort -n &amp;gt; card_list_enter
$ cat /var/log/messages | grep promisc | grep enter | cut -d &quot; &quot; -f 8 | sort | uniq -c | sort -n &amp;gt; card_list_left
$ diff card_list_enter card_list_left
...
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;上面的 shell 先统计了所有网卡进入混杂模式的次数，然后统计了所有网卡退出混杂模式的次数，再 diff 找到进入了混杂模式，但是未退出的网卡。然后再去 &lt;code class=&quot;highlighter-rouge&quot;&gt;$cat /sys/class/net/docker0/flags&lt;/code&gt;, 看具体的标志位是否打开，发现除了 docker0 网卡之外，其他有若干网卡打开了混杂模式。而同时，查看 &lt;code class=&quot;highlighter-rouge&quot;&gt;/var/log/messages&lt;/code&gt; 也发现每次 tcpdump 的时候，docker0 网卡都会进入混杂模式。&lt;/p&gt;

&lt;p&gt;尝试使用命令 &lt;code class=&quot;highlighter-rouge&quot;&gt;$ifconfig docker0 PROMISC&lt;/code&gt; 手动打开 docker0 的混杂模式后，docker 就能正常运行了。&lt;/p&gt;

&lt;h3 id=&quot;原理&quot;&gt;原理&lt;/h3&gt;

&lt;h4 id=&quot;混杂模式是什么&quot;&gt;混杂模式是什么&lt;/h4&gt;

&lt;h4 id=&quot;为什么tcpdump需要打开对应网卡的混杂模式&quot;&gt;为什么tcpdump需要打开对应网卡的混杂模式&lt;/h4&gt;

&lt;h4 id=&quot;为什么不混杂模式无法连接主机&quot;&gt;为什么不混杂模式无法连接主机&lt;/h4&gt;

&lt;h3 id=&quot;推荐阅读&quot;&gt;推荐阅读&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://docs.docker.com/network/iptables/&quot;&gt;Docker and iptables&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://ieevee.com/tech/2016/11/24/promisc.html&quot;&gt;从混杂模式开始说起&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;p&gt;如果你看到这里，一定是真爱！欢迎看看我的其他 &lt;a href=&quot;http://chendi.me/&quot;&gt;blog&lt;/a&gt;。O(∩_∩)O&lt;/p&gt;
</description>
        <pubDate>Mon, 07 Oct 2019 08:15:00 +0800</pubDate>
        <link>http://localhost:4000/2019/10/07/weird-bug-4/</link>
        <guid isPermaLink="true">http://localhost:4000/2019/10/07/weird-bug-4/</guid>
        
        <category>Tech</category>
        
        <category>Bug</category>
        
        <category>Linux</category>
        
        
      </item>
    
      <item>
        <title>Sync Outlook Calendar And Conference Room</title>
        <description>&lt;h2 id=&quot;起因&quot;&gt;起因&lt;/h2&gt;

&lt;p&gt;由于系统A实现上的需求，我们需要将 outlook 中的会议室的使用信息，以及对应每个用户的日程信息同步至内部开发的系统A中。主要需求包括：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;outlook上的会议室使用情况涉及到不使用系统A的用户，所以outlook上的会议室预约信息会比系统A中的多，我们需要把这些额外的预约信息同步至系统A中，这样系统A中的用户在预约会议室时，可以考虑到其他用户的冲突。&lt;/li&gt;
  &lt;li&gt;用户已经习惯使用 outlook 将日程和会议室信息同步至手机端，所以系统A中增加的日程需要同步至 outlook 中，包括会议室订阅也需要增加。&lt;/li&gt;
  &lt;li&gt;当系统A中日程的属性变化时，outlook中需要对应发生变化。&lt;/li&gt;
  &lt;li&gt;当outlook中日程的属性发生变化时，系统A中也需要对应发生变化&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;探索调研&quot;&gt;探索调研&lt;/h2&gt;

&lt;h3 id=&quot;搭建测试环境&quot;&gt;搭建测试环境&lt;/h3&gt;

&lt;p&gt;为了便于测试，我们需要搭建一套基于 outlook 的邮件以及会议室系统，这里需要以下资源：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Windows Server 2012r2.
    &lt;ul&gt;
      &lt;li&gt;2 核心&lt;/li&gt;
      &lt;li&gt;16G 内存&lt;/li&gt;
      &lt;li&gt;300G 磁盘&lt;/li&gt;
      &lt;li&gt;云服务商上对外 25 端口默认是禁止使用的，需要单独申请开放，例如 &lt;a href=&quot;https://help.aliyun.com/knowledge_detail/56130.html&quot;&gt;阿里云25端口解封&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;在 1 中的 windows 服务器上配置 AD 以及 Exchange Server 2016&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;需要配置一个域名以及 DNS 记录
    &lt;ul&gt;
      &lt;li&gt;需要给 exchange 服务器挂一个域名，例如 mail.abc.com，这个会作为邮件发送的服务器地址。&lt;/li&gt;
      &lt;li&gt;需要配置 autodiscover 域名，例如 autodiscover.abc.com，这个域名会用来给客户端自动发现邮箱配置。&lt;/li&gt;
      &lt;li&gt;需要配置一条 MX 记录，主机名 @，记录指向 mail.abc.com&lt;/li&gt;
      &lt;li&gt;域名最好能申请 CA 签发的正规 https 证书，否则用自签名证书可能会遇到诸多不便。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;配置用户以及模拟权限&quot;&gt;配置用户以及模拟权限&lt;/h3&gt;

&lt;p&gt;我们需要为系统A建立一个服务账号，这个账号的会使用代码进行登录。同时，我们希望这个账号可以代所有其他用户账号管理会议日程信息，所以我们需要赋予这个账号 Impersonation 权限，也叫模拟权限。&lt;/p&gt;

&lt;p&gt;我们可以通过后台管理 ecp 界面上的权限管理配置服务账号的权限：
&lt;a href=&quot;/img/in-post/outlook-calendar/pic1.png&quot;&gt;&lt;img src=&quot;/img/in-post/outlook-calendar/pic1.png&quot; alt=&quot;pic1&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;其中配置的 ApplicationImpersonation 会赋予其模拟他人账号登录的权限
&lt;a href=&quot;/img/in-post/outlook-calendar/pic2.png&quot;&gt;&lt;img src=&quot;/img/in-post/outlook-calendar/pic2.png&quot; alt=&quot;pic2&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;同时，我们也需要建立几个会议室邮箱，这样我们才能有公共的 “会议室” 以供预定。&lt;/p&gt;

&lt;h3 id=&quot;exchangelib的使用&quot;&gt;exchangelib的使用&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/ecederstrand/exchangelib&quot;&gt;exchangelib&lt;/a&gt; 提供了一个可以使用 python 代码访问 exchange 服务的库，并且在使用上去 Django 的 ORM 极其类似。&lt;/p&gt;

&lt;p&gt;安装：
&lt;code class=&quot;highlighter-rouge&quot;&gt;pip3 install exchangelib&lt;/code&gt;&lt;/p&gt;

&lt;h4 id=&quot;登陆-exchange-账号&quot;&gt;登陆 exchange 账号&lt;/h4&gt;

&lt;p&gt;如果 exchange 服务器使用的是自签名的 https 证书，则需要跳过 https 证书验证环节：&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# 自签名服务器需要跳过 HTTPS 的证书检查
&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;exchangelib.protocol&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BaseProtocol&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;NoVerifyHTTPAdapter&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;BaseProtocol&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;HTTP_ADAPTER_CLS&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;NoVerifyHTTPAdapter&lt;/span&gt;

&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;urllib3&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;urllib3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;disable_warnings&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;声明登陆服务器所使用的版本号、账号、密码、服务器连接地址：&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;version&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Version&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;build&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Build&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;15&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;12&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;34&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;credentials&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Credentials&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'administrator'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'xxxxxxx'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Configuration&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;server&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'mail.abc.com'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;credentials&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;credentials&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;version&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;version&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;auth_type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;NTLM&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;以用户 abc 的身份登陆，IMPERSONATION 字段表示以用之前配置的账号密码，模拟用户 zhangsan@abc.com 登陆：&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;account&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Account&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'zhangsan@abc.com'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;credentials&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;credentials&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;access_type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;IMPERSONATION&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;创建新的日程&quot;&gt;创建新的日程&lt;/h4&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# 新建一个日程对象
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;new_meeting&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;CalendarItem&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;account&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;account&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# 需要绑定一个发起人账号
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;folder&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;account&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;calendar&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# 默认加入该账号的日历文件夹
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;account&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;default_timezone&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;localize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;EWSDateTime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2019&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;21&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;#带时区的开始和结束时间
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;end&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;account&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;default_timezone&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;localize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;EWSDateTime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2019&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;21&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;#带时区的开始和结束时间
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;subject&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;final test 6&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# 会议名称
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;body&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Hello from Python'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# 会议内容
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;location&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'2楼广寒宫'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# 会议室地点，只需要文字描述，与实际会议室账号无关
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;required_attendees&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'abc@abc.com'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;guanghan@abc.com&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;new_meeting&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;save&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;send_meeting_invitations&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SEND_TO_ALL_AND_SAVE_COPY&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 切换至会议室账号并接受邀请
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;room_account&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Account&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'guanghan@abc.com'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;credentials&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;credentials&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;access_type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;IMPERSONATION&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;item&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;room_account&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;calendar&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;all&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;order_by&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'-datetime_received'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;accept&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;注意：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;如果需要对这个日程绑定一个会议室，需要将这个会议室对应的邮箱加到参与者列表里，然后再更换登录账号，接受所有的会议邀请。&lt;/li&gt;
  &lt;li&gt;保存时需要增加参数 &lt;code class=&quot;highlighter-rouge&quot;&gt;send_meeting_invitations=SEND_TO_ALL_AND_SAVE_COPY&lt;/code&gt;，否则参与者不会收到邀请信息。&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;查询日程并以某条件过滤&quot;&gt;查询日程并以某条件过滤&lt;/h4&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;start&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;account&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;default_timezone&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;localize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;EWSDateTime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2019&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;21&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;end&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;account&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;default_timezone&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;localize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;EWSDateTime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2019&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;21&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;items&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;account&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;calendar&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;last_modified_time__range&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;end&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;item&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;items&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# 每个会议都有一个 ID
&lt;/span&gt;	&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;subject&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# 会议标题
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;查询会议室的使用情况&quot;&gt;查询会议室的使用情况&lt;/h4&gt;

&lt;p&gt;会议室和用户没有本质上的区别。可以通过 Impersonation 登录会议室的邮箱账号，查看其日历上的内容来获取使用情况。&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;start&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;account&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;default_timezone&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;localize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;EWSDateTime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2019&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;21&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;end&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;account&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;default_timezone&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;localize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;EWSDateTime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2019&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;21&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;items&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;account&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;calendar&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;last_modified_time__range&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;end&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;item&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;items&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# 每个会议都有一个 ID
&lt;/span&gt;	&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# 会议开始时间
&lt;/span&gt;	&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;end&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# 会议结束时间
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;获取到该会议室的使用情况后，就可以检查该时间段内是否有人使用了。&lt;/p&gt;

&lt;h3 id=&quot;系统设计&quot;&gt;系统设计&lt;/h3&gt;

&lt;h4 id=&quot;outlook-中会议室使用情况同步至系统内&quot;&gt;outlook 中会议室使用情况同步至系统内&lt;/h4&gt;

&lt;p&gt;为了保证会议室使用情况的实时以及查询的稳定性，我们定期将会议室的使用情况同步至系统内&lt;/p&gt;

&lt;p&gt;同步任务需要实现：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;系统A中的会议室使用记录内增加 outlook id，字符串类型，用于记录 outlook 中的会议ID&lt;/li&gt;
  &lt;li&gt;每次查询获取所有会议室最近一段时间内的日程列表，使用 last_modifed_time 字段进行过滤，只取上次同步任务之后变更的日程，与系统内的记录对比并更新&lt;/li&gt;
  &lt;li&gt;如果有系统A中不存在的日程，标记为外部创建日程即可&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;如果有同步需求，也可以通过代码手动调用同步任务触发。
正常情况下设置定时任务，每10分钟同步一次即可。&lt;/p&gt;

&lt;h4 id=&quot;系统中增加日程&quot;&gt;系统中增加日程&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;检查对应会议室在 xx 时间段内是否有被预定&lt;/li&gt;
  &lt;li&gt;绑定会议室后，系统A内创建会议室日程。&lt;/li&gt;
  &lt;li&gt;日程保存时，检测是否有 outlook 日程绑定，同时检测 outlook 日程是否仍然存在，如果不存在，则创建outlook日程并绑定会议室，outlook中创建日程的用户与系统登录用户一致。&lt;/li&gt;
  &lt;li&gt;绑定 outlook 会议室的操作即发送会议邀请给对应的会议室账号，再登陆会议室账号接受邀请即可。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;系统中修改日程&quot;&gt;系统中修改日程&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;系统中修改日程属性，如开始时间、结束时间、会议室等。&lt;/li&gt;
  &lt;li&gt;修改后在保存时通过会议 ID 查询 outlook 中会议的对象，修改对应字段后保存 outlook 对象即可。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;系统中删除日程&quot;&gt;系统中删除日程&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;系统内标记日程位删除，同时 soft delete 删除 outlook 中的日程。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;

&lt;p&gt;outlook 对于会议室的设计感觉像是有历史遗留问题，每个会议室都必须分配一个邮箱，同时用邮箱来管理。但是目前来看，这个设计也有可取之处，就是对于会议室的操作可以复用用户的操作，学习成本更低一些。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;如果你看到这里，一定是真爱！欢迎看看我的其他 &lt;a href=&quot;http://chendi.me/&quot;&gt;blog&lt;/a&gt;。O(∩_∩)O&lt;/p&gt;
</description>
        <pubDate>Sun, 08 Sep 2019 08:15:00 +0800</pubDate>
        <link>http://localhost:4000/2019/09/08/sync-outlook-calendar/</link>
        <guid isPermaLink="true">http://localhost:4000/2019/09/08/sync-outlook-calendar/</guid>
        
        <category>Tech</category>
        
        
      </item>
    
      <item>
        <title>Leverage Datalake cloud service in ETL</title>
        <description>&lt;h2 id=&quot;起因&quot;&gt;起因&lt;/h2&gt;

&lt;p&gt;在数据采集和分析的流程中，目前有3个痛点不好解决：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;数据采集之后是以多个小 json 文件储存在类似 AWS S3 的对象储存中的，当我们要核验数据的特征，例如最大值，数据总数之类的，需要使用 MapReduce 或者 spark 才能实现，而这个操作门槛相对较高。并且由于数据是以多个小文件的形式存在，批处理脚本的执行效率低，每次都需要较长时间才能完成一个简单的数据查询。&lt;/li&gt;
  &lt;li&gt;数据清洗的时候不了解数据特性，例如空值，异常值的情况，所以容易在清洗过程中欠缺对异常情况的处理。&lt;/li&gt;
  &lt;li&gt;数据分析的迭代周期长，出了问题回溯困难。因为统计需要使用专业的数据处理脚本，所以需求提出之后，需要经过代码实现，测试，批量执行之后才能看到结果，迭代周期往往以天计算。同时某个数据的统计值与预期不符时，缺少合适的工具帮助回溯到原始数据。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;这里使用的是阿里云 Data Lake Analytics 服务帮助解决这个问题。同时用阿里云的 OSS 作为数据源储存。&lt;/p&gt;

&lt;p&gt;Data Lake Analytics 将一些简单的 ETL 任务封装成 SAAS 服务了，所以绝大部分的操作是在阿里云的控制台上执行的。&lt;/p&gt;

&lt;h2 id=&quot;简化将小文件合并成大文件的过程&quot;&gt;简化将小文件合并成大文件的过程&lt;/h2&gt;

&lt;p&gt;首先，我们来解决痛点1。&lt;/p&gt;

&lt;p&gt;对于小文件查询慢的问题，传统的解决方法是写一个 spark 的数据清洗脚本来将其转为 parquet 格式，然后再用 zepplin 之类的工具进行查询分析。&lt;/p&gt;

&lt;p&gt;Data Lake Analytics 的处理分成以下几个步骤：&lt;/p&gt;

&lt;h3 id=&quot;建立一个外表连接到需要处理的-oss-路径&quot;&gt;建立一个外表连接到需要处理的 OSS 路径。&lt;/h3&gt;

&lt;p&gt;这里可以使用阿里云的建表向导来进行。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/img/in-post/aliyun-datalake/datalake1.png&quot;&gt;&lt;img src=&quot;/img/in-post/aliyun-datalake/datalake1.png&quot; alt=&quot;datalake1&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;填入几个关于数据源的信息后，会自动生成一个建表的 schema。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/img/in-post/aliyun-datalake/datalake2.png&quot;&gt;&lt;img src=&quot;/img/in-post/aliyun-datalake/datalake2.png&quot; alt=&quot;datalake2&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;这里建议大家手动审核调整一下建表的 sql，然后在 sql 界面进行建表。&lt;/p&gt;

&lt;h3 id=&quot;使用-data-lake-的-mysql-接口连接其数据库&quot;&gt;使用 Data Lake 的 MySQL 接口连接其数据库&lt;/h3&gt;

&lt;p&gt;在阿里云控制台可以获取到连接的参数信息。建议根据 &lt;a href=&quot;https://help.aliyun.com/document_detail/98381.html?spm=a2c4g.11186623.6.557.6aff7b8cAX4zoH&quot;&gt;文档&lt;/a&gt; 配置子账号并用子账号创建新表。&lt;/p&gt;

&lt;p&gt;连接上之后，我们就可以用刚才阿里云生成的建表 sql 创建一个新的外表了。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/img/in-post/aliyun-datalake/datalake3.png&quot;&gt;&lt;img src=&quot;/img/in-post/aliyun-datalake/datalake3.png&quot; alt=&quot;datalake3&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;建立-parquet-格式的外表&quot;&gt;建立 Parquet 格式的外表&lt;/h3&gt;

&lt;p&gt;使用前面阿里云建表向导提供的建表 SQL，我们可以做一些修改，例如将 &lt;code class=&quot;highlighter-rouge&quot;&gt;STORE AS JSON&lt;/code&gt; 改为 &lt;code class=&quot;highlighter-rouge&quot;&gt;STORE AS PARQUET&lt;/code&gt; 然后建立一个指向新的 OSS 路径的外表。&lt;/p&gt;

&lt;p&gt;然后我们可以使用下面的 SQL 将 JSON 格式的文件导入到 PARQUET 格式的文件中去，完成小文件合并的任务。&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;cm&quot;&gt;/*+run_async=true*/&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;INTO&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parquet_table&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;json_table&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;记得加上面的 &lt;code class=&quot;highlighter-rouge&quot;&gt;/*+run_async=true*/&lt;/code&gt; 标注，因为这个执行过程比较久，将其设置为异步执行可以避免由于 mysql 客户端超时导致的任务失败。&lt;/p&gt;

&lt;h2 id=&quot;在parquet文件上进行数据特性分析&quot;&gt;在Parquet文件上进行数据特性分析&lt;/h2&gt;

&lt;p&gt;当我们将数据从 json 文件插入至 parquet 文件后，我们就可以从 parquet 文件对应的表进行 sql 查询了。由于文件已经被合并成大的 parquet 文件，查询性能也会大大提高。&lt;/p&gt;

&lt;h2 id=&quot;回溯问题文件&quot;&gt;回溯问题文件&lt;/h2&gt;

&lt;p&gt;当我们发现数据的统计值不符合我们的预期时，往往需要回溯寻找出问题的原始数据是什么，Datalake 也是做这类工作的一个利器。&lt;/p&gt;

&lt;p&gt;当我们使用 OSS 作为外表进行查询时，我们可以使用 &lt;code class=&quot;highlighter-rouge&quot;&gt;$path&lt;/code&gt; 获取外表数据源的文件名称。&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;json_table&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;hr /&gt;

&lt;p&gt;如果你看到这里，一定是真爱！欢迎看看我的其他 &lt;a href=&quot;http://chendi.me/&quot;&gt;blog&lt;/a&gt;。O(∩_∩)O&lt;/p&gt;
</description>
        <pubDate>Mon, 28 Jan 2019 16:15:00 +0800</pubDate>
        <link>http://localhost:4000/2019/01/28/leverage-datalake-service-in-etl/</link>
        <guid isPermaLink="true">http://localhost:4000/2019/01/28/leverage-datalake-service-in-etl/</guid>
        
        <category>Tech</category>
        
        
      </item>
    
      <item>
        <title>Snappy-python is not fully compatible with hadoop-snappy</title>
        <description>&lt;h2 id=&quot;起因&quot;&gt;起因&lt;/h2&gt;

&lt;p&gt;在我当前项目中，有一部分技术架构涉及到数据在 python 脚本中用 json + &lt;a href=&quot;https://github.com/google/snappy&quot;&gt;snappy&lt;/a&gt; 的格式压缩之后储存起来，json 是作为数据序列化的格式，而 snappy 则是作为数据压缩的格式。在下游处理中，spark 任务会读取这部分数据进行处理。这套方案理论上是没有问题的，在我们的调研中，也确认了 python 中上传的数据，在 spark 中可以被正确解读。但是在实际广泛使用时，我们发现有某些数据在 python 端能正常地被压缩以及解压，但是在 spark 端就报了下面的错误：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;java.lang.InternalError: Could not decompress data. Input is invalid.
at org.apache.hadoop.io.compress.snappy.SnappyDecompressor.decompressBytesDirect(Native Method) 
at org.apache.hadoop.io.compress.snappy.SnappyDecompressor.decompress(SnappyDecompressor.java:239)
at org.apache.hadoop.io.compress.BlockDecompressorStream.decompress(BlockDecompressorStream.java:88)
at org.apache.hadoop.io.compress.DecompressorStream.read(DecompressorStream.java:85)
...
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;这里记录的是解决这个问题的过程和结果。&lt;/p&gt;

&lt;h2 id=&quot;分析错误原因&quot;&gt;分析错误原因&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;首先缩小一下问题出现的范围&lt;/strong&gt;。&lt;/p&gt;

    &lt;p&gt;这个错误大概在1万个文件中才会出现一次，并且我们将出错的文件重新用 python 库解压之后，spark 仍然无法解析。所以基本可以认定这个文件指出了 spark 和 python 中 snappy SDK 的一些不兼容之处。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;缩小测试用例，找出最小可以复现问题的测试用例&lt;/strong&gt;。&lt;/p&gt;

    &lt;p&gt;原始的错误文件大概有2.6MB，压缩之后是2.5MB，压缩比例很差。好在文件并不大，决定用二分法找出有问题的数据内容。在将数据分为两份之后，发现只有其中一份用 python sdk 压缩之后 spark 无法解析，另一份则没有问题。在不断缩小范围之后，定位到了一段 base64 encode 的数据上。这部分 base64 encode 的数据大概有1.5MB。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;构建最小可以复现问题的测试用例&lt;/strong&gt;。&lt;/p&gt;

    &lt;p&gt;在比较正常压缩文件和该错误压缩文件之后，发现 base64 encode 的数据几乎没有被压缩，原文和压缩后的文件几乎是相同的。此时我们大胆猜测，当压缩后的文件与原文相同时，snappy 解压时会因为找不到所需的元数据而报错。在编写了一个随机字符生成器后，我们基本验证了我们的猜测：&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import random
import string
N=1000000
print(''.join(random.choices(string.ascii_uppercase + string.digits, k=N)))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;p&gt;并且在 N 在大于 100 万的情况下必然复现。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;寻找解决问题的方法&quot;&gt;寻找解决问题的方法&lt;/h2&gt;

&lt;h3 id=&quot;对比测试结果&quot;&gt;对比测试结果&lt;/h3&gt;
&lt;p&gt;在找到复现的 test case 之后，下一步我们要找问题的根源。对于一个序列化和反序列化的算法，不同语言的实现应该遵从同一套标准，那么同一段数据压缩后的二进制文件应该也是相同的。&lt;/p&gt;

&lt;p&gt;将 snappy-python 压缩后的文件命名为 python_result.snappy&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;python3 -m snappy -t hadoop_snappy -c test.txt &amp;gt; test_python.txt.snappy
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;此时我们还需要 hadoop-snappy 编译出来的二进制文件&lt;/p&gt;

&lt;h3 id=&quot;编译-hadoop-snappy-测试用例&quot;&gt;编译 hadoop-snappy 测试用例&lt;/h3&gt;
&lt;p&gt;hadoop-snappy 的源码在 &lt;a href=&quot;https://code.google.com/archive/p/hadoop-snappy/&quot;&gt;Hadoop snappy google code&lt;/a&gt;。可以从&lt;a href=&quot;https://storage.googleapis.com/google-code-archive-source/v2/code.google.com/hadoop-snappy/source-archive.zip&quot;&gt;这里&lt;/a&gt;下载源码。&lt;/p&gt;

&lt;p&gt;源码编译时需要先安装 snappy 库，同时配置 snappy 库的到 java 的 VM Options 中。例如我在 Mac OS 上用 brew 安装的 snappy。&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ brew install snappy
$ ls /usr/local/Cellar/snappy/1.1.7_1
AUTHORS              INSTALL_RECEIPT.json README.md            lib
COPYING              NEWS                 include
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;snappy 库的路径是 /usr/local/Cellar/snappy/1.1.7_1，那么就配置 -Dsnappy.prefix=/usr/local/Cellar/snappy/1.1.7_1&lt;/p&gt;

&lt;p&gt;同时要注意，老版本的 hadoop-snappy 有一个提示错误，当 snappy 格式错误时，提示的是找不到 snappy 库，可以用以下方式修改 &lt;code class=&quot;highlighter-rouge&quot;&gt;src/main/native/src/org/apache/hadoop/io/compress/snappy/SnappyDecompressor.c&lt;/code&gt;，然后重新编译来解决。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;   if (ret == SNAPPY_BUFFER_TOO_SMALL){
-    THROW(env, &quot;Ljava/lang/InternalError&quot;, &quot;Could not decompress data. Buffer length is too small.&quot;);
+    THROW(env, &quot;java/lang/InternalError&quot;, &quot;Could not decompress data. Buffer length is too small.&quot;);
   } else if (ret == SNAPPY_INVALID_INPUT){
-    THROW(env, &quot;Ljava/lang/InternalError&quot;, &quot;Could not decompress data. Input is invalid.&quot;);
+    THROW(env, &quot;java/lang/InternalError&quot;, &quot;Could not decompress data. Input is invalid.&quot;);
   } else if (ret != SNAPPY_OK){
-    THROW(env, &quot;Ljava/lang/InternalError&quot;, &quot;Could not decompress data.&quot;);
+    THROW(env, &quot;java/lang/InternalError&quot;, &quot;Could not decompress data.&quot;);
   }
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;编译之后可以使用测试用例来触发 snappy 的压缩，测试用例在 &lt;code class=&quot;highlighter-rouge&quot;&gt;src/test/java/org/apache/hadoop/io/compress/snappy/TestSnappyCodec.java&lt;/code&gt;。压缩之后我们得到了 test_java.txt.snappy&lt;/p&gt;

&lt;p&gt;我们比较一下 test_java.txt.snappy 和 test_python.txt.snappy，发现 test_python.txt.snappy 整个文件中，如果用 utf-8 编码格式打开，只有最开头有一段乱码的二进制头信息。但是 test_java.txt.snappy 则每隔 256K 就会有一段二进制头信息。&lt;/p&gt;

&lt;p&gt;在这时，我们可以初步断定是两个语言的头信息写入不一致导致的文件格式不兼容。&lt;/p&gt;

&lt;h3 id=&quot;查看源码&quot;&gt;查看源码&lt;/h3&gt;
&lt;p&gt;snappy 的压缩和代码在 java 中其实并不复杂，主要都集中在 &lt;code class=&quot;highlighter-rouge&quot;&gt;src/main/java/org/apache/hadoop/io/compress/snappy/&lt;/code&gt;，本质上是在 java 中将 byte 流读入后，将数据分块，再对每一块进行压缩。而我们看到的文件里的的二进制头信息其实就是每一块数据的元数据，例如每一块数据的长度等。那么是什么决定了数据块的默认大小呢？有两个变量可能会造成影响。&lt;/p&gt;

&lt;p&gt;一个是 DEFAULT_DIRECT_BUFFER_SIZE:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ grep DEFAULT_DIRECT_BUFFER_SIZE src/main/java/org/apache/hadoop/io/compress/snappy/SnappyCompressor.java
$   private static final int DEFAULT_DIRECT_BUFFER_SIZE = 64 * 1024;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;这里是代码定义的默认大小，64K。但是在测试用例中我们发现，调整这个数值并不会改变最后生成的数据块大小。&lt;/p&gt;

&lt;p&gt;另一个是 IO_COMPRESSION_CODEC_SNAPPY_BUFFERSIZE_DEFAULT：&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ grep -b2 IO_COMPRESSION_CODEC_SNAPPY_BUFFERSIZE_DEFAULT src/main/java/org/apache/hadoop/io/compress/SnappyCodec.java
1527-
1528-  /** Default value for IO_COMPRESSION_CODEC_SNAPPY_BUFFERSIZE_KEY */
1598:  public static final int IO_COMPRESSION_CODEC_SNAPPY_BUFFERSIZE_DEFAULT =
1673-      256 * 1024;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;这个配置文件控制了在作为 Hadoop Codec 组件实例化时，使用的数据块大小。如果我们将这个值调为 256，我们会发现测试用例中数据块的分块确实变化了。&lt;/p&gt;

&lt;p&gt;这时候，我们可以大致明白，之所以 python-snappy 压缩的文件在 hadoop-snappy 中无法解析，其实本质上是因为 python-snappy 在一整个 256K 数据块中的任何一块地方生成元数据头，导致 hadoop-snappy 一次性读取进来的 256K 全是数据，没有数据块头，也就无法解析出对应的数据块长度，最终报了 “ Input is invalid.” 错误。&lt;/p&gt;

&lt;p&gt;那么为什么其他数据没问题， base64 的数据就会出问题呢？&lt;/p&gt;

&lt;p&gt;首先，并不是一定 256K 的位置才会生成一个数据块头信息，而是每一个可以被截断并压缩的数据块就会生成一个头信息。但是对于 base64 的文字，基本是原文读入，原文写出的，所以连续的 256K base64 编码数据中，如果没有强行截断的话，就不会生成数据头。这个应该是 python-snappy sdk 的一个bug，不过由于时间原因，没办法细看 python-snappy sdk 并修复这个问题。&lt;/p&gt;

&lt;h3 id=&quot;最终解决方法&quot;&gt;最终解决方法&lt;/h3&gt;
&lt;p&gt;首先我们尝试调大 hadoop-snappy 的解压区块大小，当 hadoop-snappy 的 IO_COMPRESSION_CODEC_SNAPPY_BUFFERSIZE_DEFAULT 设置为 512K 时，我们发现 python-snappy 压缩的 base64 encode 文件可以被正常解压。但是在 hadoop 集群上，这样有可能导致这样保存下来的 snappy.json 文件无法被其他未修改配置的 hadoop 组件读取。&lt;/p&gt;

&lt;p&gt;还有一个思路就是调小 python-snappy 的区块大小。虽然文档中没有提到修改的方式，但是从 API 的签名中我们发现，在 &lt;a href=&quot;https://github.com/andrix/python-snappy/blob/master/snappy/hadoop_snappy.py&quot;&gt;hadoop-snappy.py&lt;/a&gt; 文件中也定义了 &lt;code class=&quot;highlighter-rouge&quot;&gt;SNAPPY_BUFFER_SIZE_DEFAULT&lt;/code&gt; 变量，控制默认的区块大小。而在 stream_compress 函数的签名中也有 blocksize 变量，默认值就是 SNAPPY_BUFFER_SIZE_DEFAULT。所以只要在调用 stream_compress 的时候将 blocksize 调为 128K 即可。&lt;/p&gt;

&lt;p&gt;最后联调后发现，这个方法生成的 python-snappy 文件是可以被 hadoop-snappy 成功解析的。最后我们的解决方法就是在 stream_compress 设置 blocksize 为 128K。&lt;/p&gt;

&lt;h1 id=&quot;经验总结&quot;&gt;经验总结&lt;/h1&gt;

&lt;p&gt;首先这个问题其实本质上还是一个算法，多个语言实现导致的问题。虽然底层的压缩算法使用的是同一套库，但是上层数据块的切分实现可能有细微差别，导致这个问题的发生。这个问题的解决其实关键是有一个可以复现的测试用例，有了这个测试用例之后就能帮我们不断缩小问题的范围，最后找到一个相对实现起来比较容易的解决方案。&lt;/p&gt;

&lt;h2 id=&quot;题外话&quot;&gt;题外话&lt;/h2&gt;

&lt;p&gt;在看 Google snappy 的代码时，发现一个 &lt;a href=&quot;https://github.com/google/snappy/commit/824e6718b5b5a50d32a89124853da0a11828b25c&quot;&gt;commit&lt;/a&gt;。Google 的工程师在做 regression 性能测试的时候发现，LLVM 的一个内存对齐的相关改动，导致 snappy 的性能下降了 3%，这个改动影响到了多个 intel 架构。最后虽然没能理解出现的原因，但是强行在 x86 架构上增加一个补位元素，抵消了 LLVM 上游的副作用，使得 snappy 的性能恢复到 LLVM 修改之前。&lt;/p&gt;

&lt;p&gt;这看起来是个小优化，但是也看到了 Google 背后完整的基础架构，能支持工程师定期进行性能测试，并且将性能测试在不同架构上进行复现。确实厉害。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;如果你看到这里，一定是真爱！欢迎看看我的其他 &lt;a href=&quot;http://chendi.me/&quot;&gt;blog&lt;/a&gt;。O(∩_∩)O&lt;/p&gt;
</description>
        <pubDate>Sun, 11 Nov 2018 05:15:00 +0800</pubDate>
        <link>http://localhost:4000/2018/11/11/snappy-python-incompatibility/</link>
        <guid isPermaLink="true">http://localhost:4000/2018/11/11/snappy-python-incompatibility/</guid>
        
        <category>Tech</category>
        
        
      </item>
    
      <item>
        <title>App Store Review Tips</title>
        <description>&lt;h2 id=&quot;初衷&quot;&gt;初衷&lt;/h2&gt;

&lt;p&gt;这篇博客主要想记录一下 App Store 中审核遇到的一些问题，以及最终解决的方案，希望对后来者有一定帮助，也是对自己的经验总结。&lt;/p&gt;

&lt;p&gt;对于苹果开发者来说，App Store 的审核是一个对整体迭代效率影响极大的一个环节，但是绝大部分情况下，App Store 的审核还是比较客观效率的，所以不必将其视为洪水猛兽。&lt;/p&gt;

&lt;p&gt;这里主要讨论下面几个问题：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;#第三方登录&quot;&gt;第三方登录&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#第三方支付与内购&quot;&gt;第三方支付与内购&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#网络以及服务不连通&quot;&gt;网络以及服务不连通&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#初版兼容性&quot;&gt;初版兼容性&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#区分审核服务器&quot;&gt;区分审核服务器&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#missing-infoplist-key&quot;&gt;Missing Info.plist key&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;第三方登录&quot;&gt;第三方登录&lt;/h2&gt;

&lt;p&gt;现在基本上每个游戏或者 app 都会开放第三方登录，并且可能第三方登录是 95% 用户使用的登录方式。我们也希望尽可能优化用户登录的体验，所以也希望用户使用第三方登录，而不是手机号验证码或者邮箱验证。所以我们的登录界面是这样的：&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/img/in-post/app-store-review/01-app.jpeg&quot;&gt;&lt;img src=&quot;/img/in-post/app-store-review/01-app.jpeg&quot; alt=&quot;01-app&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;但是对于 App Store 审核员来说，有两个问题：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;审核员大概率是外国人，看不懂中文，也就看不懂右上角的手机登录入口。所以有可能会打回 App，理由是未提供自有账号登录系统。&lt;/li&gt;
  &lt;li&gt;审核员点击第三方登录按钮后，会跳转至第三方登录界面，对于审核员来说，变相要求其安装 QQ 或者微信这样的第三方程序，会以 “不得要求用户安装其他程序才能使用该程序” 理由打回。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;对于这个情况，我们想了两种解决方法：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;只提供账号密码登录的方式，弱化第三方登录的 UI 显著性。&lt;/li&gt;
  &lt;li&gt;在审核期间使 App 作出与线上服务器不同的表现，只展示账号密码登录的界面，等到审核通过后，再显示完整界面。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;最后我们权衡了一下采用了方法2，这样对于 UI 和用户体验，我们有更完整的掌控性。至于如何在审核期间使 App 作出与线上服务器不同的表现，见 &lt;a href=&quot;#区分审核服务器&quot;&gt;第五节 - 区分审核服务器&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;第三方支付与内购&quot;&gt;第三方支付与内购&lt;/h2&gt;

&lt;p&gt;在我们提交审核时，我们曾被以下理由打回过 2 次：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Guideline 3.1.1 - In-App Purchase&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;We noticed that your app contains a payment mechanism other than in-app purchase for digital content or to unlock features or functionality within your app, which is not appropriate for the App Store. In-app purchase is the only valid in-app payment mechanism for digital content.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Note: Continuing to hide functionality within your app or other dishonest acts may result in the removal of your apps from the App Store and termination of your Apple Developer Program membership and all associated memberships.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Next Steps&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;To resolve this issue, please remove all external or third-party payment mechanisms and implement in-app purchase to facilitate digital good transactions, including unlocking features or functionality within your app.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;If you believe your use of an alternative payment mechanism is a permissible use case, please respond directly to this message in Resolution Center with detailed information.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;这个理由其实理解起来很简单 “我们检测到你在 app 里用了第三方登录，你别管我们怎么检测的，但是你得把它给去了”。&lt;/p&gt;

&lt;p&gt;我们第一次遇到这个问题时，我们刚接入了集成各种第三方登录的 SDK - ShareSDK，在 ShareSDK 中包含了微信的 SDK，而微信的 SDK 中包含了微信支付的代码，苹果正是监测到这部分代码后，拒绝了对应的编译包。解决方法其实相对简单，只要将微信的 SDK 更换为不带微信支付的即可。&lt;/p&gt;

&lt;p&gt;我们第二次遇到这个问题是，就比较奇怪了，在前一次正常过审核的编译和此次编译之间，我们没有引入额外的第三方支付或者更改过 SDK 包。我们在 Resolution Center 回复质询了详细信息，但是苹果并没有给出更详细的反馈。当时我们有两个方案：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;提交 Appeal 审核申诉，声明我们没有使用第三方支付，并要求重新审核。&lt;/li&gt;
  &lt;li&gt;拆开 ipa 包，扫描可疑的 API，并将其剔除。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;方案1操作起来简单，但是很可能会拖很久，而且据说一旦提起 Appeal，审核将变得非常严格，很可能得不偿失。&lt;/p&gt;

&lt;p&gt;方案2操作的主动权掌握在我们手中，可以第一时间执行，也许当天就能找到问题所在，但是相对繁琐。淘宝上有类似的服务，价格大概为3000元。&lt;/p&gt;

&lt;p&gt;我们最终选择了方案2，方案2的执行过程如下：&lt;/p&gt;

&lt;h4 id=&quot;找到-ipa-包对应的符号表&quot;&gt;找到 ipa 包对应的符号表&lt;/h4&gt;

&lt;p&gt;为了找到与支付相关的代码，我们选择从符号表入手，xcode 打包 ipa 之后，在 archive 文件中可以找到二进制文件并提取出符号表。&lt;/p&gt;

&lt;p&gt;例如 archive 文件是： myapp.xcarchive&lt;/p&gt;

&lt;p&gt;那么对应的二进制文件路径在：
&lt;code class=&quot;highlighter-rouge&quot;&gt;myapp.xcarchive/dSYMs/myapp.app.dSYM/Contents/Resources/DWARF/myapp&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;我们可以使用 Unix 的 nm 工具获取到该二进制文件的对应符号表。&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;nm myapp.xcarchive/dSYMs/myapp.app.dSYM/Contents/Resources/DWARF/myapp &amp;gt; symbols&lt;/code&gt;&lt;/p&gt;

&lt;h4 id=&quot;在符号表中找到函数名&quot;&gt;在符号表中找到函数名&lt;/h4&gt;

&lt;p&gt;我们关心的函数一般带有关键字 “pay”, “payment”，我们接着过滤出带有该关键字的函数&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;grep -i &quot;pay&quot; symbols &amp;gt; pay_api&lt;/code&gt;
&lt;code class=&quot;highlighter-rouge&quot;&gt;grep -i &quot;payment&quot; symbols &amp;gt; payment_api&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;在 pay_api 以及 payment_api 中，我们会看到类似：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;000000010275a484 t +[WXApi handleNontaxPayReq:]
0000000102757bd4 t +[WXApi handleOpenTypeWebViewWithNontaxpay:delegate:]
0000000102757d48 t +[WXApi handleOpenTypeWebViewWithPayInsurance:delegate:]
000000010275a594 t +[WXApi handlePayInsuranceReq:]
0000000102a8d780 t -[FBSDKPaymentObserver handleTransaction:]
0000000102a8d4c8 t -[FBSDKPaymentObserver init]
0000000102a8d63c t -[FBSDKPaymentObserver paymentQueue:updatedTransactions:]
0000000102a8d510 t -[FBSDKPaymentObserver startObservingTransactions]
0000000102a8d5a8 t -[FBSDKPaymentObserver stopObservingTransactions]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;这样的符号表，三个栏位分别表示：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;符号对应的虚拟地址&lt;/li&gt;
  &lt;li&gt;符号的类型&lt;/li&gt;
  &lt;li&gt;符号本身，可能是函数签名，也可能是变量名&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;在函数名中找到可疑的函数并移除&quot;&gt;在函数名中找到可疑的函数并移除&lt;/h4&gt;

&lt;p&gt;App Store 审核时显然不可能打回所有带有 &lt;code class=&quot;highlighter-rouge&quot;&gt;pay&lt;/code&gt; 或者 &lt;code class=&quot;highlighter-rouge&quot;&gt;payment&lt;/code&gt; 关键字函数的安装包，肯定是在有把握的情况下才会将 app 打回。所以下一步就是确认哪些 API 是让审核不过的。&lt;/p&gt;

&lt;p&gt;我们检查的方式主要有两个：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;该 API 所属的 SDK 是否有第三方支付的能力。&lt;/li&gt;
  &lt;li&gt;该 API 是否是直接支持第三方支付功能的。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;所以我们排除了一些无关的 API，例如：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;TalkingData 数据采集 API，TalkingData 只是数据采集方，API 被苹果监控的可能性较小。&lt;/li&gt;
  &lt;li&gt;Facebook 的 API，FB 本身不提供支付功能，API 被苹果监控的可能性较小。&lt;/li&gt;
  &lt;li&gt;支付宝的朋友圈 API，虽然符号中有 “Alipay”，但是朋友圈 API 必然也被集成进了许多不需要支付的 App，被 ban 的可能性也比较小。&lt;/li&gt;
  &lt;li&gt;我们自己代码中内购相关的 API，虽然符号中有 “pay” 字样，但是相信大部分内购 App 都会有，被 ban 的可能性较小。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;最终我们定位到了两个可疑的 API：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;QQ 支付的 API
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;0000000102c8d48c t -[QQApiPayObject AppInfo]
0000000102c8d460 t -[QQApiPayObject OrderNo]
0000000102c8d3b0 t -[QQApiPayObject dealloc]
0000000102c8d330 t -[QQApiPayObject initWithOrderNo:AppInfo:]
0000000102c8d49c t -[QQApiPayObject setAppInfo:]
0000000102c8d470 t -[QQApiPayObject setOrderNo:]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
    &lt;p&gt;对于 QQ 支付的 API 来讲，无疑是苹果针对禁止的功能，我们的做法是从 QQ 的 SDK 下载处下了一个不带支付功能的。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;微信支付 API
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;000000010275a484 t +[WXApi handleNontaxPayReq:]
0000000102757bd4 t +[WXApi handleOpenTypeWebViewWithNontaxpay:delegate:]
0000000102757d48 t +[WXApi handleOpenTypeWebViewWithPayInsurance:delegate:]
000000010275a594 t +[WXApi handlePayInsuranceReq:]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
    &lt;p&gt;对于微信的这几个 API 来说，从字面上看不出其主要功能是什么，所以我们下载了微信的两个 SDK 版本，一个带支付的，一个不带支付的。对比了一下发现两个版本中都有这几个符号，所以初步确认这个符号和支付功能无关，就没有对应修改。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;在更换了 QQ SDK 之后，我们的 App 就过审核了。&lt;/p&gt;

&lt;h2 id=&quot;网络以及服务不连通&quot;&gt;网络以及服务不连通&lt;/h2&gt;

&lt;p&gt;在第一次提交审核的时候，我们被打回的理由是 “游戏打开之后就卡在了 Unity logo 画面”，但是本地各种机型都无法复现。在加载阶段，我们做的事情很简单：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;从 HTTPDNS 获取 DNS 解析结果。&lt;/li&gt;
  &lt;li&gt;连接服务器更新最新版本信息。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;在请美国的同学帮忙测试之后发现，错误发生在从 HTTPDNS 获取 DNS 解析结果这一步，这一步我们使用的是阿里云的 HTTPDNS 服务，但是不知为何，在国外区域请求一直发生错误。无奈之下，我们自己搭建了一个简易的 HTTPDNS 服务，解决了这个问题。&lt;/p&gt;

&lt;p&gt;如果读者遇到本地无法复现的审核问题，不妨搭个 VPN，连接到加州的网络试试看。&lt;/p&gt;

&lt;h2 id=&quot;初版兼容性&quot;&gt;初版兼容性&lt;/h2&gt;

&lt;p&gt;有一个我们吃了大亏的地方，就是第一个发布版本中，Info.plist 的 UIRequiredDeviceCapabilities 没有设置，导致后期收到了不少 App Store 的差评。&lt;/p&gt;

&lt;p&gt;UIRequiredDeviceCapabilities 的&lt;a href=&quot;https://developer.apple.com/library/archive/documentation/General/Reference/InfoPlistKeyReference/Articles/iPhoneOSKeys.html#//apple_ref/doc/uid/TP40009252-SW3&quot;&gt;官方文档&lt;/a&gt;给出了一系列可以使用的 key 值，如果在 xcode 的 Info.plist 中包含对应的 key 值，则在 App Store 上，只有满足对应兼容性要求的手机才能下载。并且，&lt;strong&gt;在今后更新的版本中，都要支持曾经支持过的所有机型&lt;/strong&gt;。这就意味着，兼容性只能放宽，不能收紧。&lt;/p&gt;

&lt;p&gt;这会导致什么问题呢？对我们来说，第一次发布的版本中，我们只限制了 iOS 11 以上的手机可以下载，但是没有限制支持 arkit 的才能下载。所以有一些机型不支持 arkit 的下载之后，发现 AR 功能无法使用而留下了差评。后期我们发现之后也不能收紧兼容性，给维护造成了很大困扰。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/img/in-post/app-store-review/05-devicecompatibility.jpeg&quot;&gt;&lt;img src=&quot;/img/in-post/app-store-review/05-devicecompatibility.jpeg&quot; alt=&quot;05-devicecompatibility&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;区分审核服务器&quot;&gt;区分审核服务器&lt;/h2&gt;

&lt;p&gt;在我们的团队中，App 环境分成 3 个，dev -&amp;gt; alpha -&amp;gt; release&lt;/p&gt;

&lt;p&gt;dev 是开发团队平时用于开发，测试的服务器。
alpha 是发版本前，用于固定版本的测试环境，以及审核用的环境。
release 是线上的正式服务器。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/img/in-post/app-store-review/02-env.jpeg&quot;&gt;&lt;img src=&quot;/img/in-post/app-store-review/02-env.jpeg&quot; alt=&quot;02-env&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;每一个环境中，有其对应的安装包和服务器包。&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;安装包即 iOS 的 ipa 包。
    &lt;ul&gt;
      &lt;li&gt;其中包括了版本号，编译时间戳，还有打包时的美术资源&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;每一个版本号对应一个环境，由版本号控制安装包对应的环境&lt;/strong&gt;。&lt;/li&gt;
      &lt;li&gt;版本号对应的环境信息储存在高可用的服务器上，这里选择的是阿里云的 OSS 服务，既保证了高可用性，也在最大限度上减少了服务器开销。如下图：&lt;a href=&quot;/img/in-post/app-store-review/03-env.jpeg&quot;&gt;&lt;img src=&quot;/img/in-post/app-store-review/03-env.jpeg&quot; alt=&quot;03-env&quot; /&gt;&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;客户端在&lt;strong&gt;第一次打开时&lt;/strong&gt;，向阿里云请求该版本号对应的环境名，&lt;strong&gt;并缓存在本地&lt;/strong&gt;，下次打开时直接从本地读取。&lt;/li&gt;
      &lt;li&gt;在得到环境名后，从本地的环境 - ip 表中，获取对应的服务器 ip ，并连接对应的服务器进行交互。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;服务器则是用 docker 打包部署。
    &lt;ul&gt;
      &lt;li&gt;其中包括了服务器代码以及打 docker 时的配置表信息。&lt;/li&gt;
      &lt;li&gt;每个环境使用对应 docker tag 的 docker，例如 dev 版使用的 docker 镜像是 &lt;code class=&quot;highlighter-rouge&quot;&gt;test_docker:dev&lt;/code&gt;，而 alpha 版使用的 docker 镜像是 &lt;code class=&quot;highlighter-rouge&quot;&gt;test_docker:alpha&lt;/code&gt;，这样一来变更服务器版本就只需用一行代码来切换 tag 指向即可，保证了部署的代码和测试的代码是一致的。&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;$ docker tag test_docker:dev test_docker:alpha&lt;/code&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这样一来，每个环境之间就不会互相影响了，开发时：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;客户端程序可以连接 dev 版本的服务器进行开发，服务器的更新，数据变化不会影响到审核或者线上正式玩家。&lt;/li&gt;
  &lt;li&gt;当需要发版时，更改阿里云 OSS 上的文件，将客户端包里版本号对应的环境更改至 alpha，并将dev 标签的 docker 打上 alpha 标签，我们就完成了将 dev 环境复制到 alpha 环境的操作。&lt;/li&gt;
  &lt;li&gt;此时，我们可以将对应的客户端安装包提交审核，在审核期间，开发和线上活动均不会影响到审核员的数据。&lt;/li&gt;
  &lt;li&gt;等到审核通过后，我们可以再将审核服和对应安装包部署到 release 环境中。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;由于我们在客户端有了对应的环境名，我们也可以对应作出一些审核中特有的操作，例如：&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;env&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;alpha&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;do_something&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;do_something_else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;missing-infoplist-key&quot;&gt;Missing Info.plist key&lt;/h2&gt;

&lt;p&gt;我们在搭建了自动打包系统之后，每天都会打包上传最新的安装包，在某次 git commit 之后，收到了苹果发来的邮件：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Missing Info.plist key- This app attempts to access privacy-sensitive data without a usage description. The app's Info.plist must contain an NSContactsUsageDescription key with a string value explaining to the user how the app uses this data.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;我们在 App 的使用过程中从未获取过用户的联系人信息，所以我们希望找到导致这个警告的原因，而不是添加一个不必要的 NSContactsUsageDescription。&lt;/p&gt;

&lt;p&gt;苹果会弹出这个警告，而我们没有调用联系人的 API，那么应该是间接引入了获取联系人的 API，导致 API 被苹果扫描到了。我们在 Linked Library 中找到了 Contacts.Framework 并将其删除后，重新编译。发现讯飞科技的 SDK 报错了。原来是我们使用了游密的 SDK 实现聊天功能，游密又使用了讯飞的 SDK 实现语音转文字功能，讯飞的 SDK 又引入了联系人的 API 来获取联系人名字，帮助语音识别更准确地识别人名。&lt;/p&gt;

&lt;p&gt;最后由于我们不需要讯飞的 SDK，就和游密要了不含讯飞的SDK。如果不使用这个方式，也可以自己新建一个 .m 文件，实现几个 dummy function 来规避编译错误，又不影响已有功能。&lt;/p&gt;

&lt;h1 id=&quot;经验总结&quot;&gt;经验总结&lt;/h1&gt;

&lt;p&gt;Unity 在目前的 3D 开发引擎里，算是社区很健全，同时文档也很丰富的一个引擎。我们遇到的绝大部分问题都是其他开发者踩过的坑，如果在一个方面停滞不前，没有好的解决方案时，不妨系统地静下心来通读一下文档。欲速则不达，静下心思考之后，往往能找到更优雅地捷径。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;如果你看到这里，一定是真爱！欢迎看看我的其他 &lt;a href=&quot;http://chendi.me/&quot;&gt;blog&lt;/a&gt;。O(∩_∩)O&lt;/p&gt;
</description>
        <pubDate>Fri, 20 Apr 2018 08:15:00 +0800</pubDate>
        <link>http://localhost:4000/2018/04/20/app-store-review/</link>
        <guid isPermaLink="true">http://localhost:4000/2018/04/20/app-store-review/</guid>
        
        <category>Tech</category>
        
        <category>AppStore</category>
        
        
      </item>
    
      <item>
        <title>Unity Asset Management</title>
        <description>&lt;h2 id=&quot;需求&quot;&gt;需求&lt;/h2&gt;

&lt;p&gt;在团队进行 Unity 开发的时候，就资源管理的方式出现过许多吐槽，比如 “为什么不直接放进 Resource 里，多方便”，“要是当初放进 Resource 里就不会出这么多 bug 了 ”。当吐槽的次数越来越多，就意味着这个问题是阻碍开发效率的因素，急需解决。&lt;/p&gt;

&lt;p&gt;同时，游戏安装包的大小与资源管理的方式直接挂钩，想要缩小安装包，就必须理解资源管理的原理并进行优化。&lt;/p&gt;

&lt;h3 id=&quot;背景常识&quot;&gt;背景常识&lt;/h3&gt;

&lt;p&gt;对于大部分 Unity 开发来说，资源管理是个必修课，但是对于我这个主修后端开发的来说，还是有一些常识需要补补的。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://unity3d.com/learn/tutorials/temas/best-practices/assets-objects-and-serialization&quot;&gt;资源&lt;/a&gt;&lt;/strong&gt; 在这篇博客中特别指的是 Unity 中的资源，例如图片，纹理，材质，模型，音频文件等。在游戏进行中，绚丽的特效和精美的场景都需要将资源从手机储存中读取出来并播放。由于摩尔定律，手机的 CPU 和 GPU 都有了大幅提高 ，但是手机储存介质的存取速度却没有太多提升，这就导致了在游戏的过程中资源的管理很容易成为瓶颈。(磁盘I储存以及 IO成为瓶颈)&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;目标细化&quot;&gt;目标细化&lt;/h3&gt;
&lt;p&gt;在资源管理这个话题下，我们可以将其分为一下几个需要进行权衡的问题：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;资源在什么时候，存在哪？&lt;/strong&gt; 存在游戏安装包中？还是存在服务器上？还是存在内存中？还是存在手机磁盘上？&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;资源是否需要压缩？&lt;/strong&gt; 用如果要压缩，什么算法压缩？什么时候进行解压缩？&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;资源是否需要缓存？缓存在什么地方？&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;资源是否需要热更新？如何支持热更新？&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;游戏安装包的大小由哪几部分组成？如何在不影响游戏安装体验的情况下，如何减小安装包&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;官方文档总结&quot;&gt;官方文档总结&lt;/h2&gt;

&lt;p&gt;Unity 官方的文档对于资源管理有丰富的文档。在阅读之后受益良多，故在此总结，望与大家交流促进。&lt;/p&gt;

&lt;h3 id=&quot;resources&quot;&gt;Resources&lt;/h3&gt;

&lt;p&gt;对于大部分 Unity 开发者来说，最熟悉的资源储存位置便是 Resources 文件夹了，对于储存在 Resources 文件夹中的文件来说，读取只需要一句简单的 &lt;code class=&quot;highlighter-rouge&quot;&gt;Resources.Load&lt;/code&gt; 即可，如下：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    rend.material.mainTexture = Resources.Load(&quot;glass&quot;) as Texture;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;放在 Resources 中的好处就是方便，需要用的就放进去，用的时候直接取出来。但是在 &lt;a href=&quot;https://unity3d.com/learn/tutorials/temas/best-practices/resources-folder&quot;&gt;官方的最佳实践文档中&lt;/a&gt;，官方明确说明 &lt;code class=&quot;highlighter-rouge&quot;&gt;Don't use it&lt;/code&gt;。不推荐的原因包括：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;将资源放于 Resources 中，在程序运行时，资源在内存的管理就不由程序员掌控。一个资源，例如图片，在使用过后是否要销毁，节省内存，还是要在内存中保留，方便后续其他界面使用？这个信息是 Unity 不能直接计算出的。&lt;/li&gt;
  &lt;li&gt;在 Resources 文件夹中放置过多资源，会增加游戏的启动时间。游戏启动的时候，Splash Screen 播放的时候，会读取并索引 Resources 文件夹中的资源，索引的本质是一个&lt;a href=&quot;https://unity3d.com/learn/tutorials/temas/best-practices/resources-folder#footnote-1&quot;&gt;树结构&lt;/a&gt;。索引的建立所花的时间复杂度是 O(N log(N))，当 Resources 文件夹中有超过 10,000 个文件时，低端机上可能需要花费好几秒钟才能完成索引建立。&lt;/li&gt;
  &lt;li&gt;如果将资源放在 Resources 文件夹中，资源会在编译时生成一个 Resources 资源包，这个资源包在编译之后是不能被修改的，也就减少了资源热更新方案中的灵活性。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;综上所述，Resources 是一个短期使用方便，但是不利于长期项目发展的方案。对于快速做一个 demo 来说，是最佳选择。在正式项目中，对于部分常用，少量，不需要经常更新的资源，也可以放于 Resources 文件夹中。&lt;/p&gt;

&lt;p&gt;特别是对于图片资源来说，有个奇怪的现象。如果图片放于 Asset Bundle 中，在储存时占用的空间是 Unity 资源序列化的大小，一个 100Kb 的 jpg 图片可能会序列化成 5M 的文件。但是在 Resources 文件夹中，只会占用 100Kb 的空间，并且在加载使用时没有太多区别。&lt;/p&gt;

&lt;h3 id=&quot;asset-bundle&quot;&gt;Asset Bundle&lt;/h3&gt;

&lt;p&gt;Asset Bundle 是 Unity &lt;a href=&quot;https://unity3d.com/learn/tutorials/topics/best-practices/assetbundle-fundamentals&quot;&gt;官方推荐的资源管理方案&lt;/a&gt;。建议大家都完整地阅读以下官方的文档，非常细致详细。&lt;/p&gt;

&lt;p&gt;在使用 Asset Bundle 的时候有3个方面是首先要了解的：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Asset Bundle 是否压缩？使用哪种压缩方案？&lt;/li&gt;
  &lt;li&gt;Asset Bundle 如何读取使用？&lt;/li&gt;
  &lt;li&gt;如何从 Asset Bundle 中读取出对应的 Unity Object?&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;asset-bundle-的压缩方式以及分发&quot;&gt;Asset Bundle 的压缩方式以及分发&lt;/h4&gt;

&lt;p&gt;Asset Bundle 在项目中往往包含了模型，动作，贴图等游戏必须的资源。在 Unity 中，对于压缩方式，我们有 3 种选择：&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;压缩方式&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;提取 Object&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;压缩后大小&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;解压速度&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;不压缩&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;提取时可以单独提取某个 Object。&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;无变化&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;不需解压&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;使用 &lt;code class=&quot;highlighter-rouge&quot;&gt;LZ4&lt;/code&gt; 算法压缩&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;压缩时可以独立压缩每一个 Asset Bundle 中的 Object，并且提取时可以单独提取某个 Object。&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;压缩率与 &lt;code class=&quot;highlighter-rouge&quot;&gt;zip&lt;/code&gt; 相似&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;解压快，大部分情况下无感知&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;使用 &lt;code class=&quot;highlighter-rouge&quot;&gt;LZMA&lt;/code&gt; 算法压缩&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;提取时只能一次加载出整个 Asset Bundle 中的内容，不能单独提取某个 Object&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;多数情况下压缩率比 &lt;code class=&quot;highlighter-rouge&quot;&gt;LZ4&lt;/code&gt; 略佳&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;解压慢&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;在&lt;a href=&quot;https://unity3d.com/learn/tutorials/topics/best-practices/assetbundle-usage-patterns&quot;&gt;压缩方式的官方文档&lt;/a&gt;中，根据不同的使用场景给出了对应的建议。对于我的项目来说，由于是 iOS 平台上的项目，包体大小是希望尽量小的，这样可以避免玩家下载的等待时间。同时，我们选择不在游戏开始时下载资源包，从而避免玩家在游戏开始时由于资源包下载导致的流逝。所以，我们最后决定使用 LZ4 压缩 Asset Bundle，并在分发时&lt;a href=&quot;https://unity3d.com/learn/tutorials/temas/best-practices/assetbundle-usage-patterns?playlist=30089#Distribution_Streaming_Assets&quot;&gt;绑定在安装包中发放&lt;/a&gt;。&lt;/p&gt;

&lt;h4 id=&quot;asset-bundle-如何读取使用&quot;&gt;Asset Bundle 如何读取使用&lt;/h4&gt;

&lt;p&gt;在&lt;a href=&quot;https://unity3d.com/learn/tutorials/topics/best-practices/assetbundle-fundamentals#Loading_AssetBundles&quot;&gt;官方关于AB包读取的部分&lt;/a&gt;也提供了5种不同的 API 进行 AB 包的读取。&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;AssetBundle.LoadFromMemory&lt;/code&gt; 官方推荐不使用该 API。原因是在使用时会使用相当于资源3倍的内存占用。这个 API 底层运行是会先将资源从可执行文件的代码区读取出来，复制到一块新开辟的内存空间，所以最终会占用3块内存：&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;可执行文件的代码区内存占用。&lt;/li&gt;
      &lt;li&gt;新开辟的内存空间，用以储存从代码区拷贝出来的 AB 包。&lt;/li&gt;
      &lt;li&gt;最终从 AB 中读取出来的 Unity Object&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;AssetBundle.LoadFromFile&lt;/code&gt; 高度优化过的用以读取未压缩或者 LZ4 压缩的 AB 包。在调用该 API 时，Unity 只会加载 AB 包的头文件，而不会读取真正的内容。主要的资源内容会在实例化 Unity Object，也就是调用 &lt;code class=&quot;highlighter-rouge&quot;&gt;AssetBundle.Load&lt;/code&gt; 时进行读取。使用时要注意这个懒读取的机制，避免在性能需求高的时候进行第一次 Load 操作。同时，在 Unity Editor 中，这个 API 会直接读取加载整个 AB 包的内容，和手机上不同，所以在 Unity Editor 进行性能分析时会发现资源加载所占用的性能特别多。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;AssetBundle.LoadFromStream&lt;/code&gt; 这个 API 没有过多介绍，应该是与 &lt;code class=&quot;highlighter-rouge&quot;&gt;AssetBundle.LoadFromFile&lt;/code&gt; 类似，但是形式上传入参数为一个数据流。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;UnityWebRequest&lt;/code&gt; 中的 &lt;a href=&quot;http://docs.unity3d.com/ScriptReference/Networking.DownloadHandlerAssetBundle.html?_ga=2.267324747.47480907.1518831956-488113989.1504339953&quot;&gt;DownloadHandlerAssetBundle&lt;/a&gt; API。&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;这个 API 是官方推荐的，用法也比较多样，最简单的例子可以在 &lt;a href=&quot;https://docs.unity3d.com/Manual/UnityWebRequest-DownloadingAssetBundle.html&quot;&gt;Downloading an AssetBundle from HTTP server&lt;/a&gt; 中找到。&lt;/li&gt;
      &lt;li&gt;其中有一个功能是很有用的，就是它的缓存功能。当使用带版本号的 API &lt;code class=&quot;highlighter-rouge&quot;&gt;public static Networking.UnityWebRequest GetAssetBundle(string uri, uint version, uint crc);&lt;/code&gt; 来下载时，会先检查本地是否有该版本的 AssetBundle，如果有就直接使用本地的 AB 包，如果没有就从服务器下载后放入缓存中。&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;注意&lt;/strong&gt;，在Unity的 AssetBundle 缓存系统里，（文件名，版本号）就标注了一个 AssetBundle，和 AB 包下载的 url 无关。所以 AB 包可以一开始放在安装包中，从安装包文件夹下载出来到缓存中，而需要更新时，从 CDN 服务器检查下载新版本即可，二者可以无缝兼容。关于缓存部分原理可以看 &lt;a href=&quot;https://docs.unity3d.com/ScriptReference/Networking.UnityWebRequest.GetAssetBundle.html&quot;&gt;UnityWebRequest 的介绍&lt;/a&gt;。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;WWW.LoadFromCacheOrDownload&lt;/code&gt;。根据官方文档，从 2017.1 开始，这个 API 只是 &lt;code class=&quot;highlighter-rouge&quot;&gt;UnityWebRequest&lt;/code&gt; 的一个封装，并且将在未来 deprecated。 推荐大家尽量不使用这个 API。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;如何从-assetbundle-中读取-unity-object&quot;&gt;如何从 AssetBundle 中读取 Unity Object&lt;/h4&gt;

&lt;p&gt;从 AssetBundle 中读取 Unity Object 主要有 3 个 API：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://docs.unity3d.com/ScriptReference/AssetBundle.LoadAsset.html&quot;&gt;LoadAsset&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://docs.unity3d.com/ScriptReference/AssetBundle.LoadAllAssets.html&quot;&gt;LoadAllAsset&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://docs.unity3d.com/ScriptReference/AssetBundle.LoadAssetWithSubAssets.html&quot;&gt;LoadAssetWithSubAssets&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这三个 API 的使用选择上相对比较容易判断。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;当一个 AB 包中大部分(66%或者以上）的 Unity Object 都需要被加载时，使用 &lt;code class=&quot;highlighter-rouge&quot;&gt;LoadAllAsset&lt;/code&gt;。&lt;/li&gt;
  &lt;li&gt;如果要加载多个 Unity Object，尽量多使用 &lt;code class=&quot;highlighter-rouge&quot;&gt;LoadAllAsset&lt;/code&gt; API，如果需要可以将其分为多个 AB 包。&lt;/li&gt;
  &lt;li&gt;如果要加载的 Unity Object 引用了很多其他 Unity Object，例如一个角色形象，引用了 FBX 文件，动作，贴图等。此时使用 &lt;code class=&quot;highlighter-rouge&quot;&gt;LoadAssetWithSubAssets&lt;/code&gt;。&lt;/li&gt;
  &lt;li&gt;其余的情况都使用 LoadAsset。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;最终解决方案&quot;&gt;最终解决方案&lt;/h2&gt;

&lt;p&gt;在比较权衡了便捷性，用户体验，性能，资源占用等方面因素，我们最后使用了如下的一套方案。&lt;/p&gt;

&lt;h3 id=&quot;资源储存&quot;&gt;资源储存&lt;/h3&gt;

&lt;p&gt;绝大部分的资源使用 Asset Bundle 来进行序列化，主要包括模型，特效，界面 UI。少部分特殊资源储存于 Resources 文件夹中，这部分主要是加载界面，字体，小图标等资源。这样的分配可以让关键部件例如加载，文字提示等功能更加健壮，不会出现由于 AssetBundle 管理不善而出现的致命 Bug，同时也可以让后期更新模型特效资源更灵活。&lt;/p&gt;

&lt;h3 id=&quot;资源压缩和分发&quot;&gt;资源压缩和分发&lt;/h3&gt;

&lt;p&gt;最初，我们在 Asset Bundle 分发方面使用了热加载的方案，就是在游戏开始时检测资源包更新，下载最新资源包后，再解压资源包，进入游戏。这个流程的好处在于初始的包体非常小，可以减小至 100 MB 以内。但是这个流程的弊病也很严重，就是玩家需要一个 “下载资源包” 的过程，并且这个过程需要占用玩家的手机使用时间，不能在后台进行。对于成熟的游戏例如 “王者荣耀” 来说，玩家的认可度足够高，是可以接受这个时间付出的。但是对于一个新生的游戏，这个过程导致的用户流失却是我们不能承受的，所以我们选择了第二套方案。&lt;/p&gt;

&lt;p&gt;第二套方案是在安装包中附带了对应版本的 Asset Bundle 并进行了压缩，在游戏开启时，只需要进行一次十几秒的解压过程即可开始游戏。这是一个端游常用的方案，在游戏发行的初期可以帮助我们避免由于 “下载资源包” 导致的用户流失。&lt;/p&gt;

&lt;p&gt;在今后的迭代中，我们还准备做进一步的改进，融合第一套和第二套方案。第二套方案在游戏启动时，同样可以检测资源包的更新，通过资源包的哈希值以及更新时间，判断是否需要下载更新。这样对于第一次下载游戏的用户，可以避免由 “下载资源包” 导致的用户流失，而对于第二次更新游戏的用户，可以一定程度上避免全量更新。&lt;/p&gt;

&lt;h3 id=&quot;资源的使用&quot;&gt;资源的使用&lt;/h3&gt;

&lt;p&gt;在资源使用上，主要流程还是 预加载资源包 – 使用克隆资源 – 释放资源包，但是由于不同模块间可能会需要使用相同的资源，所以模块间仍然需要进行协作来优化资源的使用。这里主要有一个优化点。&lt;/p&gt;

&lt;p&gt;引用计数。在加载使用资源包的流程，其实和内存管理中 开辟内存空间 – 使用内存空间 – 释放内存空间 的流程很相似。所以我们也可以将内存管理中常用的手段拿来使用。内存管理中除了我们都熟悉的 Garbage Collection 之外，还有 iOS 中使用的 ARC (Automatic Reference Counting)，自动引用计数。当一个资源被引用使用时，我们将其的计数加一，当其被释放时，将其的计数减一，如果计数为 0，则将其释放。这样一来，我们既可以准确及时地释放资源，又可以最大程度地避免资源管理上的混乱。&lt;/p&gt;

&lt;h3 id=&quot;经验总结&quot;&gt;经验总结&lt;/h3&gt;

&lt;p&gt;Unity 在目前的 3D 开发引擎里，算是社区很健全，同时文档也很丰富的一个引擎。我们遇到的绝大部分问题都是其他开发者踩过的坑，如果在一个方面停滞不前，没有好的解决方案时，不妨系统地静下心来通读一下文档。欲速则不达，静下心思考之后，往往能找到更优雅地捷径。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;如果你看到这里，一定是真爱！欢迎看看我的其他 &lt;a href=&quot;http://chendi.me/&quot;&gt;blog&lt;/a&gt;。O(∩_∩)O&lt;/p&gt;
</description>
        <pubDate>Wed, 20 Dec 2017 08:15:00 +0800</pubDate>
        <link>http://localhost:4000/2017/12/20/unity-asset-management/</link>
        <guid isPermaLink="true">http://localhost:4000/2017/12/20/unity-asset-management/</guid>
        
        <category>Tech</category>
        
        <category>Unity</category>
        
        
      </item>
    
  </channel>
</rss>
